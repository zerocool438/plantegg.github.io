<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>plantegg</title>
  
  <subtitle>java tcp mysql performance network docker Linux</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://plantegg.github.io/"/>
  <updated>2024-05-26T10:34:16.340Z</updated>
  <id>https://plantegg.github.io/</id>
  
  <author>
    <name>twitter @plantegg</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>关于本博</title>
    <link href="https://plantegg.github.io/2117/06/07/%E5%85%B3%E4%BA%8E%E6%9C%AC%E5%8D%9A/"/>
    <id>https://plantegg.github.io/2117/06/07/关于本博/</id>
    <published>2117-06-07T10:30:03.000Z</published>
    <updated>2024-05-26T10:34:16.340Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于本博"><a href="#关于本博" class="headerlink" title="关于本博"></a>关于本博</h2><p>find me on twitter: <a href="https://twitter.com/plantegg" target="_blank" rel="noopener">@plantegg</a></p><p>因为误操作本博客大部分文章没有了，博主正在辛苦地找回……，且一定可以找回来的</p><p>关注基础知识，一次把问题搞清楚，从案例出发深挖相关知识。</p><p>以前觉得自己一看就懂，实际是一问就打鼓，一用就糊涂。所以现在开始记录并总结再联系案例，一般是先把零散知识记录下来（看到过），慢慢地相关知识积累更多，直到碰到实践案例或是有点领悟到于是发现这块知识可以整理成一篇系统些的文章（基本快懂了）。</p><p>“技术变化太快，容易过时”，我的看法是网络知识、操作系统、计算机原理等核心概念知识的寿命会比你的职业生涯还长。这些都是40岁之后还会还会很有用</p><p><a href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 所有方法我都记录在这篇文章中了，希望对你能有所帮助。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;关于本博&quot;&gt;&lt;a href=&quot;#关于本博&quot; class=&quot;headerlink&quot; title=&quot;关于本博&quot;&gt;&lt;/a&gt;关于本博&lt;/h2&gt;&lt;p&gt;find me on twitter: &lt;a href=&quot;https://twitter.com/plantegg&quot; tar
      
    
    </summary>
    
      <category term="others" scheme="https://plantegg.github.io/categories/others/"/>
    
    
      <category term="performance" scheme="https://plantegg.github.io/tags/performance/"/>
    
      <category term="LVS" scheme="https://plantegg.github.io/tags/LVS/"/>
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="tcpdump" scheme="https://plantegg.github.io/tags/tcpdump/"/>
    
      <category term="TCP queue" scheme="https://plantegg.github.io/tags/TCP-queue/"/>
    
  </entry>
  
  <entry>
    <title>长连接黑洞重现和分析</title>
    <link href="https://plantegg.github.io/2024/05/05/%E9%95%BF%E8%BF%9E%E6%8E%A5%E9%BB%91%E6%B4%9E%E9%87%8D%E7%8E%B0%E5%92%8C%E5%88%86%E6%9E%90-public/"/>
    <id>https://plantegg.github.io/2024/05/05/长连接黑洞重现和分析-public/</id>
    <published>2024-05-05T00:30:03.000Z</published>
    <updated>2024-05-26T10:40:45.849Z</updated>
    
    <content type="html"><![CDATA[<h1 id="长连接黑洞重现和分析"><a href="#长连接黑洞重现和分析" class="headerlink" title="长连接黑洞重现和分析"></a>长连接黑洞重现和分析</h1><p>这是一个存在多年，遍及各个不同的业务又反反复复地在集团内部出现的一个问题，本文先通过重现展示这个问题，然后从业务、数据库、OS等不同的角度来分析如何解决它，这个问题值得每一位研发同学重视起来，避免再次踩到</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了高效率应对故障，本文尝试回答如下一些问题：</p><ul><li>为什么数据库crash 重启恢复后，业务还长时间不能恢复？</li><li>我依赖的业务做了高可用切换，但是我的业务长时间报错</li><li>我依赖的服务下掉了一个节点，为什么我的业务长时间报错 </li><li>客户做变配，升级云服务节点规格，为什么会导致客户业务长时间报错</li></ul><p>目的：希望通过这篇文章尽可能地减少故障时长、让业务快速从故障中恢复</p><h2 id="重现"><a href="#重现" class="headerlink" title="重现"></a>重现</h2><p>空说无凭，先也通过一次真实的重现来展示这个问题</p><h3 id="LVS-MySQL-高可用切换"><a href="#LVS-MySQL-高可用切换" class="headerlink" title="LVS+MySQL 高可用切换"></a>LVS+MySQL 高可用切换</h3><p>OS 默认配置参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#sysctl -a |grep -E &quot;tcp_retries|keepalive&quot;</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 5</span><br><span class="line">net.ipv4.tcp_keepalive_time = 10</span><br><span class="line">net.ipv4.tcp_retries1 = 3</span><br><span class="line">net.ipv4.tcp_retries2 = 15  //主要是这个参数，默认以及alios 几乎都是15</span><br></pre></td></tr></table></figure><p>LVS 对外服务端口是3001， 后面挂的是 3307，假设3307是当前的Master，Slave是 3306，当检测到3307异常后会从LVS 上摘掉 3307挂上 3306做高可用切换</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/1713838496899-274cdfbd-aa6e-4f1f-9fcc-16725593c25e.png" alt="undefined"></p><p>切换前的 LVS 状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#ipvsadm -L --timeout</span><br><span class="line">Timeout (tcp tcpfin udp): 900 120 300</span><br><span class="line">#ipvsadm -L -n</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  127.0.0.1:3001 rr</span><br><span class="line">  -&gt; 127.0.0.1:3307               Masq    1      0          0</span><br></pre></td></tr></table></figure><p>Sysbench启动压力模拟用户访问，在 31秒的时候模拟管控检测到 3307的Master无法访问，所以管控执行切主把 3306的Slave 提升为新的 Master，同时到 LVS 摘掉 3307，挂上3306，此时管控端着冰可乐、翘着二郎腿，得意地说，你就看吧我们管控牛逼不、我们的高可用牛逼不，这一套行云流水3秒钟不到全搞定</p><p>切换命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#cat del3307.sh</span><br><span class="line">ipvsadm -d -t  127.0.0.1:3001 -r 127.0.0.1:3307 ; ipvsadm -a -t  127.0.0.1:3001 -r 127.0.0.1:3306 -m</span><br></pre></td></tr></table></figure><p>此时Sysbench运行状态，在第 32秒如期跌0：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#/usr/local/bin/sysbench --debug=on --mysql-user=&apos;root&apos; --mysql-password=&apos;123&apos; --mysql-db=&apos;test&apos; --mysql-host=&apos;127.0.0.1&apos; --mysql-port=&apos;3001&apos; --tables=&apos;16&apos;  --table-size=&apos;10000&apos; --range-size=&apos;5&apos; --db-ps-mode=&apos;disable&apos; --skip-trx=&apos;on&apos; --mysql-ignore-errors=&apos;all&apos; --time=&apos;11080&apos; --report-interval=&apos;1&apos; --histogram=&apos;on&apos; --threads=1 oltp_read_write run</span><br><span class="line">sysbench 1.1.0 (using bundled LuaJIT 2.1.0-beta3)</span><br><span class="line"></span><br><span class="line">Running the test with following options:</span><br><span class="line">Number of threads: 1</span><br><span class="line">Report intermediate results every 1 second(s)</span><br><span class="line">Debug mode enabled.</span><br><span class="line"></span><br><span class="line">Initializing random number generator from current time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Initializing worker threads...</span><br><span class="line"></span><br><span class="line">DEBUG: Worker thread (#0) started</span><br><span class="line">DEBUG: Reporting thread started</span><br><span class="line">DEBUG: Worker thread (#0) initialized</span><br><span class="line">Threads started!</span><br><span class="line"></span><br><span class="line">[ 1s ] thds: 1 tps: 51.89 qps: 947.00 (r/w/o: 739.44/207.56/0.00) lat (ms,95%): 35.59 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 2s ] thds: 1 tps: 60.03 qps: 1084.54 (r/w/o: 841.42/243.12/0.00) lat (ms,95%): 22.28 err/s 0.00 reconn/s: 0.00</span><br><span class="line">…………</span><br><span class="line">[ 29s ] thds: 1 tps: 68.00 qps: 1223.01 (r/w/o: 952.00/271.00/0.00) lat (ms,95%): 16.12 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 30s ] thds: 1 tps: 66.00 qps: 1188.00 (r/w/o: 924.00/264.00/0.00) lat (ms,95%): 16.71 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 31s ] thds: 1 tps: 67.00 qps: 1203.96 (r/w/o: 937.97/265.99/0.00) lat (ms,95%): 17.95 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 32s ] thds: 1 tps: 22.99 qps: 416.85 (r/w/o: 321.88/94.96/0.00) lat (ms,95%): 15.55 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 33s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 34s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 35s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br></pre></td></tr></table></figure><p>5分钟后故障报告大批量涌进来，客户：怎么回事，我们的业务挂掉10分钟了，报错都是访问MySQL 超时，赶紧给我看看，从监控确实看到10分钟后客户业务还没恢复：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[ 601s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 602s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 603s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 604s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br></pre></td></tr></table></figure><p>这时 oncall 都被从被窝里拎了起来，不知谁说了一句赶紧恢复吧，先试试把应用重启，5秒钟后应用重启完毕，业务恢复，大家开心地笑了，又成功防御住一次故障升级，还是重启大法好！</p><p>在业务&#x2F;Sysbench QPS跌0 期间可以看到 3307被摘掉，3306 成功挂上去了，但是没有新连接建向 3306，业务&#x2F;Sysbench 使劲薅着 3307</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#ipvsadm -L -n --stats -t 127.0.0.1:3001</span><br><span class="line">Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes</span><br><span class="line">  -&gt; RemoteAddress:Port</span><br><span class="line">TCP  127.0.0.1:3001                      2   660294   661999 78202968  184940K</span><br><span class="line">  -&gt; 127.0.0.1:3306                      0        0        0        0        0</span><br><span class="line">  </span><br><span class="line">#ipvsadm -Lcn | head -10</span><br><span class="line">IPVS connection entries</span><br><span class="line">pro expire state       source             virtual            destination</span><br><span class="line">TCP 13:11  ESTABLISHED 127.0.0.1:33864    127.0.0.1:3001     127.0.0.1:3307</span><br><span class="line"></span><br><span class="line">#netstat -anto |grep -E &quot;Recv|33864|3001|33077&quot;</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       Timer</span><br><span class="line">tcp        0    248 127.0.0.1:33864         127.0.0.1:3001          ESTABLISHED probe (33.48/0/8)</span><br><span class="line">tcp6       0     11 127.0.0.1:3307          127.0.0.1:33864         ESTABLISHED on (49.03/13/0)</span><br></pre></td></tr></table></figure><p>直到 900多秒后 OS 重试了15次发现都失败，于是向业务&#x2F;Sysbench 返回连接异常，触发业务&#x2F;Sysbench 释放异常连接重建新连接，新连接指向了新的 Master 3306，业务恢复正常</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[ 957s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">DEBUG: Ignoring error 2013 Lost connection to MySQL server during query,</span><br><span class="line">DEBUG: Reconnecting </span><br><span class="line">DEBUG: Reconnected</span><br><span class="line">[ 958s ] thds: 1 tps: 53.00 qps: 950.97 (r/w/o: 741.98/208.99/0.00) lat (ms,95%): 30.26 err/s 0.00 reconn/s: 1.00</span><br><span class="line">[ 959s ] thds: 1 tps: 64.00 qps: 1154.03 (r/w/o: 896.02/258.01/0.00) lat (ms,95%): 22.69 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 960s ] thds: 1 tps: 66.00 qps: 1184.93 (r/w/o: 923.94/260.98/0.00) lat (ms,95%): 25.28 err/s 0.00 reconn/s: 0.00</span><br></pre></td></tr></table></figure><p>到这里重现了故障中经常碰到的业务需要900多秒才能慢慢恢复，这个问题也就是 <strong>TCP 长连接流量黑洞</strong></p><p>如果我们<strong>把 net.ipv4.tcp_retries2 改成5</strong> 再来做这个实验，就会发现业务&#x2F;Sysbench 只需要20秒就能恢复了，也就是这个流量黑洞从900多秒变成了20秒，这回 oncall 不用再被从被窝里拎出来了吧：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[ 62s ] thds: 1 tps: 66.00 qps: 1191.00 (r/w/o: 924.00/267.00/0.00) lat (ms,95%): 17.63 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 63s ] thds: 1 tps: 63.00 qps: 1123.01 (r/w/o: 874.00/249.00/0.00) lat (ms,95%): 17.63 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 64s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 65s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 66s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 67s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 68s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 69s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 70s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 71s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 72s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 73s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 74s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 75s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 76s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 77s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 78s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 79s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 80s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 81s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 82s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</span><br><span class="line">DEBUG: Ignoring error 2013 Lost connection to MySQL server during query,</span><br><span class="line">DEBUG: Reconnecting </span><br><span class="line">DEBUG: Reconnected</span><br><span class="line">[ 83s ] thds: 1 tps: 26.00 qps: 457.01 (r/w/o: 357.01/100.00/0.00) lat (ms,95%): 16.41 err/s 0.00 reconn/s: 1.00</span><br><span class="line">[ 84s ] thds: 1 tps: 60.00 qps: 1086.94 (r/w/o: 846.96/239.99/0.00) lat (ms,95%): 26.68 err/s 0.00 reconn/s: 0.00</span><br><span class="line">[ 85s ] thds: 1 tps: 63.00 qps: 1134.02 (r/w/o: 882.01/252.00/0.00) lat (ms,95%): 23.10 err/s 0.00 reconn/s: 0.00</span><br></pre></td></tr></table></figure><h3 id="LVS-Nginx-上重现"><a href="#LVS-Nginx-上重现" class="headerlink" title="LVS + Nginx 上重现"></a>LVS + Nginx 上重现</h3><p>NGINX上重现这个问题：<a href="https://asciinema.org/a/649890" target="_blank" rel="noopener">https://asciinema.org/a/649890</a> 3分钟的录屏，这个视频构造了一个LVS 的HA切换过程，LVS后有两个Nginx，模拟一个Nginx(Master) 断网后，将第二个Nginx(Slave) 加入到LVS 并将第一个Nginx(Master) 从LVS 摘除，期望业务能立即恢复，但实际上可以看到之前的所有长连接都没有办法恢复，进入一个流量黑洞</p><h2 id="TCP-长连接流量黑洞原理总结"><a href="#TCP-长连接流量黑洞原理总结" class="headerlink" title="TCP 长连接流量黑洞原理总结"></a>TCP 长连接流量黑洞原理总结</h2><p>TCP 长连接在发送包的时候，如果没收到ack 默认会进行15次重传(net.ipv4.tcp_retries2&#x3D;15, 这个不要较真，会根据RTO 时间大致是15次)，累加起来大概是924秒，所以我们经常看到业务需要15分钟左右才恢复。这个问题存在所有TCP长连接中(几乎没有业务还在用短连接吧？)，问题的本质和 LVS&#x2F;k8s Service 都没关系</p><p>我这里重现带上 LVS 只是为了场景演示方便 </p><p>这个问题的本质就是如果Server突然消失(宕机、断网，来不及发 RST )客户端如果正在发东西给Server就会遵循TCP 重传逻辑不断地TCP retran , 如果一直收不到Server 的ack，大约重传15次，900秒左右。所以不是因为有 LVS 导致了这个问题，而是在某些场景下 LVS 有能力处理得更优雅，比如删除 RealServer的时候 LVS 完全可以感知这个动作并 reset 掉其上所有长连接</p><p>为什么在K8S 上这个问题更明显呢，K8S 讲究的就是服务不可靠，随时干掉POD(切断网络），如果干POD 之前能kill -9(触发reset)、或者close 业务触发断开连接那还好，但是大多时候啥都没干，有强摘POD、有直接隔离等等，这些操作都会导致对端只能TCP retran</p><h2 id="怎么解决"><a href="#怎么解决" class="headerlink" title="怎么解决"></a>怎么解决</h2><h3 id="业务方"><a href="#业务方" class="headerlink" title="业务方"></a>业务方</h3><p>业务方要对自己的请求超时时间有控制和兜底，不能任由一个请求长时间 Hang 在那里</p><p>比如JDBC URL 支持设置 SocketTimeout、ConnectTimeout，我相信其他产品也有类似的参数，业务方要设置这些值，不设置就是如上重现里演示的900多秒后才恢复</p><h4 id="SocketTimeout"><a href="#SocketTimeout" class="headerlink" title="SocketTimeout"></a>SocketTimeout</h4><p>只要是连接有机会设置 SocketTimeout 就一定要设置，具体值可以根据你们能接受的慢查询来设置；分析、AP类的请求可以设置大一点</p><p><strong>最重要的：任何业务只要你用到了TCP 长连接一定要配置一个恰当的SocketTimeout</strong>，比如 Jedis 是连接池模式，底层超时之后，会销毁当前连接，下一次重新建连，就会连接到新的切换节点上去并恢复</p><h4 id="RFC-5482-TCP-USER-TIMEOUT"><a href="#RFC-5482-TCP-USER-TIMEOUT" class="headerlink" title="RFC 5482 TCP_USER_TIMEOUT"></a><a href="https://datatracker.ietf.org/doc/html/rfc5482" target="_blank" rel="noopener">RFC 5482</a> <code>TCP_USER_TIMEOUT</code></h4><p><a href="https://datatracker.ietf.org/doc/html/rfc5482" target="_blank" rel="noopener">RFC 5482</a> 中增加了<code>TCP_USER_TIMEOUT</code>这个配置，通常用于定制当 TCP 网络连接中出现数据传输问题时，可以等待多长时间前释放网络资源，对应Linux 这个 <a href="https://github.com/torvalds/linux/commit/dca43c75e7e545694a9dd6288553f55c53e2a3a3" target="_blank" rel="noopener">commit </a></p><p><code>TCP_USER_TIMEOUT</code> 是一个整数值，它指定了当 TCP 连接的数据包在发送后多长时间内未被确认（即没有收到 ACK），TCP 连接会考虑释放这个连接。</p><p>打个比方，设置 <code>TCP_USER_TIMEOUT</code> 后，应用程序就可以指定说：“如果在 30 秒内我发送的数据没有得到确认，那我就认定网络连接出了问题，不再尝试继续发送，而是直接断开连接。”这对于确保连接质量和维护用户体验是非常有帮助的。</p><p>在 Linux 中，可以使用 <code>setsockopt</code> 函数来设置某个特定 socket 的 <code>TCP_USER_TIMEOUT</code> 值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int timeout = 30000; // 30 seconds</span><br><span class="line">setsockopt(sock, IPPROTO_TCP, TCP_USER_TIMEOUT, (char *)&amp;timeout, sizeof(timeout));</span><br></pre></td></tr></table></figure><p>在这行代码中，<code>sock</code> 是已经 established 的 TCP socket，我们将该 socket 的 <code>TCP_USER_TIMEOUT</code> 设置为 30000 毫秒，也就是 30 秒。如果设置成功，这个 TCP 连接在发送数据包后 30 秒内如果没有收到 ACK 确认，将开始进行 TCP 连接的释放流程。</p><p>TCP_USER_TIMEOUT 相较 SocketTimeout 可以做到更精确(不影响慢查询)，SocketTimeout 超时是不区分ACK 还是请求响应时间的，但是 TCP_USER_TIMEOUT 要求下层的API、OS 都支持。比如 JDK 不支持 TCP_USER_TIMEOUT，但是 <a href="https://github.com/tomasol/netty/commit/3010366d957d7b8106e353f99e15ccdb7d391d8f#diff-a998f73b7303461ca171432d10832884c6e7b0955d9f5634b9a8302b42a4706c" target="_blank" rel="noopener">Netty 框架自己搞了Native</a> 来实现对 TCP_USER_TIMEOUT 以及其它OS 参数的设置，在这些基础上<a href="https://github.com/redis/lettuce/pull/2499" target="_blank" rel="noopener">Redis 的Java 客户端 lettuce 依赖了 Netty ，所以也可以设置 TCP_USER_TIMEOUT</a></p><p>原本我是想在Druid 上提个feature 来支持 TCP_USER_TIMEOUT，这样集团绝大部分业务都可以无感知解决掉这个问题，但查下来发现 JDK 不支持设置这个值，想要在Druid 里面实现设置 TCP_USER_TIMEOUT 的话，得像 Netty 一样走Native 绕过JDK 来设置，这对 Druid 而言有点重了</p><h4 id="ConnectTimeout"><a href="#ConnectTimeout" class="headerlink" title="ConnectTimeout"></a>ConnectTimeout</h4><p>这个值是针对新连接创建超时时间设置，一般设置3-5秒就够长了</p><h4 id="连接池"><a href="#连接池" class="headerlink" title="连接池"></a>连接池</h4><p>建议参考这篇 <a href="https://help.aliyun.com/document_detail/181399.html" target="_blank" rel="noopener">《数据库连接池配置推荐》</a>  这篇里的很多建议也适合业务、应用等，你把数据库看成一个普通服务就好理解了</p><p>补充下如果用的是Druid 数据库连接池不要用它来设置你的  SocketTimeout 参数，因为他有bug 导致你觉得设置了但实际没设置上，<a href="https://github.com/alibaba/druid/releases/tag/1.2.22" target="_blank" rel="noopener">2024-03-16号的1.2.22</a>这个Release 才fix，所以强烈建议你讲 SocketTimeout 写死在JDBC URL 中简单明了</p><h3 id="OS-兜底"><a href="#OS-兜底" class="headerlink" title="OS 兜底"></a>OS 兜底</h3><p>假如业务是一个AP查询&#x2F;一次慢请求，一次查询&#x2F;请求就是需要半个小时，将 SocketTimeout 设置太小影响正常的查询，那么可以将如下 OS参数改小，从 OS 层面进行兜底</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_retries2 = 8</span><br><span class="line">net.ipv4.tcp_syn_retries = 4</span><br></pre></td></tr></table></figure><h4 id="keepalive"><a href="#keepalive" class="headerlink" title="keepalive"></a>keepalive</h4><p>keepalive 默认 7200秒太长了，建议改成20秒，可以在OS 镜像层面固化，然后各个业务可以 patch 自己的值；</p><p>如果一条连接限制超过 900 秒 LVS就会Reset 这条连接，但是我们将keepalive 设置小于900秒的话，即使业务上一直闲置，因为有 keepalive 触发心跳包，让 LVS 不至于 Reset，这也就避免了当业务取连接使用的时候才发现连接已经不可用被断开了，往往这个时候业务抛错误的时间很和真正 Reset 时间还差了很多，不好排查</p><p>在触发 TCP retransmission 后会停止 keepalive 探测</p><h3 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a>LVS</h3><p>如果你们试用了aliyun的SLB，当摘除节点的时候支持你设置一个时间，过了这个时间 aliyun的SLB 就会向这些连接的客户端发 Reset 干掉这些流量，让客户端触发新建连接，从故障中快速恢复，这是一个实例维度的参数，建议云上所有产品都支持起来，管控可以在购买 aliyun的SLB 的时候设置一个默认值：</p><p> <code>connection_drain_timeout</code> </p><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><h3 id="神奇的900秒"><a href="#神奇的900秒" class="headerlink" title="神奇的900秒"></a>神奇的900秒</h3><p>上面阐述的长连接流量黑洞一般是900+秒就恢复了，有时候我们经常在日志中看到 CommunicationsException: Communications link failure 900秒之类的错误，恰好 LVS 也是设置的 900秒闲置 Reset</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#ipvsadm -L --timeout</span><br><span class="line">Timeout (tcp tcpfin udp): 900 120 300</span><br></pre></td></tr></table></figure><h3 id="为什么这个问题这几年才明显暴露"><a href="#为什么这个问题这几年才明显暴露" class="headerlink" title="为什么这个问题这几年才明显暴露"></a>为什么这个问题这几年才明显暴露</h3><ul><li>工程师们混沌了几十年</li><li>之前因为出现频率低重启业务就糊弄过去了</li><li>对新连接不存在这个问题</li><li>有些连接池配置了Check 机制(Check机制一般几秒钟超时 fail)</li><li>微服务多了</li><li>云上 LVS 普及了</li><li>k8s service 大行其道</li></ul><h3 id="我用的-7层是不是就没有这个问题了？"><a href="#我用的-7层是不是就没有这个问题了？" class="headerlink" title="我用的 7层是不是就没有这个问题了？"></a>我用的 7层是不是就没有这个问题了？</h3><p>幼稚，你4层都挂了7层还能蹦跶，再说一遍只要是 TCP 长连接就有这个问题</p><h3 id="极端情况"><a href="#极端情况" class="headerlink" title="极端情况"></a>极端情况</h3><p>A 长连接 访问B 服务，B服务到A网络不通，假如B发生HA，一般会先Reset&#x2F;断开B上所有连接(比如 MySQL 会去kill 所有processlist；比如重启MySQL——假如这里的B是MySQL)，但是因为网络不通这里的reset、fin网络包都无法到达A，所以B是无法兜底这个异常场景， A无法感知B不可用了，会使用旧连接大约15分钟</p><p>最可怕的是 B 服务不响应，B所在的OS 还在响应，那么在A的视角 网络是正常的，这时只能A自己来通过超时兜底</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这种问题在 LVS 场景下暴露更明显了，但是又和LVS 没啥关系，任何业务长连接都会导致这个 900秒左右的流量黑洞，首先要在业务层面重视这个问题，要不以后数据库一挂掉还得重启业务才能从故障中将恢复，所以业务层面处理好了可以避免900秒黑洞和重启业务，达到快速从故障中恢复</p><p>再强调下这个问题如果去掉LVS&#x2F;k8s Service&#x2F;软负载等让两个服务直连，然后拔网线也会同样出现</p><p>最佳实践总结：</p><ul><li>如果你的业务支持设置 SocketTimeout 那么请一定要设置，但不一定适合分析类就是需要长时间返回的请求</li><li>最好的方式是设置 OS 层面的 TCP_USER_TIMEOUT 参数，只要长时间没有 ack 就报错返回，但 JDK 不支持直接设置</li><li>如果用了 ALB&#x2F;SLB 就一定要配置 connection_drain_timeout 这个参数</li><li>OS 镜像层面也可以将 tcp_retries2 设置为5-10次做一个兜底</li><li>对你的超时时间做到可控、可预期</li></ul><h2 id="相关故障和资料"><a href="#相关故障和资料" class="headerlink" title="相关故障和资料"></a>相关故障和资料</h2><p>ALB 黑洞问题详述：<a href="https://mp.weixin.qq.com/s/BJWD2V_RM2rnU1y7LPB9aw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/BJWD2V_RM2rnU1y7LPB9aw</a></p><p>数据库故障引发的“血案” ：<a href="https://www.cnblogs.com/nullllun/p/15073022.html" target="_blank" rel="noopener">https://www.cnblogs.com/nullllun/p/15073022.html</a> 这篇描述较细致，推荐看看</p><p>tcp_retries2 的解释：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">tcp_retries1 - INTEGER</span><br><span class="line">    This value influences the time, after which TCP decides, that</span><br><span class="line">    something is wrong due to unacknowledged RTO retransmissions,</span><br><span class="line">    and reports this suspicion to the network layer.</span><br><span class="line">    See tcp_retries2 for more details.</span><br><span class="line"></span><br><span class="line">    RFC 1122 recommends at least 3 retransmissions, which is the</span><br><span class="line">    default.</span><br><span class="line"></span><br><span class="line">tcp_retries2 - INTEGER</span><br><span class="line">    This value influences the timeout of an alive TCP connection,</span><br><span class="line">    when RTO retransmissions remain unacknowledged.</span><br><span class="line">    Given a value of N, a hypothetical TCP connection following</span><br><span class="line">    exponential backoff with an initial RTO of TCP_RTO_MIN would</span><br><span class="line">    retransmit N times before killing the connection at the (N+1)th RTO.</span><br><span class="line"></span><br><span class="line">    The default value of 15 yields a hypothetical timeout of 924.6</span><br><span class="line">    seconds and is a lower bound for the effective timeout.</span><br><span class="line">    TCP will effectively time out at the first RTO which exceeds the</span><br><span class="line">    hypothetical timeout.</span><br><span class="line"></span><br><span class="line">    RFC 1122 recommends at least 100 seconds for the timeout,</span><br><span class="line">    which corresponds to a value of at least 8.</span><br></pre></td></tr></table></figure><p>tcp_retries2 默认值为15，根据RTO的值来决定，相当于13-30分钟(RFC1122规定，必须大于100秒)，但是这是很多年前的拍下来古董参数值，现在网络条件好多了，尤其是内网，个人认为改成 5-10 是比较恰当 azure 建议：<a href="https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-best-practices-connection" target="_blank" rel="noopener">https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-best-practices-connection</a> ，Oracle RAC的建议值是3：<a href="https://access.redhat.com/solutions/726753" target="_blank" rel="noopener">https://access.redhat.com/solutions/726753</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;长连接黑洞重现和分析&quot;&gt;&lt;a href=&quot;#长连接黑洞重现和分析&quot; class=&quot;headerlink&quot; title=&quot;长连接黑洞重现和分析&quot;&gt;&lt;/a&gt;长连接黑洞重现和分析&lt;/h1&gt;&lt;p&gt;这是一个存在多年，遍及各个不同的业务又反反复复地在集团内部出现的一个问题，本
      
    
    </summary>
    
      <category term="network" scheme="https://plantegg.github.io/categories/network/"/>
    
    
      <category term="Linux" scheme="https://plantegg.github.io/tags/Linux/"/>
    
      <category term="LVS" scheme="https://plantegg.github.io/tags/LVS/"/>
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="SocketTimeout" scheme="https://plantegg.github.io/tags/SocketTimeout/"/>
    
      <category term="TCP_USER_TIMEOUT" scheme="https://plantegg.github.io/tags/TCP-USER-TIMEOUT/"/>
    
  </entry>
  
  <entry>
    <title>三个故事</title>
    <link href="https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/"/>
    <id>https://plantegg.github.io/2022/01/01/三个故事/</id>
    <published>2022-01-01T04:30:03.000Z</published>
    <updated>2024-05-07T09:59:58.964Z</updated>
    
    <content type="html"><![CDATA[<h1 id="三个故事"><a href="#三个故事" class="headerlink" title="三个故事"></a>三个故事</h1><h2 id="故事一-无招胜有招"><a href="#故事一-无招胜有招" class="headerlink" title="故事一 无招胜有招"></a>故事一 无招胜有招</h2><p>我有一个同事前是5Q(人人网的前身) 出来的，叫Z神，负责技术（所有解决不了的问题都找他），Z神从chinaren出道，跟着王兴一块创业做 5Q，5Q在学校靠鸡腿打下大片市场，最后被陈一舟的校内收购（据说被收购后5Q的好多技术都走了，最后王兴硬是呆在校内网把合约上的所有钱都拿到了）。</p><p>Z神让我最佩服的解决问题的能力，好多问题其实他也不一定就擅长，但是他就是有本事通过Help、Google不停地验证尝试就把一个不熟悉的问题给解决了，这是我最羡慕的能力，在后面的职业生涯中一直不停地往这个方面尝试。</p><h3 id="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"><a href="#应用刚启动连接到数据库的时候比较慢，但又不是慢查询" class="headerlink" title="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"></a>应用刚启动连接到数据库的时候比较慢，但又不是慢查询</h3><ol><li>Z神的解决办法是通过tcpdump来分析网络包，看网络包的时间戳和网络包的内容，然后找到了具体卡在了哪里。</li><li>如果是专业的DBA可能会通过show processlist 看具体连接在做什么，比如看到这些连接状态是 <strong>authentication</strong> 状态，然后再通过Google或者对这个状态的理解知道创建连接的时候MySQL需要反查IP、域名这里比较耗时，通过配置参数 <strong>skip-name-resolve</strong> 跳过去就好了。</li><li>如果是MySQL的老司机，一上来就知道连接慢的话跟 <strong>skip-name-resolve</strong> 关系最大。</li></ol><p>在我眼里这三种方式都解决了问题，最后一种最快但是纯靠积累和经验，换个问题也许就不灵了；第一种方式是最牛逼和通用的，只需要最少的知识就把问题解决了。</p><p>我当时跟着Z神从sudo、ls等linux命令开始学起。当然我不会轻易去打搅他问他，每次碰到问题我尽量让他在我的电脑上来操作，解决后我再自己复盘，通过history调出他的所有操作记录，看他在我的电脑上用Google搜啥了，然后一个个去学习分析他每个动作，去想他为什么搜这个关键字，复盘完还有不懂的再到他面前跟他面对面的讨论他为什么要这么做，指导他这么做的知识和逻辑又是什么。</p><p><strong>如果你学不会无招胜有招，那么history你总能学会吧！</strong></p><p>这是当时的Z神用我的工作台（方方正正的显示器可见年代很久远了）</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/63683421ly1h249wsg025j218g0xcnpd-20220610210134388.jpg" alt="img"></p><h2 id="故事二-网络专家的机会"><a href="#故事二-网络专家的机会" class="headerlink" title="故事二 网络专家的机会"></a>故事二 网络专家的机会</h2><p>N年前我刚加入一家公司几个月，有一个客户购买了我们的产品上线后金额对不上（1类生产事故），于是经理带着我们几个技术去现场看看是什么原因，路上经理说你们不要有什么心理压力，我不懂技术但是我过去就是替你们挨骂的，我好好跪在客户那挨骂，你们好好安心解决问题。</p><p>问题大概就是客户有一段涉及交易的代码在事务中，但是提交到后端我们的服务上后钱对不上了，客户认为我们产品事务实现有问题。</p><p>到了现场客户不让下载他们代码，只能人肉趴在他们指定的机器上用眼睛看问题在哪里，看了三天自然是没找到为啥，大家非常沮丧地回来了，然后我们的产品被下线，客户直接把数据库换成了Oracle，换完后第一天没问题，我们是越发沮丧，大家都不敢提这个事情了，但是三天后一个振奋人心的消息传过来了：金额还是对不上 …… :))))))</p><p>于是我们再度派出技术人员帮他们看为什么（这次客户配合度高了很多），最后有个同事提了一嘴要不用 tcpdump 抓个包看看，到底应用代码有没有set autocommit&#x3D;0, 半个小时后传来喜讯用户代码发出的就是autocommit&#x3D;1,说明用户代码的事务配置没生效。</p><p>最后查出来配置文件中有中文注释，测试环境没有问题，但是生产环境机器不支持中文出现了乱码，中文注释后的配置文件没有被解析到，导致事务没有生效！</p><p>打个岔，类似问题你也可以看看这个<a href="https://zhuanlan.zhihu.com/p/532243682" target="_blank" rel="noopener">MySQL JDBC驱动8.0的bug导致事务没生效</a></p><p>事情还没完，当我听到这个结果后恨不得实际抽自己，tcpdump咱也会用，怎么当时就没想到呢！于是后来我天天看tcpdump、分析网络包，有段时间最开心的是在酒店看书了。一个月后写了几篇文章放在公司内网，再然后公司内部各个团队开始拿着各种问题找过来，我的case也越来越多。</p><p>有一次产品调用是这样的 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6  产品5是我们的，1说性能上不去，rt 是100太大，扯了两天皮，然后说5有问题，于是我到5上抓了个包，抓完包一分析，我心里有底了，明确告诉他们5的rt才2，压力还没有到5这里来，另外按照我抓包结果的rt分析，5的能力是20万，现在还不到1万，瓶颈在1-5之间，然后我上1&#x2F;2&#x2F;3&#x2F;4用 netstat 分别看下网络状态发现1-2之间网络到了瓶颈（2回包给1的时候大量的包no ack）,不要怀疑netstat真有这么强大，只是你不会看而已。如下图 2上的9108服务端口给1发回结果的时候1那边迟迟不给ack。其实这个case用好工具只是很小的一点，关键的是我能抓包分析出rt，然后从rt推断出系统的能力（别说全链路监控之类的，有时候还得拼刺刀），进而快速定位到瓶颈</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20220611101850071.png" alt="image-20220611101850071"></p><p>现在我们的产品文档必备一份tcpdump、tshark（wireshark命令行版本）<a href="https://plantegg.github.io/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">救急命令箱</a>，有时候让客户复制粘贴执行后给我们某个结果，好多问题不再是问题了</p><p>这个故事的结果是我成了公司的网络“专家”</p><h2 id="故事三-Die是什么"><a href="#故事三-Die是什么" class="headerlink" title="故事三 Die是什么"></a>故事三 Die是什么</h2><p>2021年4月的时候，我们有个项目要在不同的硬件平台验收，那天傍晚7点正要回家的我被项目经理拽到了现场</p><blockquote><p>系统性能不达标，现场都不知道为啥</p></blockquote><p>我到现场看了下perf </p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/16b271c8-5132-4273-a26a-4b35e8f92882.png" alt="img"></p><p>然后处理了下，IPC从0.08提升到了0.22(IPC代表性能，越大越好)，再细调下最终能到0.27，对应的业务测试QPS也是原来的4倍。 </p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/4d4fdebb-6146-407e-881d-19170fbfd82b.png" alt="img"></p><p>到这里谈不上任何故事性，我也很好奇为什么有这么好的效果，不信可以看这篇《<a href="https://plantegg.github.io/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">十年后数据库还是不敢拥抱NUMA？</a>》。</p><p>接下来的几天那个项目经理特批我拿他们的环境随便测试，于是我停下手头的工作，花了一周在这个环境做了很多验证和学习，并请教了公司CPU方面特别厉害的大佬，如下图（2021年我的水平就是这样，和所有程序员对CPU的了解一样，只是知道主频、核数，会看top）</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/63683421gy1h30yi296dij207e038t9b.jpg" alt="img"></p><p>大佬跟我说：两个Die的L3不互通。我就问了一句Die是啥意思，他回答一个晶圆。其实这时我还没有听懂，但是不好意思再问了– 这感觉你们平时都有吧，就是不在一个段位，差太远了，不好意思再问，到了该自己先去弄脏双手后再请教的时候了！</p><p>于是就Google各种概念、并收集各种资料和图，最后整理了一下（所以文章的连贯性其实不好），以个人笔记的形式存档下来了。</p><p>最后把这些笔记从多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）总结成了一系列文章。</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"></p><p>这个故事你觉得我想说啥，辛苦帮我在评论里总结下</p><h2 id="其他想说的"><a href="#其他想说的" class="headerlink" title="其他想说的"></a>其他想说的</h2><p>看完故事升华一下方法论：<a href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a></p><h2 id="如果你觉得看完对你很有帮助可以通过如下方式找到我"><a href="#如果你觉得看完对你很有帮助可以通过如下方式找到我" class="headerlink" title="如果你觉得看完对你很有帮助可以通过如下方式找到我"></a>如果你觉得看完对你很有帮助可以通过如下方式找到我</h2><p>find me on twitter: <a href="https://twitter.com/plantegg" target="_blank" rel="noopener">@plantegg</a></p><p>知识星球：<a href="https://t.zsxq.com/0cSFEUh2J" target="_blank" rel="noopener">https://t.zsxq.com/0cSFEUh2J</a></p><p>开了一个星球，在里面讲解一些案例、知识、学习方法，肯定没法让大家称为顶尖程序员(我自己都不是)，只是希望用我的方法、知识、经验、案例作为你的垫脚石，帮助你快速、早日成为一个基本合格的程序员。</p><p>争取在星球内：</p><ul><li>养成基本动手能力</li><li>拥有起码的分析推理能力–按我接触的程序员，大多都是没有逻辑的</li><li>知识上教会你几个关键的知识点</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;三个故事&quot;&gt;&lt;a href=&quot;#三个故事&quot; class=&quot;headerlink&quot; title=&quot;三个故事&quot;&gt;&lt;/a&gt;三个故事&lt;/h1&gt;&lt;h2 id=&quot;故事一-无招胜有招&quot;&gt;&lt;a href=&quot;#故事一-无招胜有招&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="技巧" scheme="https://plantegg.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="实践" scheme="https://plantegg.github.io/tags/%E5%AE%9E%E8%B7%B5/"/>
    
      <category term="复盘" scheme="https://plantegg.github.io/tags/%E5%A4%8D%E7%9B%98/"/>
    
      <category term="逻辑" scheme="https://plantegg.github.io/tags/%E9%80%BB%E8%BE%91/"/>
    
      <category term="知识积累" scheme="https://plantegg.github.io/tags/%E7%9F%A5%E8%AF%86%E7%A7%AF%E7%B4%AF/"/>
    
  </entry>
  
  <entry>
    <title>如何在工作中学习</title>
    <link href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/"/>
    <id>https://plantegg.github.io/2018/05/23/如何在工作中学习/</id>
    <published>2018-05-23T04:30:03.000Z</published>
    <updated>2024-05-07T09:59:59.065Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何在工作中学习"><a href="#如何在工作中学习" class="headerlink" title="如何在工作中学习"></a>如何在工作中学习</h1><p>大家平时都看过很多方法论的文章，看的时候很爽觉得非常有用，但是一两周后基本还是老样子了。其中有很大一部分原因那些方法对脑力有要求、或者方法论比较空缺少落地的步骤。 下文中描述的方式方法是不需要智商也能学会的，非常具体可以复制。</p><blockquote><p>先说一件值得思考的事情：高考的时候大家都是一样的教科书，同一个教室，同样的老师辅导，时间精力基本差不多，可是最后别人考的是清华北大或者一本，而你的实力只能考个三本，为什么？ 当然这里主要是智商的影响，那么其他因素呢？智商解决的问题能不能后天用其他方式来补位一下？</p></blockquote><p>思考10秒钟再往下看</p><h2 id="关键问题点"><a href="#关键问题点" class="headerlink" title="关键问题点"></a>关键问题点</h2><p>解决问题的能力就是从你储蓄的知识中提取到方案，差别就是知识储存能力和运用能力的差异</p><h3 id="为什么你的知识积累不了？"><a href="#为什么你的知识积累不了？" class="headerlink" title="为什么你的知识积累不了？"></a>为什么你的知识积累不了？</h3><p>有些知识看过就忘、忘了再看，实际碰到问题还是联系不上这个知识，这其实是知识的积累出了问题，没有深入理解好自然就不能灵活运用，也就谈不上解决不了问题。这跟大家一起看相同的高考教科书但是高考结果不一样。问题出在了理解上，每个人的理解能力不一样（智商），绝大多数人对知识的理解要靠不断地实践（做题）来巩固。</p><h3 id="同样实践效果不一样？"><a href="#同样实践效果不一样？" class="headerlink" title="同样实践效果不一样？"></a>同样实践效果不一样？</h3><p>同样工作一年碰到了10个问题（或者说做了10套高考模拟试卷），但是结果不一样，那是因为在实践过程中方法不够好。或者说你对你为什么做对了、为什么做错了没有去分析，存在一定的瞎蒙成分。</p><p>假如碰到一个问题，身边的同事解决了，而我解决不了。那么我就去想这个问题他是怎么解决的，他看到这个问题后的逻辑和思考是怎么样的，有哪些知识指导了他这么逻辑推理，这些知识哪些我也知道但是我没有想到这么去运用推理（说明我对这个知识理解的不到位导致灵活运用缺乏）；这些知识中又有哪些是我不知道的（知识缺乏，没什么好说的快去Google什么学习下–有场景案例和目的加持，学习理解起来更快）。</p><p>等你把这个问题基本按照你同事掌握的知识和逻辑推理想明白后，需要再去琢磨一下他的逻辑推理解题思路中有没有不对的，有没有啰嗦的地方，有没有更直接的方式（对知识更好地运用）。</p><p>我相信每个问题都这么去实践的话就不会再抱怨为什么自己做不到灵活运用、举一反三，同时知识也积累下来了，实战场景下积累到的知识是不容易忘记的。</p><p>这就是向身边的牛人学习，同时很快超过他的办法。这就是为什么高考前你做了10套模拟题还不如其他人做一套的效果好的原因</p><p><strong>知识+逻辑 基本等于你的能力</strong>，知识让你知道那个东西，逻辑让你把东西和问题联系起来。碰到问题如果你连相关知识都没有就谈不上解决问题，有时候碰到问题被别人解决后你才发现有相应的知识贮备，但还不能转化成能力，那就是你只是知道那个知识点，但理解不到位、不深，也就无法实战了。</p><p><strong>这里的问题你可以理解成方案、架构、设计等</strong></p><p>逻辑可以理解为：元认知能力(思考方式、思路，像教练一样反复在大脑里追问为什么)</p><p>我们说能力强的人比如在读书的时候，他们读到的不仅仅是文字以及文字所阐述的道理，他们更多注意到j的是作者的“思考方式” ，作者的“思考方式”与自己的“思考方式”之间的不同，以及，若是作者的“思考方式”有可取之处的话，自己的“思考方式”要做出哪些调整？于是，一本概率论读完，大多数人就是考个试也不一定能及格，而另外的极少数人却成了科学家——因为他们改良了自己的思考方式，从此可以“像一个科学家一样思考”……</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/bg2023113016.webp" alt="img"></p><h3 id="系统化的知识哪里来？"><a href="#系统化的知识哪里来？" class="headerlink" title="系统化的知识哪里来？"></a>系统化的知识哪里来？</h3><p>知识之间是可以联系起来的并且像一颗大树一样自我生长，但是当你都没理解透彻，自然没法产生联系，也就不能够自我生长了。当我们讲到入门了某块的知识的时候一般是指的对关键问题点理解清晰，并且能够自我生长，也就是滚雪球一样可以滚起来了。</p><p>但是我们最容易陷入的就是掌握的深度、系统化（工作中碎片时间过多，学校里缺少实践）不够，所以一个知识点每次碰到花半个小时学习下来觉得掌握了，但是3个月后就又没印象了。总是感觉自己在懵懵懂懂中，或者一个领域学起来总是不得要领，根本的原因还是在于：宏观整体大图了解不够（缺乏体系，每次都是盲人摸象）；关键知识点深度不够，理解不透彻，这些关键点就是这个领域的骨架、支点、抓手。缺了抓手自然不能生长，缺了宏观大图容易误入歧途。</p><p>我们有时候发现自己在某个领域学起来特别快，但是换个领域就总是不得要领，问题出在了上面，即使花再多时间也是徒然。这也就是为什么学霸看两个小时的课本比你看两天效果还好，感受下来还觉得别人好聪明，是不是智商比我高啊。</p><p><strong>所以新进入一个领域的时候要去找他的大图和抓手。</strong></p><p>好的书籍或者培训总是能很轻易地把这个大图交给你，再顺便给你几个抓手，你就基本入门了，这就是培训的魅力，这种情况肯定比自学效率高多了。但是目前绝大部分的书籍和培训都做不到这点</p><h3 id="好的逻辑又怎么来？"><a href="#好的逻辑又怎么来？" class="headerlink" title="好的逻辑又怎么来？"></a>好的逻辑又怎么来？</h3><p><strong>实践、复盘</strong></p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/webp-5540564.jpg" alt="img"></p><h2 id="讲个前同事的故事"><a href="#讲个前同事的故事" class="headerlink" title="讲个前同事的故事"></a>讲个前同事的故事</h2><p>有一个前同事是5Q过来的，负责技术（所有解决不了的问题都找他），这位同学从chinaren出道，跟着王兴一块创业5Q，5Q在学校靠鸡腿打下大片市场，最后被陈一舟的校内收购（据说被收购后5Q的好多技术都走了，最后王兴硬是呆在校内网把合约上的所有钱都拿到了）。这位同学让我最佩服的解决问题的能力，好多问题其实他也不一定就擅长，但是他就是有本事通过Help、Google不停地验证尝试就把一个不熟悉的问题给解决了，这是我最羡慕的能力，在后面的职业生涯中一直不停地往这个方面尝试。</p><h3 id="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"><a href="#应用刚启动连接到数据库的时候比较慢，但又不是慢查询" class="headerlink" title="应用刚启动连接到数据库的时候比较慢，但又不是慢查询"></a>应用刚启动连接到数据库的时候比较慢，但又不是慢查询</h3><ol><li>这位同学的解决办法是通过tcpdump来分析网络通讯包，看具体卡在哪里把这个问题硬生生地给找到了。</li><li>如果是专业的DBA可能会通过show processlist 看具体连接在做什么，比如看到这些连接状态是 <strong>authentication</strong> 状态，然后再通过Google或者对这个状态的理解知道创建连接的时候MySQL需要反查IP、域名这里比较耗时，通过配置参数 <strong>skip-name-resolve</strong> 跳过去就好了。</li><li>如果是MySQL的老司机，一上来就知道 <strong>skip-name-resolve</strong> 这个参数要改改默认值。</li></ol><p>在我眼里这三种方式都解决了问题，最后一种最快但是纯靠积累和经验，换个问题也许就不灵了；第一种方式是最牛逼和通用的，只需要最少的业务知识+方法论就可以更普遍地解决各种问题。</p><p>我当时跟着他从sudo、ls等linux命令开始学起。当然我不会轻易去打搅他问他，每次碰到问题我尽量让他在我的电脑上来操作，解决后我<strong>再自己复盘，通过history调出他的所有操作记录，看他在我的电脑上用Google搜啥了，然后一个个去学习分析他每个动作，去想他为什么搜这个关键字，复盘完还有不懂的再到他面前跟他面对面的讨论他为什么要这么做，指导他这么做的知识和逻辑又是什么</strong>（这个动作没有任何难度吧，你照着做就是了，实际我发现绝对不会有10%的同学会去分析history的，而我则是通过history 搞到了各种黑科技 :) ）。</p><h2 id="场景式学习、体感的来源、面对问题学习"><a href="#场景式学习、体感的来源、面对问题学习" class="headerlink" title="场景式学习、体感的来源、面对问题学习"></a>场景式学习、体感的来源、面对问题学习</h2><p>前面提到的对知识的深入理解这有点空，如何才能做到深入理解？</p><h3 id="举个学习TCP三次握手例子"><a href="#举个学习TCP三次握手例子" class="headerlink" title="举个学习TCP三次握手例子"></a>举个学习TCP三次握手例子</h3><p>经历稍微丰富点的工程师都觉得TCP三次握手看过很多次、很多篇文章了，但是文章写得再好似乎当时理解了，但是总是过几个月就忘了或者一看就懂，过一阵子被人一问就模模糊糊了，或者多问两个为什么就答不上了，自己都觉得自己的回答是在猜或者不确定。</p><p>为什么会这样呢？而学其它知识就好通畅多了，我觉得这里最主要的是我们对TCP缺乏<strong>体感</strong>，比如没有几个工程师去看过TCP握手的代码，也没法想象真正的TCP握手是如何在电脑里运作的（打电话能给你一些类似的体感，但是细节覆盖面不够）。</p><p>如果这个时候你一边学习的时候一边再用wireshark抓包看看三次握手具体在干什么、交换了什么信息，比抽象的描述具象实在多了，你能看到握手的一来一回，并且看到一来一回带了哪些内容，这些内容又是用来做什么、为什么要带，这个时候你再去看别人讲解的理论顿时会觉得好理解多了，以后也很难忘记。</p><p>但是这里很多人执行能力不强，想去抓包，但是觉得要下载安装wireshark，要学习wireshark就放弃了。<strong>只看不动手当然是最舒适的，但是这个最舒适给了你在学习的假象，没有结果</strong>。</p><p>这是不是跟你要解决一个难题非常像，这个难题需要你去做很多事，比如下载源代码（翻不了墙，放弃）；比如要编译（还要去学习那些编译参数，放弃）；比如要搭建环境（太琐屑，放弃）。你看这中间九九八十一难你放弃了一难都取不了真经。这也是为什么同样学习、同样的问题，他能学会，他能解决，你不可以。</p><p><img src="https://cdn.jsdelivr.net/gh/plantegg/plantegg.github.io/images/951413iMgBlog/167211888bc4f2a368df3d16c68e6d51.png" alt="167211888bc4f2a368df3d16c68e6d51.png"></p><h2 id="空洞的口号"><a href="#空洞的口号" class="headerlink" title="空洞的口号"></a>空洞的口号</h2><p>很多文章都会教大家：举一反三、灵活运用、活学活用、多做多练。但是只有这些口号是没法落地的，落地的基本原则就是前面提到的，却总是被忽视了。</p><p>还有些人做事情第六感很好，他自己也不一定能阐述清楚合理的逻辑，就是感觉对了，让他给你讲道理，你还真学不来。</p><p>我这里主要是在描述<strong>能复制的一些具体做法</strong>，少喊些放哪里都正确的口号。不要那些抽象的套路，主要是不一定适合你和能复制。</p><h2 id="什么是工程效率，什么是知识效率"><a href="#什么是工程效率，什么是知识效率" class="headerlink" title="什么是工程效率，什么是知识效率"></a>什么是工程效率，什么是知识效率</h2><p>有些人纯看理论就能掌握好一门技能，还能举一反三，这是知识效率，这种人非常少；</p><p>大多数普通人都是看点知识然后结合实践来强化理论，要经过反反复复才能比较好地掌握一个知识，这就是工程效率，讲究技巧、工具来达到目的。</p><p>肯定知识效率最牛逼，但是拥有这种技能的人毕竟非常少（天生的高智商吧）。从小我们周边那种不怎么学的学霸型基本都是这类，这种学霸都还能触类旁通非常快的掌握一个新知识，非常气人。剩下的绝大部分只能拼时间+方法+总结等也能掌握一些知识</p><p>非常遗憾我就是工程效率型，只能羡慕那些知识效率型的学霸。但是这事又不能独立看待有些人在某些方向上是工程效率型，有些方向就又是知识效率型（有一种知识效率型是你掌握的实在太多也就比较容易触类旁通了，这算灰色知识效率型）</p><p>使劲挖掘自己在知识效率型方面的能力吧，两者之间当然没有明显的界限，知识积累多了逻辑训练好了在别人看来你的智商就高了</p><h2 id="知识分两种"><a href="#知识分两种" class="headerlink" title="知识分两种"></a>知识分两种</h2><p>一种是通用知识（不是说对所有人通用，而是说在一个专业领域去到哪个公司都能通用）；另外一种是跟业务公司绑定的特定知识</p><p>通用知识没有任何疑问碰到后要非常饥渴地扑上去掌握他们（受益终生，这还有什么疑问吗？）。对于特定知识就要看你对业务需要掌握的深度了，肯定也是需要掌握一些的，特定知识掌握好的一般在公司里混的也会比较好</p><p>这篇文章我最喜欢的一条评论是：</p><blockquote><p>看完深有感触，尤其是后面的知识效率和工程效率型的区别。以前总是很中二的觉得自己看一遍就理解记住了，结果一次次失败又怀疑自己的智商是不是有问题，其实就是把自己当作知识效率型来用了。一个不太恰当的形容就是，有颗公主心却没公主命！</p></blockquote><p>我喜欢这条评论是很真实地说出来我们平时总是高估自己然后浪费了精力</p><h2 id="案例学习的例子"><a href="#案例学习的例子" class="headerlink" title="案例学习的例子"></a>案例学习的例子</h2><p>通过一个小问题，花上一周看源代码、做各种实验反复验证，把这里涉及到的知识全部拿下，同时把业务代码、内核配置、出问题的表征、监控指标等等都连贯起来，<strong>要么不做要么一杆到底</strong>： <a href="https://plantegg.github.io/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></p><h2 id="进一步阅读"><a href="#进一步阅读" class="headerlink" title="进一步阅读"></a>进一步阅读</h2><p>如果喜欢本文的话，你也会喜欢我亲身经历的：<a href="https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/">《三个故事》</a></p><h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>大家都知道贷款有等额本息、等额本金两种还款方式，网上到处流传等额本金划得来因为利息少，等额本息提前还贷划不来，尤其是已经还了10年了提前还贷就划不来！</p><p>任务：你可以先去搜索什么是等额本息、等额本金这两概念入手，然后去计算第一个月、第二个月的利息是怎么计算的(从具体到抽象)，然后再思考：</p><ol><li>无论哪种还贷方式利率是不是一样——肯定一样的，贷款利率和还贷方式无关</li><li>等额本息你多还了利息是因为什么？</li><li>提前还贷跟时间有没有关系？(换个说法：你第一个月还的利息有没有替10年后还？)</li></ol><p>结果：你一次把概念搞清楚，然后通过一个很具体的第一个月、第二个月(不行你就多迭代几个月)来强化你对当月利息是怎么产生的理论：当月所欠本金*利率 。利率固定不变就不存在划不划得来，你看没有人跟你说借100万划得来、借200万就划不来这个概念吧，只会跟你说年华5%的房贷划不来有点高，年化3%的房贷很划得来</p><p>进阶：你把这个概念完全理解后再去看分期付款、保险划不划得来就很容易了</p><p>你看所有核心知识就是每个月的利息怎么计算的这一个小学知识的概念，但是居然搞出这么多包装概念把大家搞糊涂了</p><h2 id="如果你觉得看完对你很有帮助可以通过如下方式找到我"><a href="#如果你觉得看完对你很有帮助可以通过如下方式找到我" class="headerlink" title="如果你觉得看完对你很有帮助可以通过如下方式找到我"></a>如果你觉得看完对你很有帮助可以通过如下方式找到我</h2><p>find me on twitter: <a href="https://twitter.com/plantegg" target="_blank" rel="noopener">@plantegg</a></p><p>知识星球：<a href="https://t.zsxq.com/0cSFEUh2J" target="_blank" rel="noopener">https://t.zsxq.com/0cSFEUh2J</a></p><p>开了一个星球，在里面讲解一些案例、知识、学习方法，肯定没法让大家称为顶尖程序员(我自己都不是)，只是希望用我的方法、知识、经验、案例作为你的垫脚石，帮助你快速、早日成为一个基本合格的程序员。</p><p>争取在星球内：</p><ul><li>养成基本动手能力</li><li>拥有起码的分析推理能力–按我接触的程序员，大多都是没有逻辑的</li><li>知识上教会你几个关键的知识点</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;如何在工作中学习&quot;&gt;&lt;a href=&quot;#如何在工作中学习&quot; class=&quot;headerlink&quot; title=&quot;如何在工作中学习&quot;&gt;&lt;/a&gt;如何在工作中学习&lt;/h1&gt;&lt;p&gt;大家平时都看过很多方法论的文章，看的时候很爽觉得非常有用，但是一两周后基本还是老样子了。其中
      
    
    </summary>
    
      <category term="技巧" scheme="https://plantegg.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="实践" scheme="https://plantegg.github.io/tags/%E5%AE%9E%E8%B7%B5/"/>
    
      <category term="复盘" scheme="https://plantegg.github.io/tags/%E5%A4%8D%E7%9B%98/"/>
    
      <category term="逻辑" scheme="https://plantegg.github.io/tags/%E9%80%BB%E8%BE%91/"/>
    
      <category term="知识积累" scheme="https://plantegg.github.io/tags/%E7%9F%A5%E8%AF%86%E7%A7%AF%E7%B4%AF/"/>
    
  </entry>
  
</feed>
