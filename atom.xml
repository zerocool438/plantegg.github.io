<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>plantegg</title>
  <subtitle>java tcp mysql performance network docker Linux</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://plantegg.github.io/"/>
  <updated>2023-03-31T05:55:11.223Z</updated>
  <id>https://plantegg.github.io/</id>
  
  <author>
    <name>twitter @plantegg</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>关于本博</title>
    <link href="https://plantegg.github.io/2117/06/07/%E5%85%B3%E4%BA%8E%E6%9C%AC%E5%8D%9A/"/>
    <id>https://plantegg.github.io/2117/06/07/关于本博/</id>
    <published>2117-06-07T10:30:03.000Z</published>
    <updated>2023-03-31T05:55:11.223Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于本博"><a href="#关于本博" class="headerlink" title="关于本博"></a>关于本博</h2><p>find me on twitter: <a href="https://twitter.com/plantegg" target="_blank" rel="external">@plantegg</a></p>
<p>知识星球：<a href="https://t.zsxq.com/0cSFEUh2J" target="_blank" rel="external">https://t.zsxq.com/0cSFEUh2J</a></p>
<p>Github: <a href="https://github.com/plantegg/programmer_case" target="_blank" rel="external">欢迎star</a> </p>
<p>关注基础知识，一次把问题搞清楚，从案例出发深挖相关知识。</p>
<p>以前觉得自己一看就懂，实际是一问就打鼓，一用就糊涂。所以现在开始记录并总结再联系案例，一般是先把零散知识记录下来（看到过），慢慢地相关知识积累更多，直到碰到实践案例或是有点领悟到于是发现这块知识可以整理成一篇系统些的文章（基本快懂了）。</p>
<p>“技术变化太快，容易过时”，我的看法是网络知识、操作系统、计算机原理等核心概念知识的寿命会比你的职业生涯还长。这些都是40岁之后还会还会很有用</p>
<p><a href="https://plantegg.github.io/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 所有方法我都记录在这篇文章中了，希望对你能有所帮助。</p>
<p>所有新文章从<a href="https://plantegg.github.io/archives">这里可以看到</a>，即使再简单的一篇总结我可以持续总结三五年，有新的发现、感悟都是直接在原文上增减，不会发表新的文章。</p>
<p><img src="/images/951413iMgBlog/image-20220421102225491.png" alt="image-20220421102225491"></p>
<p>为什么写博客而不是公众号，我见过20年前的互联网，深度依赖搜索引擎，所以还是喜欢博客。另外技术类文章更适合电脑阅读（随时摘录、实验）</p>
<h2 id="精华文章推荐"><a href="#精华文章推荐" class="headerlink" title="精华文章推荐"></a>精华文章推荐</h2><h4 id="在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇-MySQL-–-The-MySQL-“swap-insanity”-problem-and-the-effects-of-the-NUMA-architecture-http-blog-jcole-us-2010-09-28-mysql-swap-insanity-and-the-numa-architecture-文章描述了性能问题的原因-文章中把原因找错了-以及解决方案：关闭NUMA。-实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https-github-com-torvalds-linux-commit-4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。"><a href="#在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇-MySQL-–-The-MySQL-“swap-insanity”-problem-and-the-effects-of-the-NUMA-architecture-http-blog-jcole-us-2010-09-28-mysql-swap-insanity-and-the-numa-architecture-文章描述了性能问题的原因-文章中把原因找错了-以及解决方案：关闭NUMA。-实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https-github-com-torvalds-linux-commit-4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。" class="headerlink" title="在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/ 文章描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。"></a><a href="https://plantegg.github.io/2021/05/14/%E5%8D%81%E5%B9%B4%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E4%B8%8D%E6%95%A2%E6%8B%A5%E6%8A%B1NUMA/">在2010年前后MySQL、PG、Oracle数据库在使用NUMA的时候碰到了性能问题，流传最广的这篇  MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/ 文章描述了性能问题的原因(文章中把原因找错了)以及解决方案：关闭NUMA。 实际这个原因是kernel实现的一个低级bug，这个Bug在2014年修复了https://github.com/torvalds/linux/commit/4f9b16a64753d0bb607454347036dc997fd03b82，但是修复这么多年后仍然以讹传讹，这篇文章希望正本清源、扭转错误的认识。</a></h4><p><img src="/images/951413iMgBlog/image-20210517082233798.png" alt="image-20210517082233798"></p>
<h4 id="CPU的制造和概念-从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache-line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。"><a href="#CPU的制造和概念-从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache-line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。" class="headerlink" title="CPU的制造和概念 从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。"></a><a href="https://plantegg.github.io/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a> 从最底层的沙子开始用8篇文章来回答关于CPU的各种疑问以及大量的实验对比案例和测试数据来展示了CPU的各种原理，比如多核、超线程、NUMA、睿频、功耗、GPU、大小核再到分支预测、cache_line失效、加锁代价、IPC等各种指标（都有对应的代码和测试数据）。</h4><p><img src="/images/951413iMgBlog/image-20210802161410524-1011377.png" alt="image-20210802161410524"> </p>
<h4 id="《Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》-从一个参数引起的rt抖动定位到OS锁等待再到CPU-Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大"><a href="#《Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》-从一个参数引起的rt抖动定位到OS锁等待再到CPU-Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大" class="headerlink" title="《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大"></a><a href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">《Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的》 从一个参数引起的rt抖动定位到OS锁等待再到CPU Pause指令，以及不同CPU型号对Pause使用cycles不同的影响，最终反馈到应用层面的rt全过程。在MySQL内核开发的时候考虑了Pause，但是没有考虑不同的CPU型号，所以换了CPU型号后性能差异比较大</a></h4><p><img src="/images/oss/d567449fe52725a9d0b9d4ec9baa372c.png" alt="image.png"></p>
<h4 id="10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。"><a href="#10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。" class="headerlink" title="10倍性能提升全过程 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。"></a><a href="https://plantegg.github.io/2018/01/23/10+%E5%80%8D%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E5%85%A8%E8%BF%87%E7%A8%8B/">10倍性能提升全过程</a> 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，一次全栈性能优化过程的详细记录和分析。</h4><p><img src="/images/oss/05703c168e63e96821ea9f921d83712b.png" alt="image.png"></p>
<h4 id="就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET"><a href="#就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET" class="headerlink" title="就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET"></a><a href="https://plantegg.github.io/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">就是要你懂TCP–半连接队列和全连接队列：偶发性的连接reset异常、重启服务后短时间的连接异常，通过一篇文章阐明TCP连接的半连接队列和全连接队大小是怎么影响连接创建的，以及用什么工具来观察队列有没有溢出、连接为什么会RESET</a></h4><p><img src="/images/oss/1579241362064-807d8378-6c54-4a2c-a888-ff2337df817c.png" alt="image.png" style="zoom:80%;"></p>
<h4 id="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的"><a href="#就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的" class="headerlink" title="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的"></a><a href="https://plantegg.github.io/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a></h4><p><img src="/images/oss/e177d59ecb886daef5905ed80a84dfd2.png" alt=""></p>
<h4 id="就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。-同时可以跟讲这块的RFC1180比较一下，RFC1180-写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90-的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用"><a href="#就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。-同时可以跟讲这块的RFC1180比较一下，RFC1180-写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90-的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用" class="headerlink" title="就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。  同时可以跟讲这块的RFC1180比较一下，RFC1180 写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90%的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用"></a><a href="https://plantegg.github.io/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">就是要你懂网络–一个网络包的旅程：教科书式地阐述书本中的路由、网关、子网、Mac地址、IP地址是如何一起协作让网络包最终传输到目标机器上。</a>  同时可以跟讲这块的<a href="https://tools.ietf.org/html/rfc1180" target="_blank" rel="external">RFC1180</a>比较一下，RFC1180 写的确实很好，清晰简洁，图文并茂，结构逻辑合理，但是对于90%的程序员没有什么卵用，看完几周后就忘得差不多，因为他不是从实践的角度来阐述问题，中间没有很多为什么，所以一般资质的程序员看完当时感觉很好，实际还是不会灵活运用</h4><p><img src="/images/oss/8f5d8518c1d92ed68d23218028e3cd11.png" alt=""></p>
<h4 id="国产CPU和Intel、AMD性能PK-从Intel、AMD、海光、鲲鹏920、飞腾2500-等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响"><a href="#国产CPU和Intel、AMD性能PK-从Intel、AMD、海光、鲲鹏920、飞腾2500-等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响" class="headerlink" title="国产CPU和Intel、AMD性能PK 从Intel、AMD、海光、鲲鹏920、飞腾2500 等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响"></a><a href="https://plantegg.github.io/2022/01/13/%E4%B8%8D%E5%90%8CCPU%E6%80%A7%E8%83%BD%E5%A4%A7PK/">国产CPU和Intel、AMD性能PK</a> 从Intel、AMD、海光、鲲鹏920、飞腾2500 等CPU在TPCC、sysbench下的性能对比来分析他们的性能差距，同时分析内存延迟对性能的影响</h4><p><img src="/images/951413iMgBlog/image-20220319115644219.png" alt="image-20220319115644219"></p>
<h4 id="从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》"><a href="#从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》" class="headerlink" title="从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》"></a><a href="/2019/06/20/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/">从网络路由连通性的原理上来看负载均衡lvs的DR、NAT、FullNAT到底搞了些什么鬼，以及为什么要这么搞，和带来的优缺点：《就是要你懂负载均衡–lvs和转发模式》</a></h4><p><img src="/images/oss/94d55b926b5bb1573c4cab8353428712.png" alt=""></p>
<h4 id="LVS-20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。"><a href="#LVS-20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。" class="headerlink" title="LVS 20倍的负载不均衡，原来是内核的这个Bug，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。"></a><a href="/2019/07/19/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/">LVS 20倍的负载不均衡，原来是内核的这个Bug</a>，这个内核bug现在还在，可以稳定重现，有兴趣的话去重现一下，然后对照源代码以及抓包分析一下就清楚了。</h4><h4 id="就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理"><a href="#就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理" class="headerlink" title="就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">就是要你懂TCP–握手和挥手，不是你想象中三次握手、四次挥手就理解了TCP，本文从握手的本质–握手都做了什么事情、连接的本质是什么等来阐述握手、挥手的原理</a></h4><p><img src="/images/oss/6d66dadecb72e11e3e5ab765c6c3ea2e.png" alt=""></p>
<h4 id="nslookup-OK-but-ping-fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来"><a href="#nslookup-OK-but-ping-fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来" class="headerlink" title="nslookup OK but ping fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来"></a><a href="/2019/01/09/nslookup-OK-but-ping-fail/">nslookup OK but ping fail–看看老司机是如何解决问题的，解决问题的方法肯定比知识点重要多了，同时透过一个问题怎么样通篇来理解一大块知识，让这块原理真正在你的只是提示中扎根下来</a></h4><p><img src="/images/oss/ca466bb6430f1149958ceb41b9ffe591.png" alt=""></p>
<h4 id="如何在工作中学习-一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？"><a href="#如何在工作中学习-一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？" class="headerlink" title="如何在工作中学习 一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？"></a><a href="/2018/05/23/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0/">如何在工作中学习</a> 一篇很土但是很务实可以复制的方法论文章。不要讲举一反三、触类旁通，谁都知道要举一反三、触类旁通，但是为什么我总是不能够举一反三、触类旁通？</h4><h4 id="举三反一–从理论知识到实际问题的推导-坚决不让思路跑偏，如何从一个理论知识点推断可能的问题"><a href="#举三反一–从理论知识到实际问题的推导-坚决不让思路跑偏，如何从一个理论知识点推断可能的问题" class="headerlink" title="举三反一–从理论知识到实际问题的推导 坚决不让思路跑偏，如何从一个理论知识点推断可能的问题"></a><a href="/2020/11/02/举三反一--从理论知识到实际问题的推导/">举三反一–从理论知识到实际问题的推导</a> 坚决不让思路跑偏，如何从一个理论知识点推断可能的问题</h4><h2 id="性能相关（2015-2018年）"><a href="#性能相关（2015-2018年）" class="headerlink" title="性能相关（2015-2018年）"></a>性能相关（2015-2018年）</h2><h4 id="就是要你懂TCP–半连接队列和全连接队列-偶发性的连接reset异常、重启服务后短时间的连接异常"><a href="#就是要你懂TCP–半连接队列和全连接队列-偶发性的连接reset异常、重启服务后短时间的连接异常" class="headerlink" title="就是要你懂TCP–半连接队列和全连接队列  偶发性的连接reset异常、重启服务后短时间的连接异常"></a><a href="/2017/06/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/">就是要你懂TCP–半连接队列和全连接队列</a>  偶发性的连接reset异常、重启服务后短时间的连接异常</h4><h4 id="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的-发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响"><a href="#就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的-发送窗口大小-Buffer-、接收窗口大小-Buffer-对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响" class="headerlink" title="就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的  发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响"></a><a href="/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">就是要你懂TCP–性能和发送接收Buffer的关系：发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响。BDP、RT、带宽对传输速度又是怎么影响的</a>  发送窗口大小(Buffer)、接收窗口大小(Buffer)对TCP传输速度的影响，以及怎么观察窗口对传输速度的影响</h4><h4 id="就是要你懂TCP–性能优化大全"><a href="#就是要你懂TCP–性能优化大全" class="headerlink" title="就是要你懂TCP–性能优化大全"></a><a href="/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%A4%A7%E5%85%A8/">就是要你懂TCP–性能优化大全</a></h4><h4 id="就是要你懂TCP–TCP性能问题-Nagle算法和delay-ack"><a href="#就是要你懂TCP–TCP性能问题-Nagle算法和delay-ack" class="headerlink" title="就是要你懂TCP–TCP性能问题 Nagle算法和delay ack"></a><a href="/2018/06/14/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84TCP%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/">就是要你懂TCP–TCP性能问题</a> Nagle算法和delay ack</h4><h4 id="10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。"><a href="#10倍性能提升全过程-在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。" class="headerlink" title="10倍性能提升全过程 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。"></a><a href="/2018/01/23/10+%E5%80%8D%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E5%85%A8%E8%BF%87%E7%A8%8B/">10倍性能提升全过程</a> 在双11的紧张流程下，将系统tps从500优化到5500，从网络到snat、再到Spring和StackTrace，看看一个性能全栈工程师如何在各种工具加持下发现各种问题的。</h4><h2 id="CPU系列文章（2021年完成）"><a href="#CPU系列文章（2021年完成）" class="headerlink" title="CPU系列文章（2021年完成）"></a>CPU系列文章（2021年完成）</h2><h4 id="CPU的制造和概念"><a href="#CPU的制造和概念" class="headerlink" title="CPU的制造和概念"></a><a href="/2021/06/01/CPU的制造和概念/">CPU的制造和概念</a></h4><h4 id="十年后数据库还是不敢拥抱NUMA？"><a href="#十年后数据库还是不敢拥抱NUMA？" class="headerlink" title="十年后数据库还是不敢拥抱NUMA？"></a><a href="/2021/05/14/十年后数据库还是不敢拥抱NUMA/">十年后数据库还是不敢拥抱NUMA？</a></h4><h4 id="Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"><a href="#Intel-PAUSE指令变化是如何影响自旋锁以及MySQL的性能的" class="headerlink" title="Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的"></a><a href="/2019/12/16/Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的/">Intel PAUSE指令变化是如何影响自旋锁以及MySQL的性能的</a></h4><h4 id="Perf-IPC以及CPU性能"><a href="#Perf-IPC以及CPU性能" class="headerlink" title="Perf IPC以及CPU性能"></a><a href="/2021/05/16/Perf IPC以及CPU利用率/">Perf IPC以及CPU性能</a></h4><h4 id="CPU性能和CACHE"><a href="#CPU性能和CACHE" class="headerlink" title="CPU性能和CACHE"></a><a href="https://plantegg.github.io/2021/07/19/CPU性能和CACHE/">CPU性能和CACHE</a></h4><h4 id="CPU-性能和Cache-Line"><a href="#CPU-性能和Cache-Line" class="headerlink" title="CPU 性能和Cache Line"></a><a href="/2021/05/16/CPU Cache Line 和性能/">CPU 性能和Cache Line</a></h4><h4 id="AMD-Zen-CPU-架构-以及-AMD、海光、Intel、鲲鹏的性能对比"><a href="#AMD-Zen-CPU-架构-以及-AMD、海光、Intel、鲲鹏的性能对比" class="headerlink" title="AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比"></a><a href="/2021/08/13/AMD_Zen_CPU架构/">AMD Zen CPU 架构 以及 AMD、海光、Intel、鲲鹏的性能对比</a></h4><h4 id="Intel、海光、鲲鹏920、飞腾2500-CPU性能对比"><a href="#Intel、海光、鲲鹏920、飞腾2500-CPU性能对比" class="headerlink" title="Intel、海光、鲲鹏920、飞腾2500 CPU性能对比"></a><a href="/2021/06/18/几款CPU性能对比/">Intel、海光、鲲鹏920、飞腾2500 CPU性能对比</a></h4><h2 id="网络相关基础知识（2017年完成）"><a href="#网络相关基础知识（2017年完成）" class="headerlink" title="网络相关基础知识（2017年完成）"></a>网络相关基础知识（2017年完成）</h2><h4 id="就是要你懂网络–一个网络包的旅程"><a href="#就是要你懂网络–一个网络包的旅程" class="headerlink" title="就是要你懂网络–一个网络包的旅程"></a><a href="/2019/05/15/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%97%85%E7%A8%8B/">就是要你懂网络–一个网络包的旅程</a></h4><h4 id="通过案例来理解MSS、MTU等相关TCP概念"><a href="#通过案例来理解MSS、MTU等相关TCP概念" class="headerlink" title="通过案例来理解MSS、MTU等相关TCP概念"></a><a href="/2018/05/07/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E9%80%9A%E8%BF%87%E6%A1%88%E4%BE%8B%E6%9D%A5%E5%AD%A6%E4%B9%A0MSS%E3%80%81MTU/">通过案例来理解MSS、MTU等相关TCP概念</a></h4><h4 id="就是要你懂TCP–握手和挥手"><a href="#就是要你懂TCP–握手和挥手" class="headerlink" title="就是要你懂TCP–握手和挥手"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8F%A1%E6%89%8B/">就是要你懂TCP–握手和挥手</a></h4><h4 id="wireshark-dup-ack-issue-and-keepalive"><a href="#wireshark-dup-ack-issue-and-keepalive" class="headerlink" title="wireshark-dup-ack-issue and keepalive"></a><a href="/2017/06/02/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--wireshark-dup-ack-issue/">wireshark-dup-ack-issue and keepalive</a></h4><h4 id="一个没有遵守tcp规则导致的问题"><a href="#一个没有遵守tcp规则导致的问题" class="headerlink" title="一个没有遵守tcp规则导致的问题"></a><a href="/2018/11/26/%E4%B8%80%E4%B8%AA%E6%B2%A1%E6%9C%89%E9%81%B5%E5%AE%88tcp%E8%A7%84%E5%88%99%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/">一个没有遵守tcp规则导致的问题</a></h4><h4 id="kubernetes-service-和-kube-proxy详解"><a href="#kubernetes-service-和-kube-proxy详解" class="headerlink" title="kubernetes service 和 kube-proxy详解"></a><a href="/2020/09/22/kubernetes service 和 kube-proxy详解/">kubernetes service 和 kube-proxy详解</a></h4><h2 id="DNS相关"><a href="#DNS相关" class="headerlink" title="DNS相关"></a>DNS相关</h2><h4 id="就是要你懂DNS–一文搞懂域名解析相关问题"><a href="#就是要你懂DNS–一文搞懂域名解析相关问题" class="headerlink" title="就是要你懂DNS–一文搞懂域名解析相关问题"></a><a href="/2019/06/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">就是要你懂DNS–一文搞懂域名解析相关问题</a></h4><h4 id="nslookup-OK-but-ping-fail"><a href="#nslookup-OK-but-ping-fail" class="headerlink" title="nslookup OK but ping fail"></a><a href="/2019/01/09/nslookup-OK-but-ping-fail/">nslookup OK but ping fail</a></h4><h4 id="Docker中的DNS解析过程"><a href="#Docker中的DNS解析过程" class="headerlink" title="Docker中的DNS解析过程"></a><a href="/2019/01/12/Docker%E4%B8%AD%E7%9A%84DNS%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B/">Docker中的DNS解析过程</a></h4><h4 id="windows7的wifi总是报DNS域名异常无法上网"><a href="#windows7的wifi总是报DNS域名异常无法上网" class="headerlink" title="windows7的wifi总是报DNS域名异常无法上网"></a><a href="/2019/01/10/windows7%E7%9A%84wifi%E6%80%BB%E6%98%AF%E6%8A%A5DNS%E5%9F%9F%E5%90%8D%E5%BC%82%E5%B8%B8%E6%97%A0%E6%B3%95%E4%B8%8A%E7%BD%91/">windows7的wifi总是报DNS域名异常无法上网</a></h4><h2 id="LVS-负载均衡"><a href="#LVS-负载均衡" class="headerlink" title="LVS 负载均衡"></a>LVS 负载均衡</h2><h4 id="就是要你懂负载均衡–lvs和转发模式"><a href="#就是要你懂负载均衡–lvs和转发模式" class="headerlink" title="就是要你懂负载均衡–lvs和转发模式"></a><a href="/2019/06/20/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--lvs%E5%92%8C%E8%BD%AC%E5%8F%91%E6%A8%A1%E5%BC%8F/">就是要你懂负载均衡–lvs和转发模式</a></h4><h4 id="就是要你懂负载均衡–负载均衡调度算法和为什么不均衡"><a href="#就是要你懂负载均衡–负载均衡调度算法和为什么不均衡" class="headerlink" title="就是要你懂负载均衡–负载均衡调度算法和为什么不均衡"></a><a href="/2019/07/19/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1--%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9D%87%E8%A1%A1/">就是要你懂负载均衡–负载均衡调度算法和为什么不均衡</a></h4><h2 id="网络工具"><a href="#网络工具" class="headerlink" title="网络工具"></a>网络工具</h2><h4 id="就是要你懂Unix-Socket-进行抓包解析"><a href="#就是要你懂Unix-Socket-进行抓包解析" class="headerlink" title="就是要你懂Unix Socket 进行抓包解析"></a><a href="/2018/01/01/%E9%80%9A%E8%BF%87tcpdump%E5%AF%B9Unix%20Socket%20%E8%BF%9B%E8%A1%8C%E6%8A%93%E5%8C%85%E8%A7%A3%E6%9E%90/">就是要你懂Unix Socket 进行抓包解析</a></h4><h4 id="就是要你懂网络监控–ss用法大全"><a href="#就是要你懂网络监控–ss用法大全" class="headerlink" title="就是要你懂网络监控–ss用法大全"></a><a href="/2016/10/12/ss%E7%94%A8%E6%B3%95%E5%A4%A7%E5%85%A8/">就是要你懂网络监控–ss用法大全</a></h4><h4 id="就是要你懂抓包–WireShark之命令行版tshark"><a href="#就是要你懂抓包–WireShark之命令行版tshark" class="headerlink" title="就是要你懂抓包–WireShark之命令行版tshark"></a><a href="/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">就是要你懂抓包–WireShark之命令行版tshark</a></h4><h4 id="netstat-timer-keepalive-explain"><a href="#netstat-timer-keepalive-explain" class="headerlink" title="netstat timer keepalive explain"></a><a href="/2017/08/28/netstat%20%E7%AD%89%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/">netstat timer keepalive explain</a></h4><h4 id="Git-HTTP-Proxy-and-SSH-Proxy"><a href="#Git-HTTP-Proxy-and-SSH-Proxy" class="headerlink" title="Git HTTP Proxy and SSH Proxy"></a><a href="/2018/03/14/%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEgit%20Proxy/">Git HTTP Proxy and SSH Proxy</a></h4>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;关于本博&quot;&gt;&lt;a href=&quot;#关于本博&quot; class=&quot;headerlink&quot; title=&quot;关于本博&quot;&gt;&lt;/a&gt;关于本博&lt;/h2&gt;&lt;p&gt;find me on twitter: &lt;a href=&quot;https://twitter.com/plantegg&quot; tar
    
    </summary>
    
      <category term="others" scheme="https://plantegg.github.io/categories/others/"/>
    
    
      <category term="performance" scheme="https://plantegg.github.io/tags/performance/"/>
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="LVS" scheme="https://plantegg.github.io/tags/LVS/"/>
    
      <category term="tcpdump" scheme="https://plantegg.github.io/tags/tcpdump/"/>
    
      <category term="TCP queue" scheme="https://plantegg.github.io/tags/TCP-queue/"/>
    
  </entry>
  
  <entry>
    <title>必读 成长路径</title>
    <link href="https://plantegg.github.io/2024/02/20/%E5%BF%85%E8%AF%BB%20%E6%98%9F%E7%90%83%E6%88%90%E9%95%BF%E8%B7%AF%E5%BE%84/"/>
    <id>https://plantegg.github.io/2024/02/20/必读 星球成长路径/</id>
    <published>2024-02-20T09:30:03.000Z</published>
    <updated>2024-02-23T13:47:32.941Z</updated>
    
    <content type="html"><![CDATA[<h1 id="必读-成长路径"><a href="#必读-成长路径" class="headerlink" title="必读 成长路径"></a>必读 成长路径</h1><p>我的<a href="https://plantegg.github.io/2023/05/10/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%A1%88%E4%BE%8B%E6%98%9F%E7%90%83%E4%BB%8B%E7%BB%8D/">星球介绍</a></p>
<p>这篇是关于我星球里的内容、目标以及如何达到这个目标的一些概述</p>
<h2 id="星球目标"><a href="#星球目标" class="headerlink" title="星球目标"></a>星球目标</h2><p>本星球致力深度分析各种程序员领域疑难案例，通过案例带动对基础核心知识的理解，同时强化动手能力</p>
<p>一年星球没法让大家称为顶尖程序员(我自己都不是)，只是希望用我的方法、知识、经验、案例作为你的垫脚石，帮助你快速、早日成为一个基本合格的程序员。</p>
<h2 id="必会技能"><a href="#必会技能" class="headerlink" title="必会技能"></a>必会技能</h2><p>在星球一年的时间你能学到什么(跟着做一定可以学会的)：</p>
<ul>
<li>网络入门，抓包分析网络能力，wireshark使用 网络篇章索引：<a href="https://articles.zsxq.com/id_jr1w5wvb8j9f.html" target="_blank" rel="external">https://articles.zsxq.com/id_jr1w5wvb8j9f.html</a> </li>
<li><a href="https://t.zsxq.com/17CmWErZB" target="_blank" rel="external">QPS、RT和并发的关系</a>，记住查瓶颈追着 RT跑（哪里RT增加快瓶颈就在哪里）</li>
<li>IPC是什么和性能的本质</li>
<li><a href="https://wx.zsxq.com/dweb2/index/topic_detail/411522214118158" target="_blank" rel="external">养成</a><a href="https://wx.zsxq.com/dweb2/index/topic_detail/411522214118158" target="_blank" rel="external">做会</a><a href="https://wx.zsxq.com/dweb2/index/topic_detail/411522214118158" target="_blank" rel="external">而不是</a><a href="https://wx.zsxq.com/dweb2/index/topic_detail/411522214118158" target="_blank" rel="external">学会</a><a href="https://wx.zsxq.com/dweb2/index/topic_detail/411522214118158" target="_blank" rel="external">的习惯</a></li>
</ul>
<h2 id="视频素材"><a href="#视频素材" class="headerlink" title="视频素材"></a>视频素材</h2><p><strong>如果你发现看文章、做实验有些障碍，我特意录制了视频做演示（如果你基础好，看文章就能看懂并把实验做完，其实没必要看视频）</strong>：<a href="https://articles.zsxq.com/id_blqwkgux7i0a.html" target="_blank" rel="external">https://articles.zsxq.com/id_blqwkgux7i0a.html</a> </p>
<p>视频内容目前已经完成了：</p>
<ul>
<li>抓包技巧演示</li>
<li>QPS、并发、RT 的关系</li>
<li>tcp-rt 展示和在性能定位中的使用</li>
<li>瓶颈定位分析——追着RT 跑</li>
<li>单机内瓶颈定位</li>
<li>认识CPU 和 Cache，以及测试Cache、内存时延</li>
</ul>
<p>我在星球内一直强调视频不是高效的学习方法，因为你没有办法仔细思索、随时前后反复看等等，看完视频容易形成学懂了的错觉实际很快就忘了，但是我录完这些视频看大家的反馈我发现视频也有优点那就是：很直观、门槛低等，但是一定要注意一个错觉：以为看视频看懂了。但实际就是看视频看完了忘得比看文章快多了，所以看完视频一定要再去实验一下，实验所需要的素材基本都在星球内有了，代码等我都放在了github上</p>
<h2 id="挑战技能"><a href="#挑战技能" class="headerlink" title="挑战技能"></a>挑战技能</h2><p>有些技能不好描述，或者说是一些暗知识，我们尽量去讨论这些技能的逻辑，同时对一些特别有效的工具、知识会重点突破，这些恰恰是我希望你们最终能掌握的：</p>
<ul>
<li>分析解决问题的能力，在一定的知识的基础上靠谱地去分析</li>
<li>掌握技能而不是死知识</li>
<li>掌握核心知识点，核心知识点是指理解了一个点很容易对一个领域有较大的突破，比如IPC对于CPU性能、比如内存墙对计算机组成原理的理解、比如RT 对性能瓶颈的定位等</li>
</ul>
<p>知识总是学不完的，况且大多时候我们有了知识也解决不了问题，所以我们更注重能力的训练，比如这个提问：<a href="https://t.zsxq.com/0cfBnpmLw" target="_blank" rel="external">https://t.zsxq.com/0cfBnpmLw</a></p>
<h2 id="节奏安排"><a href="#节奏安排" class="headerlink" title="节奏安排"></a>节奏安排</h2><ul>
<li>一个月完成这一年唯一的一个必做作业：<a href="https://t.zsxq.com/0cUhJcVNa" target="_blank" rel="external">https://t.zsxq.com/0cUhJcVNa</a> 目的体验做会和学会的差别</li>
<li>一个月QPS、并发、RT的关系：<a href="https://t.zsxq.com/0dCmWErZB" target="_blank" rel="external">https://t.zsxq.com/0dCmWErZB</a> 性能、瓶颈定位的最核心理论</li>
<li>一个月补CPU基础，核心可以从内存墙、IPC、NUMA 入手，星球内都有不错的案例，可以查看 CPU 专栏</li>
<li>一个月用来实践性能瓶颈定位，比如就用Sysbench + MySQL 来构造：<a href="https://articles.zsxq.com/id_blqwkgux7i0a.html" target="_blank" rel="external">https://articles.zsxq.com/id_blqwkgux7i0a.html</a> </li>
<li>……补充中</li>
</ul>
<p>如果你发现这个节奏你跟不上，那么就先去<a href="https://articles.zsxq.com/id_blqwkgux7i0a.html" target="_blank" rel="external">看视频</a>，然后再按这个节奏来，如果还不行可以再去看视频，如果视频看不懂可以到微信群里讨论或者就视频里的哪个点提问，如果觉得看懂了，但是还是没法独立实验，那可以这个看懂了还是错觉，或者是基础缺的太多了</p>
<p>请先浏览星球专栏里的必看资源以及学习方法，做到做会而不是看会。另外每个主题后面的留言也很有价值</p>
<p>本星球大部分理论指导部分请看视频：<a href="https://t.zsxq.com/0dF2WvzEF" target="_blank" rel="external">https://t.zsxq.com/0dF2WvzEF</a> (5-10节共90分钟)，视频中的理论要和案例结合</p>
<h2 id="案例选择"><a href="#案例选择" class="headerlink" title="案例选择"></a>案例选择</h2><p>星球选用的案例尽量典型普适性强，代表基础组件基本原理等知识。</p>
<p>分析手段尽量通用，分析过程一定要逻辑合理每个疑问都能回答清晰。</p>
<p>搞清楚一个案例基本能横扫一个领域，其次在一个案例后再带3/5个相关小案例可以帮你丰富场景，多角度理解</p>
<p>基于以上目标一年内选择了如下4个案例：</p>
<ul>
<li>TCP传输性能–对应星球有一年唯一的必做实验让大家上手：<a href="https://t.zsxq.com/0dUhJcVNa" target="_blank" rel="external">https://t.zsxq.com/0dUhJcVNa</a> <strong>目标：动手</strong></li>
<li><a href="https://github.com/plantegg/programmer_case/blame/main/performance/Nginx resueport 导致偶发性卡顿.md" target="_blank" rel="external">历时3年的Nginx卡顿分析</a>–Nginx的架构本身的设计缺陷带来的卡顿，<strong>修复放来来自TCP传输性能，知识之间的联系</strong></li>
<li><a href="https://t.zsxq.com/0f00mI5gF" target="_blank" rel="external">MySQL有的连接一直慢、有的连接一直快，为什么</a>？目的：<strong>Wireshark分析的巧用，这个方法普适性极强</strong></li>
<li>同样的QPS，但CPU使用率相差3倍是为什么。<strong>目标：实现对CPU理解的入门</strong></li>
</ul>
<p>详细描述请看这里：<a href="https://t.zsxq.com/0cyPswpVB" target="_blank" rel="external">https://t.zsxq.com/0cyPswpVB</a></p>
<h2 id="本星球口头禅"><a href="#本星球口头禅" class="headerlink" title="本星球口头禅"></a>本星球口头禅</h2><p><strong>慢就是快，做会而不是看会，无招胜有招</strong></p>
<p>慢就是快指的是不要贪多，而是要彻底搞懂一个问题、一个知识点，让这个点成为一个支柱长成体系，贪多往往啥都没有掌握</p>
<p>做会而不是看会：程序员是工程类(也有科学家，但我们CRUD boy肯定不是)，尤其像网络包、CPU流水线都是看不到无法感受，所以建议你去抓包、去做实验体会、触摸到每个包就能够更好地理解，所以星球强调做案例</p>
<p>无招胜有招：尽量找我普适性强的技能，比如ping ping神功，比如抓包，比如Google搜索，你会反复看到我的案例中使用这些技能</p>
<h2 id="如何在本星球获得成长的基本步骤"><a href="#如何在本星球获得成长的基本步骤" class="headerlink" title="如何在本星球获得成长的基本步骤"></a>如何在本星球获得成长的基本步骤</h2><p>多和以前的学习方式对比，学了一大堆几个月后全忘了，学了很多不会解决问题，学了很多但要靠反复刷。你不应该继续像以前一样忙忙碌碌但是收获很小</p>
<ul>
<li>该买的书买了：<a href="https://t.zsxq.com/0c3P6gpJE" target="_blank" rel="external">https://t.zsxq.com/0c3P6gpJE</a></li>
<li>该做的实验做了:<a href="https://t.zsxq.com/0cUhJcVNa" target="_blank" rel="external">https://t.zsxq.com/0cUhJcVNa</a> ，反复试过后，不懂的尽量提问</li>
<li>该看的视频看过了：<a href="https://articles.zsxq.com/id_blqwkgux7i0a.html" target="_blank" rel="external">https://articles.zsxq.com/id_blqwkgux7i0a.html</a> (实验你能独立完成就不用看视频了)</li>
<li>薅住几个case使劲干，能干多深干多深，看不懂的慢慢想，最好能在工作中找到场景实践一下</li>
<li>学习方法一定要看</li>
<li>不要急于求成，贪多不化，尽量单点突破(就是一个点使劲往深里干)，彻底学懂一个后你会感受到加速</li>
<li>体会到动手做和看书的差异，体会到深度学习案例和看书的差异</li>
<li>不要相信自己看会了，不要相信自己的记忆能力</li>
<li>为什么你有知识但是没有能力：<a href="https://t.zsxq.com/0cfBnpmLw" target="_blank" rel="external">https://t.zsxq.com/0cfBnpmLw</a></li>
<li>养成记笔记，然后总结输出的习惯</li>
<li>必看专栏一定要高优先级先看</li>
</ul>
<p>最好能有自己的总结输出，比如博客文章，写文章是一次最好的总结，不一定要发出来，也不一定一次写完美了，我经常修改7、8年前的文章，因为随着经验的丰富有了更深入、不同的理解，这时不要写一篇新的，我都是在原来的基础上修改、扩充，这才是体系建设</p>
<h2 id="成长案例"><a href="#成长案例" class="headerlink" title="成长案例"></a>成长案例</h2><p>这是大学刚毕业几个月的新同学写的博客：<a href="https://yishenggong.com/2023/05/06/why-does-my-network-speed-drop-cn" target="_blank" rel="external">https://yishenggong.com/2023/05/06/why-does-my-network-speed-drop-cn/</a> </p>
<p><a href="https://yishenggong.com/2023/05/22/is-20m-of-rows-still-a-valid-soft-limit-of-mysql-table-in-2023" target="_blank" rel="external">https://yishenggong.com/2023/05/22/is-20m-of-rows-still-a-valid-soft-limit-of-mysql-table-in-2023/</a> 你可以比较他加入星球前后的博客文章(20230315 加入星球), 第二篇是英文版上了hacker news前三</p>
<p>我观察到的学员成长好习惯：</p>
<ul>
<li>动手动手，不论事情大小先干起来；</li>
<li>有自己的节奏，不贪多先把一篇文章、一个知识点薅扎实了</li>
</ul>
<h2 id="欢迎在星球里提问"><a href="#欢迎在星球里提问" class="headerlink" title="欢迎在星球里提问"></a>欢迎在星球里提问</h2><p>欢迎大家提问，越具体越好</p>
<p>比如这个问题就很具体、很好： <a href="https://t.zsxq.com/0enzptS47" target="_blank" rel="external">https://t.zsxq.com/0enzptS47</a> (千万不要微信上问，回答了也没有价值)</p>
<p>我自己一个人写写出来的东西难免自嗨，但是如果是你碰到的实际业务问题我觉得就更有代表性一些</p>
<p>提问肯定尽力要把问题描述具体，好重现，典型的就是之前 aws 流量降速导致MySQL QPS下降，提问的同学做得特别好的就是把这个问题自己反复分析后发现是网络流量被限速了，然后问题就很容易描述和重现，最后一大帮人帮忙分析问题，最后的结果大家都很开心学到了东西。问题在这里：<a href="https://articles.zsxq.com/id_iq5a872u8sux.html" target="_blank" rel="external">https://articles.zsxq.com/id_iq5a872u8sux.html</a> </p>
<p>你要是通过星球里的方法帮你解决了实际问题这是星球的最终目的，我当然最开心，如果你提了一个你工作中的问题大家一起帮你分析、讨论并最终解决了这就是最好的N对1的私教训练——觉得适合你的能力提升</p>
<p>我有时候绞尽脑汁写了文章然后大家不关心，有时候一个普通问题似乎大家都很嗨，我也喜欢能让你们很嗨的问题(即使我不懂也可以一起讨论)</p>
<h2 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h2><p>必看(一定要看的，我尽量控制必看的少)、实战案例(年度计划一定要分享和搞清楚的案例)、动手实验(做会一直是本星球的重要原则)、学习方法(磨刀不误砍柴工)，剩下的就是按类别分比较好理解</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>星主自我介绍：<a href="https://t.zsxq.com/0c33AXrCi" target="_blank" rel="external">https://t.zsxq.com/0c33AXrCi</a></p>
<p>或者在推特找我：<a href="https://twitter.com/plantegg" target="_blank" rel="external">https://twitter.com/plantegg</a> </p>
<p>个人博客：<a href="https://plantegg.github.io/2022/01/01/三个故事">https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/</a> </p>
<p>博客存放在github，图多的文章会慢一些，可以刷新几次。 </p>
<p>建议大家多用PC版星球( <a href="https://wx.zsxq.com" target="_blank" rel="external">https://wx.zsxq.com</a> )，第一次记住密码后也很方便，主要是打字看图更合适些</p>
<p>画图工具和素材：<a href="https://t.zsxq.com/0enaoOUBp" target="_blank" rel="external">https://t.zsxq.com/0enaoOUBp</a> </p>
<p>知识星球：<a href="https://t.zsxq.com/0cSFEUh2J" target="_blank" rel="external">https://t.zsxq.com/0cSFEUh2J</a> 或者看看星球的介绍：<a href="https://plantegg.github.io/2023/05/10/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%A1%88%E4%BE%8B%E6%98%9F%E7%90%83%E4%BB%8B%E7%BB%8D/">https://plantegg.github.io/2023/05/10/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%A1%88%E4%BE%8B%E6%98%9F%E7%90%83%E4%BB%8B%E7%BB%8D/</a> </p>
<p><img src="/images/951413iMgBlog/image-20230407232314969.png" alt="image-20230407232314969" style="zoom:50%;"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;必读-成长路径&quot;&gt;&lt;a href=&quot;#必读-成长路径&quot; class=&quot;headerlink&quot; title=&quot;必读 成长路径&quot;&gt;&lt;/a&gt;必读 成长路径&lt;/h1&gt;&lt;p&gt;我的&lt;a href=&quot;https://plantegg.github.io/2023/05/10/%
    
    </summary>
    
      <category term="others" scheme="https://plantegg.github.io/categories/others/"/>
    
    
      <category term="星球" scheme="https://plantegg.github.io/tags/%E6%98%9F%E7%90%83/"/>
    
  </entry>
  
  <entry>
    <title>保险</title>
    <link href="https://plantegg.github.io/2024/01/18/%E4%BF%9D%E9%99%A9/"/>
    <id>https://plantegg.github.io/2024/01/18/保险/</id>
    <published>2024-01-18T04:30:03.000Z</published>
    <updated>2024-02-20T09:57:14.866Z</updated>
    
    <content type="html"><![CDATA[<h2 id="保险"><a href="#保险" class="headerlink" title="保险"></a>保险</h2><h2 id="我的观点"><a href="#我的观点" class="headerlink" title="我的观点"></a>我的观点</h2><ol>
<li>不推荐任何理财型保险(你简单认为一年保费过万的都不推荐)</li>
<li>推荐少量消费型的保险(就是那种几乎没人给你推销，一年几百、几千的保费，没事不返还任何钱给你)</li>
<li>不推荐重疾险，回报率低</li>
<li>资源有限就优先给家庭主要收入来源的人买保险，很多人一上来给小孩买，中年男人裸奔，这搞错了</li>
<li>最实惠的保险是相互宝那种，可惜被获利阶层伙同傻逼们干没了</li>
</ol>
<h2 id="理由"><a href="#理由" class="headerlink" title="理由"></a>理由</h2><p>基本逻辑：保险是保意外的，你想赚钱就去买房子、股票、基金、做生意(不是说这几年哈)。消费型的保险(比如人身意外伤害险、车险都算)才是保意外，以小博大，当然也是保的小概率。</p>
<p>任何一个保险扣除运营费用就是返还率，相互宝运营费用10%-8%，大多人没概念，这是极低了，没有营销成本，10%用在理赔的时候调查考证。但是一个理财型的保险20-30% 给一线销售，这就是为什么这些保险人反复、耐心跟你讲要买保险，为你服务，当然这是成本，值不值你自己考虑；这还没完，还有上级、经理、公司的运营工资等，要不保险公司凭什么养那么多领导家属；所以这是保险公司核心收入来源，也必然导致了价格奇高。</p>
<p>理赔很复杂，没事的时候当然好，真要理赔各种你没想到的事前告知，你连我这几百字都不愿意看，保险公司那条款你就更不愿意看了。所以我推荐意外险，死了就陪那种简单些，越复杂的你越搞不懂。卖保险的人是不会跟你说那么清晰的，实际上他自己都搞不清楚，真到了出险才是真正的考验！</p>
<h3 id="一家三口，只买一份保险，假设预算一年5000的话，给谁买？"><a href="#一家三口，只买一份保险，假设预算一年5000的话，给谁买？" class="headerlink" title="一家三口，只买一份保险，假设预算一年5000的话，给谁买？"></a>一家三口，只买一份保险，假设预算一年5000的话，给谁买？</h3><p>肯定是给创造家里主要收入来源那人，保险其实是给活人的福利，你给小朋友买，妈妈挂了，他惨不惨？收入一下子也没了，保险能给他生活费、学费？</p>
<p>如果给妈妈买，你看至少保额还可以供他几年。现在的父母觉得自己有爱、爱娃，当然是给小朋友买，所以我说是错的</p>
<p>你别拿有钱人人都买来扛哈。</p>
<h3 id="为什么不推荐重疾险"><a href="#为什么不推荐重疾险" class="headerlink" title="为什么不推荐重疾险"></a>为什么不推荐重疾险</h3><p>重疾险本来是挺好的，出险直接给钱，是医保外的补充，正如我上面所说赔付率太低了，你还不如把保费存起来，赌概率。</p>
<h3 id="买一年几百的意外险其实是能嫖到一年几万保费的人为你提供服务的"><a href="#买一年几百的意外险其实是能嫖到一年几万保费的人为你提供服务的" class="headerlink" title="买一年几百的意外险其实是能嫖到一年几万保费的人为你提供服务的"></a>买一年几百的意外险其实是能嫖到一年几万保费的人为你提供服务的</h3><p>这个自己想想</p>
<p>保险大家都需要，都希望有，但是保险行业是最需要革命和精简的，比银行还夸张，所以我不会花太多钱补贴这帮蛀得太厉害的蛀虫</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;保险&quot;&gt;&lt;a href=&quot;#保险&quot; class=&quot;headerlink&quot; title=&quot;保险&quot;&gt;&lt;/a&gt;保险&lt;/h2&gt;&lt;h2 id=&quot;我的观点&quot;&gt;&lt;a href=&quot;#我的观点&quot; class=&quot;headerlink&quot; title=&quot;我的观点&quot;&gt;&lt;/a&gt;我的观点&lt;/h
    
    </summary>
    
      <category term="技巧" scheme="https://plantegg.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="保险" scheme="https://plantegg.github.io/tags/%E4%BF%9D%E9%99%A9/"/>
    
  </entry>
  
  <entry>
    <title>几款不同的CPU一些数据--备查</title>
    <link href="https://plantegg.github.io/2023/12/23/%E5%87%A0%E6%AC%BE%E4%B8%8D%E5%90%8C%E7%9A%84CPU%E4%B8%80%E4%BA%9B%E6%95%B0%E6%8D%AE--%E5%A4%87%E6%9F%A5/"/>
    <id>https://plantegg.github.io/2023/12/23/几款不同的CPU一些数据--备查/</id>
    <published>2023-12-23T09:30:03.000Z</published>
    <updated>2024-02-20T09:57:12.437Z</updated>
    
    <content type="html"><![CDATA[<h1 id="几款不同的CPU一些数据–备查"><a href="#几款不同的CPU一些数据–备查" class="headerlink" title="几款不同的CPU一些数据–备查"></a>几款不同的CPU一些数据–备查</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>方便大家对不同的CPU混个脸熟，有个整体概念。本来发布在知识星球，但是知识星球上格式看起来太影响阅读效率了，所以特意拿出来发到博客上</p>
<p>简单查看CPU我一般用 lscpu(默认自带) 命令，或者用复杂点的工具：hwloc 工具安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install hwloc -y</div></pre></td></tr></table></figure>
<p>安装后生成结构图片命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lstopo --logical --output-format png &gt; kunpeng_920.png</div></pre></td></tr></table></figure>
<p>生成字符结构，不要图片：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lstopo-no-graphics</div></pre></td></tr></table></figure>
<p>后面展示的都算是整体机构，所以还会附带有内存怎么接(一个多少条，每条多大，一个Numa node插了几个物理内存条)，这些我博客上都有，就不展开了。一般都是对称的(每个node、socket对称，不对称肯定发挥不出来好性能)</p>
<h2 id="intel-E5-2682"><a href="#intel-E5-2682" class="headerlink" title="intel E5 2682"></a>intel E5 2682</h2><p>大概是Intel 2012年的主流服务器CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                64 //整机总共64核，实际是由32个物理核通过超线程得来</div><div class="line">On-line CPU(s) list:   0-63</div><div class="line">Thread(s) per core:    2 //一个物理核2个超线程</div><div class="line">Core(s) per socket:    16 //每块CPU有16个物理核</div><div class="line">Socket(s):             2 //两路，两块物理上能买到的CPU</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 79</div><div class="line">Model name:            Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2499.902</div><div class="line">CPU max MHz:           3000.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              4999.76</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K //L1 data</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              256K</div><div class="line">L3 cache:              40960K //40M L3,也有人叫 LLC(last level cache), L3是一个socket下所有核共享</div><div class="line">NUMA node0 CPU(s):     0-15,32-47  //node0</div><div class="line">NUMA node1 CPU(s):     16-31,48-63 //node1</div><div class="line"></div><div class="line">//进一步详细看看CPU的结构</div><div class="line">#lstopo-no-graphics </div><div class="line">Machine (512GB) //机器总共512G内存</div><div class="line">  NUMANode L#0 (P#0 256GB) //两路，共两个Numa Node，第一个Node 256G内存</div><div class="line">    Socket L#0 + L3 L#0 (40MB) //Node 0的 L3 40MB，32个逻辑核共享</div><div class="line">      //第一个物理核，每一个物理核都有自己的L2(256KB)和 L1(32KB+32KB), L1分数据、指令两部分</div><div class="line">      L2 L#0 (256KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 </div><div class="line">        PU L#0 (P#0)  //第一个逻辑核</div><div class="line">        PU L#1 (P#32) //第二个逻辑核，这两逻辑核实际是同一个物理核，第二个逻辑核编号是32</div><div class="line"></div><div class="line">      //以下是第二个物理核，都是一样的结构……</div><div class="line">      L2 L#1 (256KB) + L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1</div><div class="line">        PU L#2 (P#1)</div><div class="line">        PU L#3 (P#33)</div><div class="line">      L2 L#2 (256KB) + L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2</div><div class="line">        PU L#4 (P#2)</div><div class="line">        PU L#5 (P#34)</div><div class="line">      L2 L#3 (256KB) + L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3</div><div class="line">        PU L#6 (P#3)</div><div class="line">        PU L#7 (P#35)</div><div class="line">      L2 L#4 (256KB) + L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4</div><div class="line">        PU L#8 (P#4)</div><div class="line">        PU L#9 (P#36)</div><div class="line">      L2 L#5 (256KB) + L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5</div><div class="line">        PU L#10 (P#5)</div><div class="line">        PU L#11 (P#37)</div><div class="line">      L2 L#6 (256KB) + L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6</div><div class="line">        PU L#12 (P#6)</div><div class="line">        PU L#13 (P#38)</div><div class="line">      L2 L#7 (256KB) + L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7</div><div class="line">        PU L#14 (P#7)</div><div class="line">        PU L#15 (P#39)</div><div class="line">      L2 L#8 (256KB) + L1d L#8 (32KB) + L1i L#8 (32KB) + Core L#8</div><div class="line">        PU L#16 (P#8)</div><div class="line">        PU L#17 (P#40)</div><div class="line">      L2 L#9 (256KB) + L1d L#9 (32KB) + L1i L#9 (32KB) + Core L#9</div><div class="line">        PU L#18 (P#9)</div><div class="line">        PU L#19 (P#41)</div><div class="line">      L2 L#10 (256KB) + L1d L#10 (32KB) + L1i L#10 (32KB) + Core L#10</div><div class="line">        PU L#20 (P#10)</div><div class="line">        PU L#21 (P#42)</div><div class="line">      L2 L#11 (256KB) + L1d L#11 (32KB) + L1i L#11 (32KB) + Core L#11</div><div class="line">        PU L#22 (P#11)</div><div class="line">        PU L#23 (P#43)</div><div class="line">      L2 L#12 (256KB) + L1d L#12 (32KB) + L1i L#12 (32KB) + Core L#12</div><div class="line">        PU L#24 (P#12)</div><div class="line">        PU L#25 (P#44)</div><div class="line">      L2 L#13 (256KB) + L1d L#13 (32KB) + L1i L#13 (32KB) + Core L#13</div><div class="line">        PU L#26 (P#13)</div><div class="line">        PU L#27 (P#45)</div><div class="line">      L2 L#14 (256KB) + L1d L#14 (32KB) + L1i L#14 (32KB) + Core L#14</div><div class="line">        PU L#28 (P#14)</div><div class="line">        PU L#29 (P#46)</div><div class="line">      L2 L#15 (256KB) + L1d L#15 (32KB) + L1i L#15 (32KB) + Core L#15</div><div class="line">        PU L#30 (P#15)</div><div class="line">        PU L#31 (P#47)</div><div class="line">    HostBridge L#0</div><div class="line">      PCIBridge</div><div class="line">        PCI 144d:a804</div><div class="line">      PCIBridge</div><div class="line">        PCI 8086:10fb</div><div class="line">          Net L#0 &quot;eth2&quot; //两块PCI 万兆网卡插在Socket0上，所有Socket0上的core访问网络效率更高</div><div class="line">        PCI 8086:10fb</div><div class="line">          Net L#1 &quot;eth3&quot;</div><div class="line">      PCIBridge</div><div class="line">        PCIBridge</div><div class="line">          PCI 1a03:2000</div><div class="line">            GPU L#2 &quot;card0&quot;</div><div class="line">            GPU L#3 &quot;controlD64&quot;</div><div class="line">      PCI 8086:8d02</div><div class="line">        Block L#4 &quot;sda&quot; //sda硬盘</div><div class="line">  NUMANode L#1 (P#1 256GB) //第二路，也就是第二个Node，内存、cache、核都是对称的</div><div class="line">    Socket L#1 + L3 L#1 (40MB)</div><div class="line">      L2 L#16 (256KB) + L1d L#16 (32KB) + L1i L#16 (32KB) + Core L#16</div><div class="line">        PU L#32 (P#16)</div><div class="line">        PU L#33 (P#48)</div><div class="line">      L2 L#17 (256KB) + L1d L#17 (32KB) + L1i L#17 (32KB) + Core L#17</div><div class="line">        PU L#34 (P#17)</div><div class="line">        PU L#35 (P#49)</div><div class="line">      L2 L#18 (256KB) + L1d L#18 (32KB) + L1i L#18 (32KB) + Core L#18</div><div class="line">        PU L#36 (P#18)</div><div class="line">        PU L#37 (P#50)</div><div class="line">      L2 L#19 (256KB) + L1d L#19 (32KB) + L1i L#19 (32KB) + Core L#19</div><div class="line">        PU L#38 (P#19)</div><div class="line">        PU L#39 (P#51)</div><div class="line">      L2 L#20 (256KB) + L1d L#20 (32KB) + L1i L#20 (32KB) + Core L#20</div><div class="line">        PU L#40 (P#20)</div><div class="line">        PU L#41 (P#52)</div><div class="line">      L2 L#21 (256KB) + L1d L#21 (32KB) + L1i L#21 (32KB) + Core L#21</div><div class="line">        PU L#42 (P#21)</div><div class="line">        PU L#43 (P#53)</div><div class="line">      L2 L#22 (256KB) + L1d L#22 (32KB) + L1i L#22 (32KB) + Core L#22</div><div class="line">        PU L#44 (P#22)</div><div class="line">        PU L#45 (P#54)</div><div class="line">      L2 L#23 (256KB) + L1d L#23 (32KB) + L1i L#23 (32KB) + Core L#23</div><div class="line">        PU L#46 (P#23)</div><div class="line">        PU L#47 (P#55)</div><div class="line">      L2 L#24 (256KB) + L1d L#24 (32KB) + L1i L#24 (32KB) + Core L#24</div><div class="line">        PU L#48 (P#24)</div><div class="line">        PU L#49 (P#56)</div><div class="line">      L2 L#25 (256KB) + L1d L#25 (32KB) + L1i L#25 (32KB) + Core L#25</div><div class="line">        PU L#50 (P#25)</div><div class="line">        PU L#51 (P#57)</div><div class="line">      L2 L#26 (256KB) + L1d L#26 (32KB) + L1i L#26 (32KB) + Core L#26</div><div class="line">        PU L#52 (P#26)</div><div class="line">        PU L#53 (P#58)</div><div class="line">      L2 L#27 (256KB) + L1d L#27 (32KB) + L1i L#27 (32KB) + Core L#27</div><div class="line">        PU L#54 (P#27)</div><div class="line">        PU L#55 (P#59)</div><div class="line">      L2 L#28 (256KB) + L1d L#28 (32KB) + L1i L#28 (32KB) + Core L#28</div><div class="line">        PU L#56 (P#28)</div><div class="line">        PU L#57 (P#60)</div><div class="line">      L2 L#29 (256KB) + L1d L#29 (32KB) + L1i L#29 (32KB) + Core L#29</div><div class="line">        PU L#58 (P#29)</div><div class="line">        PU L#59 (P#61)</div><div class="line">      L2 L#30 (256KB) + L1d L#30 (32KB) + L1i L#30 (32KB) + Core L#30</div><div class="line">        PU L#60 (P#30)</div><div class="line">        PU L#61 (P#62)</div><div class="line">      L2 L#31 (256KB) + L1d L#31 (32KB) + L1i L#31 (32KB) + Core L#31</div><div class="line">        PU L#62 (P#31)</div><div class="line">        PU L#63 (P#63)</div><div class="line">    HostBridge L#5</div><div class="line">      PCIBridge</div><div class="line">        PCI 8086:1521</div><div class="line">          Net L#5 &quot;enp130s0f0&quot; //两块PCI 千兆网卡</div><div class="line">        PCI 8086:1521</div><div class="line">          Net L#6 &quot;enp130s0f1&quot;</div><div class="line">      PCIBridge</div><div class="line">        PCI 144d:a804</div><div class="line">      PCIBridge</div><div class="line">        PCI 144d:a804</div></pre></td></tr></table></figure>
<p>intel 还有一个自带的工具：cpuid-topo 可以看结构，以下是其中一个Socket的展示</p>
<p><img src="/images/951413iMgBlog/FnS99B0Zq6MFk3q3iXvU2O2tY4pp.png" alt="img"></p>
<h2 id="海光"><a href="#海光" class="headerlink" title="海光"></a>海光</h2><p>购买的AMD版权设计等搞出来国产的 x86 架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:        x86_64</div><div class="line">CPU op-mode(s):      32-bit, 64-bit</div><div class="line">Byte Order:          Little Endian</div><div class="line">Address sizes:       43 bits physical, 48 bits virtual</div><div class="line">CPU(s):              48</div><div class="line">On-line CPU(s) list: 0-47</div><div class="line">Thread(s) per core:  1 //我故意把超线程关掉了</div><div class="line">Core(s) per socket:  24</div><div class="line">Socket(s):           2</div><div class="line">NUMA node(s):        8</div><div class="line">Vendor ID:           HygonGenuine</div><div class="line">CPU family:          24</div><div class="line">Model:               1</div><div class="line">Model name:          Hygon C86 7260 24-core Processor</div><div class="line">Stepping:            1</div><div class="line">Frequency boost:     enabled</div><div class="line">CPU MHz:             1070.950</div><div class="line">CPU max MHz:         2200.0000</div><div class="line">CPU min MHz:         1200.0000</div><div class="line">BogoMIPS:            4399.54</div><div class="line">Virtualization:      AMD-V</div><div class="line">L1d cache:           1.5 MiB //好大，不符合逻辑，后面解释</div><div class="line">L1i cache:           3 MiB</div><div class="line">L2 cache:            24 MiB  //48个物理核总共24MB L2，但是每个物理核只能用自己的512KB</div><div class="line">L3 cache:            128 MiB // </div><div class="line">NUMA node0 CPU(s):   0-5</div><div class="line">NUMA node1 CPU(s):   6-11</div><div class="line">NUMA node2 CPU(s):   12-17</div><div class="line">NUMA node3 CPU(s):   18-23</div><div class="line">NUMA node4 CPU(s):   24-29</div><div class="line">NUMA node5 CPU(s):   30-35</div><div class="line">NUMA node6 CPU(s):   36-41</div><div class="line">NUMA node7 CPU(s):   42-47 //搞了8个Numa Node</div></pre></td></tr></table></figure>
<p>L1、L2太大了，好吓人，这么大不符合逻辑(太贵，没必要)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">//继续看看L2 为啥这么大</div><div class="line">#cd /sys/devices/system/cpu/cpu0</div><div class="line"></div><div class="line">#ls cache/index2/</div><div class="line">coherency_line_size      number_of_sets           shared_cpu_list          type</div><div class="line">id                       physical_line_partition  shared_cpu_map           uevent</div><div class="line">level                    power/                   size                     ways_of_associativity</div><div class="line"></div><div class="line">#cat cache/index2/size</div><div class="line">512K  //实际是512K， 2M是4个核共享，搞了个花活，但每个核只能用自己的512K</div><div class="line"></div><div class="line">#cat cache/index2/shared_cpu_list</div><div class="line">0  //确认 L2只有自己用</div><div class="line"></div><div class="line">#cat cache/index3/shared_cpu_list</div><div class="line">0-2 //L3 给0-2这3个物理核共享，一个Die下有6个物理核，每三个共享一个8M的L3</div><div class="line"></div><div class="line">#cat cache/index3/size</div><div class="line">8192K //3个物理核共享8M L3</div><div class="line"></div><div class="line">#cat cache/index1/size</div><div class="line">64K</div><div class="line"></div><div class="line">#cat cache/index0/size</div><div class="line">32K</div></pre></td></tr></table></figure>
<p>index0/index1 分别代表啥？</p>
<p>海光为啥搞了8个Node，请看：<a href="https://plantegg.github.io/2021/03/08/%E6%B5%B7%E5%85%89CPU/">https://plantegg.github.io/2021/03/08/%E6%B5%B7%E5%85%89CPU/</a></p>
<p>图片可以看高清大图</p>
<p><img src="/images/951413iMgBlog/Fnv-AneATqzhd3NYlhXEupxJafLF.png" alt="img"></p>
<p>对应的字符结构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div></pre></td><td class="code"><pre><div class="line">#lstopo</div><div class="line">Machine (504GB total)</div><div class="line">  Package L#0</div><div class="line">    NUMANode L#0 (P#0 63GB)</div><div class="line">      L3 L#0 (8192KB)</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (32KB) + L1i L#0 (64KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (32KB) + L1i L#1 (64KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L2 L#2 (512KB) + L1d L#2 (32KB) + L1i L#2 (64KB) + Core L#2 + PU L#2 (P#2)</div><div class="line">      L3 L#1 (8192KB)</div><div class="line">        L2 L#3 (512KB) + L1d L#3 (32KB) + L1i L#3 (64KB) + Core L#3 + PU L#3 (P#3)</div><div class="line">        L2 L#4 (512KB) + L1d L#4 (32KB) + L1i L#4 (64KB) + Core L#4 + PU L#4 (P#4)</div><div class="line">        L2 L#5 (512KB) + L1d L#5 (32KB) + L1i L#5 (64KB) + Core L#5 + PU L#5 (P#5)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCI 1a03:2000</div><div class="line">              GPU L#0 &quot;controlD64&quot;</div><div class="line">              GPU L#1 &quot;card0&quot;</div><div class="line">        PCIBridge</div><div class="line">          PCI 1d94:7901</div><div class="line">            Block(Disk) L#2 &quot;sda&quot;</div><div class="line">    NUMANode L#1 (P#1 63GB)</div><div class="line">      L3 L#2 (8192KB)</div><div class="line">        L2 L#6 (512KB) + L1d L#6 (32KB) + L1i L#6 (64KB) + Core L#6 + PU L#6 (P#6)</div><div class="line">        L2 L#7 (512KB) + L1d L#7 (32KB) + L1i L#7 (64KB) + Core L#7 + PU L#7 (P#7)</div><div class="line">        L2 L#8 (512KB) + L1d L#8 (32KB) + L1i L#8 (64KB) + Core L#8 + PU L#8 (P#8)</div><div class="line">      L3 L#3 (8192KB)</div><div class="line">        L2 L#9 (512KB) + L1d L#9 (32KB) + L1i L#9 (64KB) + Core L#9 + PU L#9 (P#9)</div><div class="line">        L2 L#10 (512KB) + L1d L#10 (32KB) + L1i L#10 (64KB) + Core L#10 + PU L#10 (P#10)</div><div class="line">        L2 L#11 (512KB) + L1d L#11 (32KB) + L1i L#11 (64KB) + Core L#11 + PU L#11 (P#11)</div><div class="line">      HostBridge L#4</div><div class="line">        PCIBridge</div><div class="line">          PCI 1c5f:0557</div><div class="line">            Block(Disk) L#3 &quot;nvme0n1&quot;</div><div class="line">        PCIBridge</div><div class="line">          PCI 1c5f:0557</div><div class="line">            Block(Disk) L#4 &quot;nvme1n1&quot;</div><div class="line">    NUMANode L#2 (P#2 63GB)</div><div class="line">      L3 L#4 (8192KB)</div><div class="line">        L2 L#12 (512KB) + L1d L#12 (32KB) + L1i L#12 (64KB) + Core L#12 + PU L#12 (P#12)</div><div class="line">        L2 L#13 (512KB) + L1d L#13 (32KB) + L1i L#13 (64KB) + Core L#13 + PU L#13 (P#13)</div><div class="line">        L2 L#14 (512KB) + L1d L#14 (32KB) + L1i L#14 (64KB) + Core L#14 + PU L#14 (P#14)</div><div class="line">      L3 L#5 (8192KB)</div><div class="line">        L2 L#15 (512KB) + L1d L#15 (32KB) + L1i L#15 (64KB) + Core L#15 + PU L#15 (P#15)</div><div class="line">        L2 L#16 (512KB) + L1d L#16 (32KB) + L1i L#16 (64KB) + Core L#16 + PU L#16 (P#16)</div><div class="line">        L2 L#17 (512KB) + L1d L#17 (32KB) + L1i L#17 (64KB) + Core L#17 + PU L#17 (P#17)</div><div class="line">      HostBridge L#7</div><div class="line">        PCIBridge</div><div class="line">          PCI 15b3:1015</div><div class="line">            Net L#5 &quot;enp33s0f0&quot;</div><div class="line">            OpenFabrics L#6 &quot;mlx5_0&quot;</div><div class="line">          PCI 15b3:1015</div><div class="line">            Net L#7 &quot;enp33s0f1&quot;</div><div class="line">            OpenFabrics L#8 &quot;mlx5_1&quot;</div><div class="line">    NUMANode L#3 (P#3 63GB)</div><div class="line">      L3 L#6 (8192KB)</div><div class="line">        L2 L#18 (512KB) + L1d L#18 (32KB) + L1i L#18 (64KB) + Core L#18 + PU L#18 (P#18)</div><div class="line">        L2 L#19 (512KB) + L1d L#19 (32KB) + L1i L#19 (64KB) + Core L#19 + PU L#19 (P#19)</div><div class="line">        L2 L#20 (512KB) + L1d L#20 (32KB) + L1i L#20 (64KB) + Core L#20 + PU L#20 (P#20)</div><div class="line">      L3 L#7 (8192KB)</div><div class="line">        L2 L#21 (512KB) + L1d L#21 (32KB) + L1i L#21 (64KB) + Core L#21 + PU L#21 (P#21)</div><div class="line">        L2 L#22 (512KB) + L1d L#22 (32KB) + L1i L#22 (64KB) + Core L#22 + PU L#22 (P#22)</div><div class="line">        L2 L#23 (512KB) + L1d L#23 (32KB) + L1i L#23 (64KB) + Core L#23 + PU L#23 (P#23)</div><div class="line">      HostBridge L#9</div><div class="line">        PCIBridge</div><div class="line">          PCI 8086:1521</div><div class="line">            Net L#9 &quot;eno1&quot;</div><div class="line">          PCI 8086:1521</div><div class="line">            Net L#10 &quot;eno2&quot;</div><div class="line">  Package L#1</div><div class="line">    NUMANode L#4 (P#4 63GB)</div><div class="line">      L3 L#8 (8192KB)</div><div class="line">        L2 L#24 (512KB) + L1d L#24 (32KB) + L1i L#24 (64KB) + Core L#24 + PU L#24 (P#24)</div><div class="line">        L2 L#25 (512KB) + L1d L#25 (32KB) + L1i L#25 (64KB) + Core L#25 + PU L#25 (P#25)</div><div class="line">        L2 L#26 (512KB) + L1d L#26 (32KB) + L1i L#26 (64KB) + Core L#26 + PU L#26 (P#26)</div><div class="line">      L3 L#9 (8192KB)</div><div class="line">        L2 L#27 (512KB) + L1d L#27 (32KB) + L1i L#27 (64KB) + Core L#27 + PU L#27 (P#27)</div><div class="line">        L2 L#28 (512KB) + L1d L#28 (32KB) + L1i L#28 (64KB) + Core L#28 + PU L#28 (P#28)</div><div class="line">        L2 L#29 (512KB) + L1d L#29 (32KB) + L1i L#29 (64KB) + Core L#29 + PU L#29 (P#29)</div><div class="line">    NUMANode L#5 (P#5 63GB)</div><div class="line">      L3 L#10 (8192KB)</div><div class="line">        L2 L#30 (512KB) + L1d L#30 (32KB) + L1i L#30 (64KB) + Core L#30 + PU L#30 (P#30)</div><div class="line">        L2 L#31 (512KB) + L1d L#31 (32KB) + L1i L#31 (64KB) + Core L#31 + PU L#31 (P#31)</div><div class="line">        L2 L#32 (512KB) + L1d L#32 (32KB) + L1i L#32 (64KB) + Core L#32 + PU L#32 (P#32)</div><div class="line">      L3 L#11 (8192KB)</div><div class="line">        L2 L#33 (512KB) + L1d L#33 (32KB) + L1i L#33 (64KB) + Core L#33 + PU L#33 (P#33)</div><div class="line">        L2 L#34 (512KB) + L1d L#34 (32KB) + L1i L#34 (64KB) + Core L#34 + PU L#34 (P#34)</div><div class="line">        L2 L#35 (512KB) + L1d L#35 (32KB) + L1i L#35 (64KB) + Core L#35 + PU L#35 (P#35)</div><div class="line">      HostBridge L#11</div><div class="line">        PCIBridge</div><div class="line">          PCI 1d94:7901</div><div class="line">    NUMANode L#6 (P#6 63GB)</div><div class="line">      L3 L#12 (8192KB)</div><div class="line">        L2 L#36 (512KB) + L1d L#36 (32KB) + L1i L#36 (64KB) + Core L#36 + PU L#36 (P#36)</div><div class="line">        L2 L#37 (512KB) + L1d L#37 (32KB) + L1i L#37 (64KB) + Core L#37 + PU L#37 (P#37)</div><div class="line">        L2 L#38 (512KB) + L1d L#38 (32KB) + L1i L#38 (64KB) + Core L#38 + PU L#38 (P#38)</div><div class="line">      L3 L#13 (8192KB)</div><div class="line">        L2 L#39 (512KB) + L1d L#39 (32KB) + L1i L#39 (64KB) + Core L#39 + PU L#39 (P#39)</div><div class="line">        L2 L#40 (512KB) + L1d L#40 (32KB) + L1i L#40 (64KB) + Core L#40 + PU L#40 (P#40)</div><div class="line">        L2 L#41 (512KB) + L1d L#41 (32KB) + L1i L#41 (64KB) + Core L#41 + PU L#41 (P#41)</div><div class="line">    NUMANode L#7 (P#7 63GB)</div><div class="line">      L3 L#14 (8192KB)</div><div class="line">        L2 L#42 (512KB) + L1d L#42 (32KB) + L1i L#42 (64KB) + Core L#42 + PU L#42 (P#42)</div><div class="line">        L2 L#43 (512KB) + L1d L#43 (32KB) + L1i L#43 (64KB) + Core L#43 + PU L#43 (P#43)</div><div class="line">        L2 L#44 (512KB) + L1d L#44 (32KB) + L1i L#44 (64KB) + Core L#44 + PU L#44 (P#44)</div><div class="line">      L3 L#15 (8192KB)</div><div class="line">        L2 L#45 (512KB) + L1d L#45 (32KB) + L1i L#45 (64KB) + Core L#45 + PU L#45 (P#45)</div><div class="line">        L2 L#46 (512KB) + L1d L#46 (32KB) + L1i L#46 (64KB) + Core L#46 + PU L#46 (P#46)</div><div class="line">        L2 L#47 (512KB) + L1d L#47 (32KB) + L1i L#47 (64KB) + Core L#47 + PU L#47 (P#47)</div><div class="line">  Misc(MemoryModule)</div><div class="line">  Misc(MemoryModule)</div><div class="line">  Misc(MemoryModule)</div></pre></td></tr></table></figure>
<p>以上是海光的7260，还有一个CPU是海光 7280：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    32</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          8</div><div class="line">Vendor ID:             HygonGenuine</div><div class="line">CPU family:            24</div><div class="line">Model:                 1</div><div class="line">Model name:            Hygon C86 7280 32-core Processor</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               1981.025</div><div class="line">CPU max MHz:           2000.0000</div><div class="line">CPU min MHz:           1200.0000</div><div class="line">BogoMIPS:              3999.55</div><div class="line">Virtualization:        AMD-V</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              8192K</div><div class="line">NUMA node0 CPU(s):     0-7,64-71</div><div class="line">NUMA node1 CPU(s):     8-15,72-79</div><div class="line">NUMA node2 CPU(s):     16-23,80-87</div><div class="line">NUMA node3 CPU(s):     24-31,88-95</div><div class="line">NUMA node4 CPU(s):     32-39,96-103</div><div class="line">NUMA node5 CPU(s):     40-47,104-111</div><div class="line">NUMA node6 CPU(s):     48-55,112-119</div><div class="line">NUMA node7 CPU(s):     56-63,120-127</div></pre></td></tr></table></figure>
<p>作业：7260和7280的区别是？为什么搞了这两个差异很小的CPU？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">//继续在7280上看看L3的大小和共享，能够识别他的Die设计理念</div><div class="line"></div><div class="line">//7280上 L3 由8个超线程，也就是4个物理核共享</div><div class="line">#cat cache/index3/shared_cpu_list</div><div class="line">0-3,64-67      //就这里核数不一样</div><div class="line">#cat cache/index3/size</div><div class="line">8192K          //L3大小和7260一样</div></pre></td></tr></table></figure>
<p>还记得7260是3个物理核共享一个8M的L3吧，计算机的世界大多是1、2、4、8，看到3我就觉得有些别扭。评论区告诉我为什么会搞出3个核这样一个奇葩设计？（星球图解专栏里有答案）</p>
<h2 id="AMD-7T83"><a href="#AMD-7T83" class="headerlink" title="AMD 7T83"></a>AMD 7T83</h2><p>整机256核，一路128超线程，单CPU 64个物理核，很猛了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div><div class="line">449</div><div class="line">450</div><div class="line">451</div><div class="line">452</div><div class="line">453</div><div class="line">454</div><div class="line">455</div><div class="line">456</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                256</div><div class="line">On-line CPU(s) list:   0-255</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          4</div><div class="line">Vendor ID:             AuthenticAMD</div><div class="line">CPU family:            25</div><div class="line">Model:                 1</div><div class="line">Model name:            AMD EPYC 7T83 64-Core Processor</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               1638.563    //主频有点低，估计还是核太多了</div><div class="line">CPU max MHz:           2550.0000</div><div class="line">CPU min MHz:           1500.0000</div><div class="line">BogoMIPS:              5090.06</div><div class="line">Virtualization:        AMD-V</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              32768K</div><div class="line">NUMA node0 CPU(s):     0-31,128-159</div><div class="line">NUMA node1 CPU(s):     32-63,160-191</div><div class="line">NUMA node2 CPU(s):     64-95,192-223</div><div class="line">NUMA node3 CPU(s):     96-127,224-255 //这里展示的是4个Node，在Bios中可配置</div><div class="line"></div><div class="line">#lstopo-no-graphics</div><div class="line">Machine (2015GB) //2T 内存</div><div class="line">  Socket L#0 (1007GB) //单路 1T内存，一路下有两个Numa Node</div><div class="line">    NUMANode L#0 (P#0 503GB) //这个Node下有4块独立的L3 </div><div class="line">      L3 L#0 (32MB) //看起来16个超线程共享这一个L3，其实这16个核应该是一个独立的Node比较好</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0</div><div class="line">          PU L#0 (P#0)</div><div class="line">          PU L#1 (P#128)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1</div><div class="line">          PU L#2 (P#1)</div><div class="line">          PU L#3 (P#129)</div><div class="line">        L2 L#2 (512KB) + L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2</div><div class="line">          PU L#4 (P#2)</div><div class="line">          PU L#5 (P#130)</div><div class="line">        L2 L#3 (512KB) + L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3</div><div class="line">          PU L#6 (P#3)</div><div class="line">          PU L#7 (P#131)</div><div class="line">        L2 L#4 (512KB) + L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4</div><div class="line">          PU L#8 (P#4)</div><div class="line">          PU L#9 (P#132)</div><div class="line">        L2 L#5 (512KB) + L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5</div><div class="line">          PU L#10 (P#5)</div><div class="line">          PU L#11 (P#133)</div><div class="line">        L2 L#6 (512KB) + L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6</div><div class="line">          PU L#12 (P#6)</div><div class="line">          PU L#13 (P#134)</div><div class="line">        L2 L#7 (512KB) + L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7</div><div class="line">          PU L#14 (P#7)</div><div class="line">          PU L#15 (P#135)</div><div class="line">      L3 L#1 (32MB)</div><div class="line">        L2 L#8 (512KB) + L1d L#8 (32KB) + L1i L#8 (32KB) + Core L#8</div><div class="line">          PU L#16 (P#8)</div><div class="line">          PU L#17 (P#136)</div><div class="line">        L2 L#9 (512KB) + L1d L#9 (32KB) + L1i L#9 (32KB) + Core L#9</div><div class="line">          PU L#18 (P#9)</div><div class="line">          PU L#19 (P#137)</div><div class="line">        L2 L#10 (512KB) + L1d L#10 (32KB) + L1i L#10 (32KB) + Core L#10</div><div class="line">          PU L#20 (P#10)</div><div class="line">          PU L#21 (P#138)</div><div class="line">        L2 L#11 (512KB) + L1d L#11 (32KB) + L1i L#11 (32KB) + Core L#11</div><div class="line">          PU L#22 (P#11)</div><div class="line">          PU L#23 (P#139)</div><div class="line">        L2 L#12 (512KB) + L1d L#12 (32KB) + L1i L#12 (32KB) + Core L#12</div><div class="line">          PU L#24 (P#12)</div><div class="line">          PU L#25 (P#140)</div><div class="line">        L2 L#13 (512KB) + L1d L#13 (32KB) + L1i L#13 (32KB) + Core L#13</div><div class="line">          PU L#26 (P#13)</div><div class="line">          PU L#27 (P#141)</div><div class="line">        L2 L#14 (512KB) + L1d L#14 (32KB) + L1i L#14 (32KB) + Core L#14</div><div class="line">          PU L#28 (P#14)</div><div class="line">          PU L#29 (P#142)</div><div class="line">        L2 L#15 (512KB) + L1d L#15 (32KB) + L1i L#15 (32KB) + Core L#15</div><div class="line">          PU L#30 (P#15)</div><div class="line">          PU L#31 (P#143)</div><div class="line">      L3 L#2 (32MB)</div><div class="line">        L2 L#16 (512KB) + L1d L#16 (32KB) + L1i L#16 (32KB) + Core L#16</div><div class="line">          PU L#32 (P#16)</div><div class="line">          PU L#33 (P#144)</div><div class="line">        L2 L#17 (512KB) + L1d L#17 (32KB) + L1i L#17 (32KB) + Core L#17</div><div class="line">          PU L#34 (P#17)</div><div class="line">          PU L#35 (P#145)</div><div class="line">        L2 L#18 (512KB) + L1d L#18 (32KB) + L1i L#18 (32KB) + Core L#18</div><div class="line">          PU L#36 (P#18)</div><div class="line">          PU L#37 (P#146)</div><div class="line">        L2 L#19 (512KB) + L1d L#19 (32KB) + L1i L#19 (32KB) + Core L#19</div><div class="line">          PU L#38 (P#19)</div><div class="line">          PU L#39 (P#147)</div><div class="line">        L2 L#20 (512KB) + L1d L#20 (32KB) + L1i L#20 (32KB) + Core L#20</div><div class="line">          PU L#40 (P#20)</div><div class="line">          PU L#41 (P#148)</div><div class="line">        L2 L#21 (512KB) + L1d L#21 (32KB) + L1i L#21 (32KB) + Core L#21</div><div class="line">          PU L#42 (P#21)</div><div class="line">          PU L#43 (P#149)</div><div class="line">        L2 L#22 (512KB) + L1d L#22 (32KB) + L1i L#22 (32KB) + Core L#22</div><div class="line">          PU L#44 (P#22)</div><div class="line">          PU L#45 (P#150)</div><div class="line">        L2 L#23 (512KB) + L1d L#23 (32KB) + L1i L#23 (32KB) + Core L#23</div><div class="line">          PU L#46 (P#23)</div><div class="line">          PU L#47 (P#151)</div><div class="line">      L3 L#3 (32MB)</div><div class="line">        L2 L#24 (512KB) + L1d L#24 (32KB) + L1i L#24 (32KB) + Core L#24</div><div class="line">          PU L#48 (P#24)</div><div class="line">          PU L#49 (P#152)</div><div class="line">        L2 L#25 (512KB) + L1d L#25 (32KB) + L1i L#25 (32KB) + Core L#25</div><div class="line">          PU L#50 (P#25)</div><div class="line">          PU L#51 (P#153)</div><div class="line">        L2 L#26 (512KB) + L1d L#26 (32KB) + L1i L#26 (32KB) + Core L#26</div><div class="line">          PU L#52 (P#26)</div><div class="line">          PU L#53 (P#154)</div><div class="line">        L2 L#27 (512KB) + L1d L#27 (32KB) + L1i L#27 (32KB) + Core L#27</div><div class="line">          PU L#54 (P#27)</div><div class="line">          PU L#55 (P#155)</div><div class="line">        L2 L#28 (512KB) + L1d L#28 (32KB) + L1i L#28 (32KB) + Core L#28</div><div class="line">          PU L#56 (P#28)</div><div class="line">          PU L#57 (P#156)</div><div class="line">        L2 L#29 (512KB) + L1d L#29 (32KB) + L1i L#29 (32KB) + Core L#29</div><div class="line">          PU L#58 (P#29)</div><div class="line">          PU L#59 (P#157)</div><div class="line">        L2 L#30 (512KB) + L1d L#30 (32KB) + L1i L#30 (32KB) + Core L#30</div><div class="line">          PU L#60 (P#30)</div><div class="line">          PU L#61 (P#158)</div><div class="line">        L2 L#31 (512KB) + L1d L#31 (32KB) + L1i L#31 (32KB) + Core L#31</div><div class="line">          PU L#62 (P#31)</div><div class="line">          PU L#63 (P#159)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCI 144d:a80a</div><div class="line">        PCIBridge</div><div class="line">          PCI 144d:a80a</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCI 1a03:2000</div><div class="line">              GPU L#0 &quot;controlD64&quot;</div><div class="line">              GPU L#1 &quot;card0&quot;</div><div class="line">    NUMANode L#1 (P#1 504GB)</div><div class="line">      L3 L#4 (32MB)</div><div class="line">        L2 L#32 (512KB) + L1d L#32 (32KB) + L1i L#32 (32KB) + Core L#32</div><div class="line">          PU L#64 (P#32)</div><div class="line">          PU L#65 (P#160)</div><div class="line">        L2 L#33 (512KB) + L1d L#33 (32KB) + L1i L#33 (32KB) + Core L#33</div><div class="line">          PU L#66 (P#33)</div><div class="line">          PU L#67 (P#161)</div><div class="line">        L2 L#34 (512KB) + L1d L#34 (32KB) + L1i L#34 (32KB) + Core L#34</div><div class="line">          PU L#68 (P#34)</div><div class="line">          PU L#69 (P#162)</div><div class="line">        L2 L#35 (512KB) + L1d L#35 (32KB) + L1i L#35 (32KB) + Core L#35</div><div class="line">          PU L#70 (P#35)</div><div class="line">          PU L#71 (P#163)</div><div class="line">        L2 L#36 (512KB) + L1d L#36 (32KB) + L1i L#36 (32KB) + Core L#36</div><div class="line">          PU L#72 (P#36)</div><div class="line">          PU L#73 (P#164)</div><div class="line">        L2 L#37 (512KB) + L1d L#37 (32KB) + L1i L#37 (32KB) + Core L#37</div><div class="line">          PU L#74 (P#37)</div><div class="line">          PU L#75 (P#165)</div><div class="line">        L2 L#38 (512KB) + L1d L#38 (32KB) + L1i L#38 (32KB) + Core L#38</div><div class="line">          PU L#76 (P#38)</div><div class="line">          PU L#77 (P#166)</div><div class="line">        L2 L#39 (512KB) + L1d L#39 (32KB) + L1i L#39 (32KB) + Core L#39</div><div class="line">          PU L#78 (P#39)</div><div class="line">          PU L#79 (P#167)</div><div class="line">      L3 L#5 (32MB)</div><div class="line">        L2 L#40 (512KB) + L1d L#40 (32KB) + L1i L#40 (32KB) + Core L#40</div><div class="line">          PU L#80 (P#40)</div><div class="line">          PU L#81 (P#168)</div><div class="line">        L2 L#41 (512KB) + L1d L#41 (32KB) + L1i L#41 (32KB) + Core L#41</div><div class="line">          PU L#82 (P#41)</div><div class="line">          PU L#83 (P#169)</div><div class="line">        L2 L#42 (512KB) + L1d L#42 (32KB) + L1i L#42 (32KB) + Core L#42</div><div class="line">          PU L#84 (P#42)</div><div class="line">          PU L#85 (P#170)</div><div class="line">        L2 L#43 (512KB) + L1d L#43 (32KB) + L1i L#43 (32KB) + Core L#43</div><div class="line">          PU L#86 (P#43)</div><div class="line">          PU L#87 (P#171)</div><div class="line">        L2 L#44 (512KB) + L1d L#44 (32KB) + L1i L#44 (32KB) + Core L#44</div><div class="line">          PU L#88 (P#44)</div><div class="line">          PU L#89 (P#172)</div><div class="line">        L2 L#45 (512KB) + L1d L#45 (32KB) + L1i L#45 (32KB) + Core L#45</div><div class="line">          PU L#90 (P#45)</div><div class="line">          PU L#91 (P#173)</div><div class="line">        L2 L#46 (512KB) + L1d L#46 (32KB) + L1i L#46 (32KB) + Core L#46</div><div class="line">          PU L#92 (P#46)</div><div class="line">          PU L#93 (P#174)</div><div class="line">        L2 L#47 (512KB) + L1d L#47 (32KB) + L1i L#47 (32KB) + Core L#47</div><div class="line">          PU L#94 (P#47)</div><div class="line">          PU L#95 (P#175)</div><div class="line">      L3 L#6 (32MB)</div><div class="line">        L2 L#48 (512KB) + L1d L#48 (32KB) + L1i L#48 (32KB) + Core L#48</div><div class="line">          PU L#96 (P#48)</div><div class="line">          PU L#97 (P#176)</div><div class="line">        L2 L#49 (512KB) + L1d L#49 (32KB) + L1i L#49 (32KB) + Core L#49</div><div class="line">          PU L#98 (P#49)</div><div class="line">          PU L#99 (P#177)</div><div class="line">        L2 L#50 (512KB) + L1d L#50 (32KB) + L1i L#50 (32KB) + Core L#50</div><div class="line">          PU L#100 (P#50)</div><div class="line">          PU L#101 (P#178)</div><div class="line">        L2 L#51 (512KB) + L1d L#51 (32KB) + L1i L#51 (32KB) + Core L#51</div><div class="line">          PU L#102 (P#51)</div><div class="line">          PU L#103 (P#179)</div><div class="line">        L2 L#52 (512KB) + L1d L#52 (32KB) + L1i L#52 (32KB) + Core L#52</div><div class="line">          PU L#104 (P#52)</div><div class="line">          PU L#105 (P#180)</div><div class="line">        L2 L#53 (512KB) + L1d L#53 (32KB) + L1i L#53 (32KB) + Core L#53</div><div class="line">          PU L#106 (P#53)</div><div class="line">          PU L#107 (P#181)</div><div class="line">        L2 L#54 (512KB) + L1d L#54 (32KB) + L1i L#54 (32KB) + Core L#54</div><div class="line">          PU L#108 (P#54)</div><div class="line">          PU L#109 (P#182)</div><div class="line">        L2 L#55 (512KB) + L1d L#55 (32KB) + L1i L#55 (32KB) + Core L#55</div><div class="line">          PU L#110 (P#55)</div><div class="line">          PU L#111 (P#183)</div><div class="line">      L3 L#7 (32MB)</div><div class="line">        L2 L#56 (512KB) + L1d L#56 (32KB) + L1i L#56 (32KB) + Core L#56</div><div class="line">          PU L#112 (P#56)</div><div class="line">          PU L#113 (P#184)</div><div class="line">        L2 L#57 (512KB) + L1d L#57 (32KB) + L1i L#57 (32KB) + Core L#57</div><div class="line">          PU L#114 (P#57)</div><div class="line">          PU L#115 (P#185)</div><div class="line">        L2 L#58 (512KB) + L1d L#58 (32KB) + L1i L#58 (32KB) + Core L#58</div><div class="line">          PU L#116 (P#58)</div><div class="line">          PU L#117 (P#186)</div><div class="line">        L2 L#59 (512KB) + L1d L#59 (32KB) + L1i L#59 (32KB) + Core L#59</div><div class="line">          PU L#118 (P#59)</div><div class="line">          PU L#119 (P#187)</div><div class="line">        L2 L#60 (512KB) + L1d L#60 (32KB) + L1i L#60 (32KB) + Core L#60</div><div class="line">          PU L#120 (P#60)</div><div class="line">          PU L#121 (P#188)</div><div class="line">        L2 L#61 (512KB) + L1d L#61 (32KB) + L1i L#61 (32KB) + Core L#61</div><div class="line">          PU L#122 (P#61)</div><div class="line">          PU L#123 (P#189)</div><div class="line">        L2 L#62 (512KB) + L1d L#62 (32KB) + L1i L#62 (32KB) + Core L#62</div><div class="line">          PU L#124 (P#62)</div><div class="line">          PU L#125 (P#190)</div><div class="line">        L2 L#63 (512KB) + L1d L#63 (32KB) + L1i L#63 (32KB) + Core L#63</div><div class="line">          PU L#126 (P#63)</div><div class="line">          PU L#127 (P#191)</div><div class="line">      HostBridge L#5</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 1af4:1001</div><div class="line">            PCIBridge</div><div class="line">              PCI 1ded:1001</div><div class="line">              PCI ffff:ffff</div><div class="line"></div><div class="line">  Socket L#1 (1008GB)</div><div class="line">    NUMANode L#2 (P#2 504GB)</div><div class="line">      L3 L#8 (32MB)</div><div class="line">        L2 L#64 (512KB) + L1d L#64 (32KB) + L1i L#64 (32KB) + Core L#64</div><div class="line">          PU L#128 (P#64)</div><div class="line">          PU L#129 (P#192)</div><div class="line">        L2 L#65 (512KB) + L1d L#65 (32KB) + L1i L#65 (32KB) + Core L#65</div><div class="line">          PU L#130 (P#65)</div><div class="line">          PU L#131 (P#193)</div><div class="line">        L2 L#66 (512KB) + L1d L#66 (32KB) + L1i L#66 (32KB) + Core L#66</div><div class="line">          PU L#132 (P#66)</div><div class="line">          PU L#133 (P#194)</div><div class="line">        L2 L#67 (512KB) + L1d L#67 (32KB) + L1i L#67 (32KB) + Core L#67</div><div class="line">          PU L#134 (P#67)</div><div class="line">          PU L#135 (P#195)</div><div class="line">        L2 L#68 (512KB) + L1d L#68 (32KB) + L1i L#68 (32KB) + Core L#68</div><div class="line">          PU L#136 (P#68)</div><div class="line">          PU L#137 (P#196)</div><div class="line">        L2 L#69 (512KB) + L1d L#69 (32KB) + L1i L#69 (32KB) + Core L#69</div><div class="line">          PU L#138 (P#69)</div><div class="line">          PU L#139 (P#197)</div><div class="line">        L2 L#70 (512KB) + L1d L#70 (32KB) + L1i L#70 (32KB) + Core L#70</div><div class="line">          PU L#140 (P#70)</div><div class="line">          PU L#141 (P#198)</div><div class="line">        L2 L#71 (512KB) + L1d L#71 (32KB) + L1i L#71 (32KB) + Core L#71</div><div class="line">          PU L#142 (P#71)</div><div class="line">          PU L#143 (P#199)</div><div class="line">      L3 L#9 (32MB)</div><div class="line">        L2 L#72 (512KB) + L1d L#72 (32KB) + L1i L#72 (32KB) + Core L#72</div><div class="line">          PU L#144 (P#72)</div><div class="line">          PU L#145 (P#200)</div><div class="line">        L2 L#73 (512KB) + L1d L#73 (32KB) + L1i L#73 (32KB) + Core L#73</div><div class="line">          PU L#146 (P#73)</div><div class="line">          PU L#147 (P#201)</div><div class="line">        L2 L#74 (512KB) + L1d L#74 (32KB) + L1i L#74 (32KB) + Core L#74</div><div class="line">          PU L#148 (P#74)</div><div class="line">          PU L#149 (P#202)</div><div class="line">        L2 L#75 (512KB) + L1d L#75 (32KB) + L1i L#75 (32KB) + Core L#75</div><div class="line">          PU L#150 (P#75)</div><div class="line">          PU L#151 (P#203)</div><div class="line">        L2 L#76 (512KB) + L1d L#76 (32KB) + L1i L#76 (32KB) + Core L#76</div><div class="line">          PU L#152 (P#76)</div><div class="line">          PU L#153 (P#204)</div><div class="line">        L2 L#77 (512KB) + L1d L#77 (32KB) + L1i L#77 (32KB) + Core L#77</div><div class="line">          PU L#154 (P#77)</div><div class="line">          PU L#155 (P#205)</div><div class="line">        L2 L#78 (512KB) + L1d L#78 (32KB) + L1i L#78 (32KB) + Core L#78</div><div class="line">          PU L#156 (P#78)</div><div class="line">          PU L#157 (P#206)</div><div class="line">        L2 L#79 (512KB) + L1d L#79 (32KB) + L1i L#79 (32KB) + Core L#79</div><div class="line">          PU L#158 (P#79)</div><div class="line">          PU L#159 (P#207)</div><div class="line">      L3 L#10 (32MB)</div><div class="line">        L2 L#80 (512KB) + L1d L#80 (32KB) + L1i L#80 (32KB) + Core L#80</div><div class="line">          PU L#160 (P#80)</div><div class="line">          PU L#161 (P#208)</div><div class="line">        L2 L#81 (512KB) + L1d L#81 (32KB) + L1i L#81 (32KB) + Core L#81</div><div class="line">          PU L#162 (P#81)</div><div class="line">          PU L#163 (P#209)</div><div class="line">        L2 L#82 (512KB) + L1d L#82 (32KB) + L1i L#82 (32KB) + Core L#82</div><div class="line">          PU L#164 (P#82)</div><div class="line">          PU L#165 (P#210)</div><div class="line">        L2 L#83 (512KB) + L1d L#83 (32KB) + L1i L#83 (32KB) + Core L#83</div><div class="line">          PU L#166 (P#83)</div><div class="line">          PU L#167 (P#211)</div><div class="line">        L2 L#84 (512KB) + L1d L#84 (32KB) + L1i L#84 (32KB) + Core L#84</div><div class="line">          PU L#168 (P#84)</div><div class="line">          PU L#169 (P#212)</div><div class="line">        L2 L#85 (512KB) + L1d L#85 (32KB) + L1i L#85 (32KB) + Core L#85</div><div class="line">          PU L#170 (P#85)</div><div class="line">          PU L#171 (P#213)</div><div class="line">        L2 L#86 (512KB) + L1d L#86 (32KB) + L1i L#86 (32KB) + Core L#86</div><div class="line">          PU L#172 (P#86)</div><div class="line">          PU L#173 (P#214)</div><div class="line">        L2 L#87 (512KB) + L1d L#87 (32KB) + L1i L#87 (32KB) + Core L#87</div><div class="line">          PU L#174 (P#87)</div><div class="line">          PU L#175 (P#215)</div><div class="line">      L3 L#11 (32MB)</div><div class="line">        L2 L#88 (512KB) + L1d L#88 (32KB) + L1i L#88 (32KB) + Core L#88</div><div class="line">          PU L#176 (P#88)</div><div class="line">          PU L#177 (P#216)</div><div class="line">        L2 L#89 (512KB) + L1d L#89 (32KB) + L1i L#89 (32KB) + Core L#89</div><div class="line">          PU L#178 (P#89)</div><div class="line">          PU L#179 (P#217)</div><div class="line">        L2 L#90 (512KB) + L1d L#90 (32KB) + L1i L#90 (32KB) + Core L#90</div><div class="line">          PU L#180 (P#90)</div><div class="line">          PU L#181 (P#218)</div><div class="line">        L2 L#91 (512KB) + L1d L#91 (32KB) + L1i L#91 (32KB) + Core L#91</div><div class="line">          PU L#182 (P#91)</div><div class="line">          PU L#183 (P#219)</div><div class="line">        L2 L#92 (512KB) + L1d L#92 (32KB) + L1i L#92 (32KB) + Core L#92</div><div class="line">          PU L#184 (P#92)</div><div class="line">          PU L#185 (P#220)</div><div class="line">        L2 L#93 (512KB) + L1d L#93 (32KB) + L1i L#93 (32KB) + Core L#93</div><div class="line">          PU L#186 (P#93)</div><div class="line">          PU L#187 (P#221)</div><div class="line">        L2 L#94 (512KB) + L1d L#94 (32KB) + L1i L#94 (32KB) + Core L#94</div><div class="line">          PU L#188 (P#94)</div><div class="line">          PU L#189 (P#222)</div><div class="line">        L2 L#95 (512KB) + L1d L#95 (32KB) + L1i L#95 (32KB) + Core L#95</div><div class="line">          PU L#190 (P#95)</div><div class="line">          PU L#191 (P#223)</div><div class="line">    NUMANode L#3 (P#3 504GB)</div><div class="line">      L3 L#12 (32MB)</div><div class="line">        L2 L#96 (512KB) + L1d L#96 (32KB) + L1i L#96 (32KB) + Core L#96</div><div class="line">          PU L#192 (P#96)</div><div class="line">          PU L#193 (P#224)</div><div class="line">        L2 L#97 (512KB) + L1d L#97 (32KB) + L1i L#97 (32KB) + Core L#97</div><div class="line">          PU L#194 (P#97)</div><div class="line">          PU L#195 (P#225)</div><div class="line">        L2 L#98 (512KB) + L1d L#98 (32KB) + L1i L#98 (32KB) + Core L#98</div><div class="line">          PU L#196 (P#98)</div><div class="line">          PU L#197 (P#226)</div><div class="line">        L2 L#99 (512KB) + L1d L#99 (32KB) + L1i L#99 (32KB) + Core L#99</div><div class="line">          PU L#198 (P#99)</div><div class="line">          PU L#199 (P#227)</div><div class="line">        L2 L#100 (512KB) + L1d L#100 (32KB) + L1i L#100 (32KB) + Core L#100</div><div class="line">          PU L#200 (P#100)</div><div class="line">          PU L#201 (P#228)</div><div class="line">        L2 L#101 (512KB) + L1d L#101 (32KB) + L1i L#101 (32KB) + Core L#101</div><div class="line">          PU L#202 (P#101)</div><div class="line">          PU L#203 (P#229)</div><div class="line">        L2 L#102 (512KB) + L1d L#102 (32KB) + L1i L#102 (32KB) + Core L#102</div><div class="line">          PU L#204 (P#102)</div><div class="line">          PU L#205 (P#230)</div><div class="line">        L2 L#103 (512KB) + L1d L#103 (32KB) + L1i L#103 (32KB) + Core L#103</div><div class="line">          PU L#206 (P#103)</div><div class="line">          PU L#207 (P#231)</div><div class="line">      L3 L#13 (32MB)</div><div class="line">        L2 L#104 (512KB) + L1d L#104 (32KB) + L1i L#104 (32KB) + Core L#104</div><div class="line">          PU L#208 (P#104)</div><div class="line">          PU L#209 (P#232)</div><div class="line">        L2 L#105 (512KB) + L1d L#105 (32KB) + L1i L#105 (32KB) + Core L#105</div><div class="line">          PU L#210 (P#105)</div><div class="line">          PU L#211 (P#233)</div><div class="line">        L2 L#106 (512KB) + L1d L#106 (32KB) + L1i L#106 (32KB) + Core L#106</div><div class="line">          PU L#212 (P#106)</div><div class="line">          PU L#213 (P#234)</div><div class="line">        L2 L#107 (512KB) + L1d L#107 (32KB) + L1i L#107 (32KB) + Core L#107</div><div class="line">          PU L#214 (P#107)</div><div class="line">          PU L#215 (P#235)</div><div class="line">        L2 L#108 (512KB) + L1d L#108 (32KB) + L1i L#108 (32KB) + Core L#108</div><div class="line">          PU L#216 (P#108)</div><div class="line">          PU L#217 (P#236)</div><div class="line">        L2 L#109 (512KB) + L1d L#109 (32KB) + L1i L#109 (32KB) + Core L#109</div><div class="line">          PU L#218 (P#109)</div><div class="line">          PU L#219 (P#237)</div><div class="line">        L2 L#110 (512KB) + L1d L#110 (32KB) + L1i L#110 (32KB) + Core L#110</div><div class="line">          PU L#220 (P#110)</div><div class="line">          PU L#221 (P#238)</div><div class="line">        L2 L#111 (512KB) + L1d L#111 (32KB) + L1i L#111 (32KB) + Core L#111</div><div class="line">          PU L#222 (P#111)</div><div class="line">          PU L#223 (P#239)</div><div class="line">      L3 L#14 (32MB)</div><div class="line">        L2 L#112 (512KB) + L1d L#112 (32KB) + L1i L#112 (32KB) + Core L#112</div><div class="line">          PU L#224 (P#112)</div><div class="line">          PU L#225 (P#240)</div><div class="line">        L2 L#113 (512KB) + L1d L#113 (32KB) + L1i L#113 (32KB) + Core L#113</div><div class="line">          PU L#226 (P#113)</div><div class="line">          PU L#227 (P#241)</div><div class="line">        L2 L#114 (512KB) + L1d L#114 (32KB) + L1i L#114 (32KB) + Core L#114</div><div class="line">          PU L#228 (P#114)</div><div class="line">          PU L#229 (P#242)</div><div class="line">        L2 L#115 (512KB) + L1d L#115 (32KB) + L1i L#115 (32KB) + Core L#115</div><div class="line">          PU L#230 (P#115)</div><div class="line">          PU L#231 (P#243)</div><div class="line">        L2 L#116 (512KB) + L1d L#116 (32KB) + L1i L#116 (32KB) + Core L#116</div><div class="line">          PU L#232 (P#116)</div><div class="line">          PU L#233 (P#244)</div><div class="line">        L2 L#117 (512KB) + L1d L#117 (32KB) + L1i L#117 (32KB) + Core L#117</div><div class="line">          PU L#234 (P#117)</div><div class="line">          PU L#235 (P#245)</div><div class="line">        L2 L#118 (512KB) + L1d L#118 (32KB) + L1i L#118 (32KB) + Core L#118</div><div class="line">          PU L#236 (P#118)</div><div class="line">          PU L#237 (P#246)</div><div class="line">        L2 L#119 (512KB) + L1d L#119 (32KB) + L1i L#119 (32KB) + Core L#119</div><div class="line">          PU L#238 (P#119)</div><div class="line">          PU L#239 (P#247)</div><div class="line">      L3 L#15 (32MB)</div><div class="line">        L2 L#120 (512KB) + L1d L#120 (32KB) + L1i L#120 (32KB) + Core L#120</div><div class="line">          PU L#240 (P#120)</div><div class="line">          PU L#241 (P#248)</div><div class="line">        L2 L#121 (512KB) + L1d L#121 (32KB) + L1i L#121 (32KB) + Core L#121</div><div class="line">          PU L#242 (P#121)</div><div class="line">          PU L#243 (P#249)</div><div class="line">        L2 L#122 (512KB) + L1d L#122 (32KB) + L1i L#122 (32KB) + Core L#122</div><div class="line">          PU L#244 (P#122)</div><div class="line">          PU L#245 (P#250)</div><div class="line">        L2 L#123 (512KB) + L1d L#123 (32KB) + L1i L#123 (32KB) + Core L#123</div><div class="line">          PU L#246 (P#123)</div><div class="line">          PU L#247 (P#251)</div><div class="line">        L2 L#124 (512KB) + L1d L#124 (32KB) + L1i L#124 (32KB) + Core L#124</div><div class="line">          PU L#248 (P#124)</div><div class="line">          PU L#249 (P#252)</div><div class="line">        L2 L#125 (512KB) + L1d L#125 (32KB) + L1i L#125 (32KB) + Core L#125</div><div class="line">          PU L#250 (P#125)</div><div class="line">          PU L#251 (P#253)</div><div class="line">        L2 L#126 (512KB) + L1d L#126 (32KB) + L1i L#126 (32KB) + Core L#126</div><div class="line">          PU L#252 (P#126)</div><div class="line">          PU L#253 (P#254)</div><div class="line">        L2 L#127 (512KB) + L1d L#127 (32KB) + L1i L#127 (32KB) + Core L#127</div><div class="line">          PU L#254 (P#127)</div><div class="line">          PU L#255 (P#255)</div></pre></td></tr></table></figure>
<p>这台机器改下BIOS设置</p>
<p><img src="/images/951413iMgBlog/FrVuhXNHEf2LzigZPHHV6c7UNKrP.png" alt="img"></p>
<p>白色Channel 那里可以选择Auto/Die/Channel/Socket, 选择Socket后得到如下Node 结构:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                256</div><div class="line">On-line CPU(s) list:   0-255</div><div class="line">Thread(s) per core:    2</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             AuthenticAMD</div><div class="line">CPU family:            25</div><div class="line">Model:                 1</div><div class="line">Model name:            AMD EPYC 7T83 64-Core Processor</div><div class="line">Stepping:              1</div><div class="line">CPU MHz:               2399.192</div><div class="line">CPU max MHz:           2550.0000</div><div class="line">CPU min MHz:           1500.0000</div><div class="line">BogoMIPS:              5090.50</div><div class="line">Virtualization:        AMD-V</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              32768K</div><div class="line">NUMA node0 CPU(s):     0-63,128-191</div><div class="line">NUMA node1 CPU(s):     64-127,192-255 //每个socket下的内存交织，也就是一个Socket是一个独立的 Numa Node</div></pre></td></tr></table></figure>
<h2 id="鲲鹏-920"><a href="#鲲鹏-920" class="headerlink" title="鲲鹏 920"></a>鲲鹏 920</h2><p>鲲鹏是ARM架构，一般都没有超线程，因为指令简单流水线较流畅，搞超线程收益不大</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div></pre></td><td class="code"><pre><div class="line"># lscpu</div><div class="line">架构：                           aarch64</div><div class="line">CPU 运行模式：                   64-bit</div><div class="line">字节序：                         Little Endian</div><div class="line">CPU:                             96</div><div class="line">在线 CPU 列表：                  0-95</div><div class="line">每个核的线程数：                 1</div><div class="line">每个座的核数：                   48</div><div class="line">座：                             2</div><div class="line">NUMA 节点：                      4</div><div class="line">厂商 ID：                        HiSilicon</div><div class="line">型号：                           0</div><div class="line">型号名称：                       Kunpeng-920</div><div class="line">步进：                           0x1</div><div class="line">CPU 最大 MHz：                   2600.0000</div><div class="line">CPU 最小 MHz：                   200.0000</div><div class="line">BogoMIPS：                       200.00</div><div class="line">L1d 缓存：                       6 MiB</div><div class="line">L1i 缓存：                       6 MiB</div><div class="line">L2 缓存：                        48 MiB</div><div class="line">L3 缓存：                        96 MiB</div><div class="line">NUMA 节点0 CPU：                 0-23</div><div class="line">NUMA 节点1 CPU：                 24-47</div><div class="line">NUMA 节点2 CPU：                 48-71</div><div class="line">NUMA 节点3 CPU：                 72-95</div><div class="line"></div><div class="line">#lstopo</div><div class="line">Machine (766GB total)</div><div class="line">  Package L#0</div><div class="line">    NUMANode L#0 (P#0 191GB)</div><div class="line">      L3 L#0 (24MB)</div><div class="line">        L2 L#0 (512KB) + L1d L#0 (64KB) + L1i L#0 (64KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L2 L#1 (512KB) + L1d L#1 (64KB) + L1i L#1 (64KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L2 L#2 (512KB) + L1d L#2 (64KB) + L1i L#2 (64KB) + Core L#2 + PU L#2 (P#2)</div><div class="line">        L2 L#3 (512KB) + L1d L#3 (64KB) + L1i L#3 (64KB) + Core L#3 + PU L#3 (P#3)</div><div class="line">        L2 L#4 (512KB) + L1d L#4 (64KB) + L1i L#4 (64KB) + Core L#4 + PU L#4 (P#4)</div><div class="line">        L2 L#5 (512KB) + L1d L#5 (64KB) + L1i L#5 (64KB) + Core L#5 + PU L#5 (P#5)</div><div class="line">        L2 L#6 (512KB) + L1d L#6 (64KB) + L1i L#6 (64KB) + Core L#6 + PU L#6 (P#6)</div><div class="line">        L2 L#7 (512KB) + L1d L#7 (64KB) + L1i L#7 (64KB) + Core L#7 + PU L#7 (P#7)</div><div class="line">        L2 L#8 (512KB) + L1d L#8 (64KB) + L1i L#8 (64KB) + Core L#8 + PU L#8 (P#8)</div><div class="line">        L2 L#9 (512KB) + L1d L#9 (64KB) + L1i L#9 (64KB) + Core L#9 + PU L#9 (P#9)</div><div class="line">        L2 L#10 (512KB) + L1d L#10 (64KB) + L1i L#10 (64KB) + Core L#10 + PU L#10 (P#10)</div><div class="line">        L2 L#11 (512KB) + L1d L#11 (64KB) + L1i L#11 (64KB) + Core L#11 + PU L#11 (P#11)</div><div class="line">        L2 L#12 (512KB) + L1d L#12 (64KB) + L1i L#12 (64KB) + Core L#12 + PU L#12 (P#12)</div><div class="line">        L2 L#13 (512KB) + L1d L#13 (64KB) + L1i L#13 (64KB) + Core L#13 + PU L#13 (P#13)</div><div class="line">        L2 L#14 (512KB) + L1d L#14 (64KB) + L1i L#14 (64KB) + Core L#14 + PU L#14 (P#14)</div><div class="line">        L2 L#15 (512KB) + L1d L#15 (64KB) + L1i L#15 (64KB) + Core L#15 + PU L#15 (P#15)</div><div class="line">        L2 L#16 (512KB) + L1d L#16 (64KB) + L1i L#16 (64KB) + Core L#16 + PU L#16 (P#16)</div><div class="line">        L2 L#17 (512KB) + L1d L#17 (64KB) + L1i L#17 (64KB) + Core L#17 + PU L#17 (P#17)</div><div class="line">        L2 L#18 (512KB) + L1d L#18 (64KB) + L1i L#18 (64KB) + Core L#18 + PU L#18 (P#18)</div><div class="line">        L2 L#19 (512KB) + L1d L#19 (64KB) + L1i L#19 (64KB) + Core L#19 + PU L#19 (P#19)</div><div class="line">        L2 L#20 (512KB) + L1d L#20 (64KB) + L1i L#20 (64KB) + Core L#20 + PU L#20 (P#20)</div><div class="line">        L2 L#21 (512KB) + L1d L#21 (64KB) + L1i L#21 (64KB) + Core L#21 + PU L#21 (P#21)</div><div class="line">        L2 L#22 (512KB) + L1d L#22 (64KB) + L1i L#22 (64KB) + Core L#22 + PU L#22 (P#22)</div><div class="line">        L2 L#23 (512KB) + L1d L#23 (64KB) + L1i L#23 (64KB) + Core L#23 + PU L#23 (P#23)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCI 15b3:1017</div><div class="line">            Net L#0 &quot;enp2s0f0&quot;</div><div class="line">          PCI 15b3:1017</div><div class="line">            Net L#1 &quot;enp2s0f1&quot;</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:1711</div><div class="line">            GPU L#2 &quot;controlD64&quot;</div><div class="line">            GPU L#3 &quot;card0&quot;</div><div class="line">      HostBridge L#3</div><div class="line">        2 x &#123; PCI 19e5:a230 &#125;</div><div class="line">        PCI 19e5:a235</div><div class="line">          Block(Disk) L#4 &quot;sda&quot;</div><div class="line">      HostBridge L#4</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:a222</div><div class="line">            Net L#5 &quot;enp125s0f0&quot;</div><div class="line">            OpenFabrics L#6 &quot;hns_0&quot;</div><div class="line">          PCI 19e5:a221</div><div class="line">            Net L#7 &quot;enp125s0f1&quot;</div><div class="line">          PCI 19e5:a222</div><div class="line">            Net L#8 &quot;enp125s0f2&quot;</div><div class="line">            OpenFabrics L#9 &quot;hns_1&quot;</div><div class="line">          PCI 19e5:a221</div><div class="line">            Net L#10 &quot;enp125s0f3&quot;</div><div class="line">    NUMANode L#1 (P#1 192GB) + L3 L#1 (24MB)</div><div class="line">      L2 L#24 (512KB) + L1d L#24 (64KB) + L1i L#24 (64KB) + Core L#24 + PU L#24 (P#24)</div><div class="line">      L2 L#25 (512KB) + L1d L#25 (64KB) + L1i L#25 (64KB) + Core L#25 + PU L#25 (P#25)</div><div class="line">      L2 L#26 (512KB) + L1d L#26 (64KB) + L1i L#26 (64KB) + Core L#26 + PU L#26 (P#26)</div><div class="line">      L2 L#27 (512KB) + L1d L#27 (64KB) + L1i L#27 (64KB) + Core L#27 + PU L#27 (P#27)</div><div class="line">      L2 L#28 (512KB) + L1d L#28 (64KB) + L1i L#28 (64KB) + Core L#28 + PU L#28 (P#28)</div><div class="line">      L2 L#29 (512KB) + L1d L#29 (64KB) + L1i L#29 (64KB) + Core L#29 + PU L#29 (P#29)</div><div class="line">      L2 L#30 (512KB) + L1d L#30 (64KB) + L1i L#30 (64KB) + Core L#30 + PU L#30 (P#30)</div><div class="line">      L2 L#31 (512KB) + L1d L#31 (64KB) + L1i L#31 (64KB) + Core L#31 + PU L#31 (P#31)</div><div class="line">      L2 L#32 (512KB) + L1d L#32 (64KB) + L1i L#32 (64KB) + Core L#32 + PU L#32 (P#32)</div><div class="line">      L2 L#33 (512KB) + L1d L#33 (64KB) + L1i L#33 (64KB) + Core L#33 + PU L#33 (P#33)</div><div class="line">      L2 L#34 (512KB) + L1d L#34 (64KB) + L1i L#34 (64KB) + Core L#34 + PU L#34 (P#34)</div><div class="line">      L2 L#35 (512KB) + L1d L#35 (64KB) + L1i L#35 (64KB) + Core L#35 + PU L#35 (P#35)</div><div class="line">      L2 L#36 (512KB) + L1d L#36 (64KB) + L1i L#36 (64KB) + Core L#36 + PU L#36 (P#36)</div><div class="line">      L2 L#37 (512KB) + L1d L#37 (64KB) + L1i L#37 (64KB) + Core L#37 + PU L#37 (P#37)</div><div class="line">      L2 L#38 (512KB) + L1d L#38 (64KB) + L1i L#38 (64KB) + Core L#38 + PU L#38 (P#38)</div><div class="line">      L2 L#39 (512KB) + L1d L#39 (64KB) + L1i L#39 (64KB) + Core L#39 + PU L#39 (P#39)</div><div class="line">      L2 L#40 (512KB) + L1d L#40 (64KB) + L1i L#40 (64KB) + Core L#40 + PU L#40 (P#40)</div><div class="line">      L2 L#41 (512KB) + L1d L#41 (64KB) + L1i L#41 (64KB) + Core L#41 + PU L#41 (P#41)</div><div class="line">      L2 L#42 (512KB) + L1d L#42 (64KB) + L1i L#42 (64KB) + Core L#42 + PU L#42 (P#42)</div><div class="line">      L2 L#43 (512KB) + L1d L#43 (64KB) + L1i L#43 (64KB) + Core L#43 + PU L#43 (P#43)</div><div class="line">      L2 L#44 (512KB) + L1d L#44 (64KB) + L1i L#44 (64KB) + Core L#44 + PU L#44 (P#44)</div><div class="line">      L2 L#45 (512KB) + L1d L#45 (64KB) + L1i L#45 (64KB) + Core L#45 + PU L#45 (P#45)</div><div class="line">      L2 L#46 (512KB) + L1d L#46 (64KB) + L1i L#46 (64KB) + Core L#46 + PU L#46 (P#46)</div><div class="line">      L2 L#47 (512KB) + L1d L#47 (64KB) + L1i L#47 (64KB) + Core L#47 + PU L#47 (P#47)</div><div class="line">  Package L#1</div><div class="line">    NUMANode L#2 (P#2 192GB)</div><div class="line">      L3 L#2 (24MB)</div><div class="line">        L2 L#48 (512KB) + L1d L#48 (64KB) + L1i L#48 (64KB) + Core L#48 + PU L#48 (P#48)</div><div class="line">        L2 L#49 (512KB) + L1d L#49 (64KB) + L1i L#49 (64KB) + Core L#49 + PU L#49 (P#49)</div><div class="line">        L2 L#50 (512KB) + L1d L#50 (64KB) + L1i L#50 (64KB) + Core L#50 + PU L#50 (P#50)</div><div class="line">        L2 L#51 (512KB) + L1d L#51 (64KB) + L1i L#51 (64KB) + Core L#51 + PU L#51 (P#51)</div><div class="line">        L2 L#52 (512KB) + L1d L#52 (64KB) + L1i L#52 (64KB) + Core L#52 + PU L#52 (P#52)</div><div class="line">        L2 L#53 (512KB) + L1d L#53 (64KB) + L1i L#53 (64KB) + Core L#53 + PU L#53 (P#53)</div><div class="line">        L2 L#54 (512KB) + L1d L#54 (64KB) + L1i L#54 (64KB) + Core L#54 + PU L#54 (P#54)</div><div class="line">        L2 L#55 (512KB) + L1d L#55 (64KB) + L1i L#55 (64KB) + Core L#55 + PU L#55 (P#55)</div><div class="line">        L2 L#56 (512KB) + L1d L#56 (64KB) + L1i L#56 (64KB) + Core L#56 + PU L#56 (P#56)</div><div class="line">        L2 L#57 (512KB) + L1d L#57 (64KB) + L1i L#57 (64KB) + Core L#57 + PU L#57 (P#57)</div><div class="line">        L2 L#58 (512KB) + L1d L#58 (64KB) + L1i L#58 (64KB) + Core L#58 + PU L#58 (P#58)</div><div class="line">        L2 L#59 (512KB) + L1d L#59 (64KB) + L1i L#59 (64KB) + Core L#59 + PU L#59 (P#59)</div><div class="line">        L2 L#60 (512KB) + L1d L#60 (64KB) + L1i L#60 (64KB) + Core L#60 + PU L#60 (P#60)</div><div class="line">        L2 L#61 (512KB) + L1d L#61 (64KB) + L1i L#61 (64KB) + Core L#61 + PU L#61 (P#61)</div><div class="line">        L2 L#62 (512KB) + L1d L#62 (64KB) + L1i L#62 (64KB) + Core L#62 + PU L#62 (P#62)</div><div class="line">        L2 L#63 (512KB) + L1d L#63 (64KB) + L1i L#63 (64KB) + Core L#63 + PU L#63 (P#63)</div><div class="line">        L2 L#64 (512KB) + L1d L#64 (64KB) + L1i L#64 (64KB) + Core L#64 + PU L#64 (P#64)</div><div class="line">        L2 L#65 (512KB) + L1d L#65 (64KB) + L1i L#65 (64KB) + Core L#65 + PU L#65 (P#65)</div><div class="line">        L2 L#66 (512KB) + L1d L#66 (64KB) + L1i L#66 (64KB) + Core L#66 + PU L#66 (P#66)</div><div class="line">        L2 L#67 (512KB) + L1d L#67 (64KB) + L1i L#67 (64KB) + Core L#67 + PU L#67 (P#67)</div><div class="line">        L2 L#68 (512KB) + L1d L#68 (64KB) + L1i L#68 (64KB) + Core L#68 + PU L#68 (P#68)</div><div class="line">        L2 L#69 (512KB) + L1d L#69 (64KB) + L1i L#69 (64KB) + Core L#69 + PU L#69 (P#69)</div><div class="line">        L2 L#70 (512KB) + L1d L#70 (64KB) + L1i L#70 (64KB) + Core L#70 + PU L#70 (P#70)</div><div class="line">        L2 L#71 (512KB) + L1d L#71 (64KB) + L1i L#71 (64KB) + Core L#71 + PU L#71 (P#71)</div><div class="line">      HostBridge L#6</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">        PCIBridge</div><div class="line">          PCI 19e5:3714</div><div class="line">      HostBridge L#11</div><div class="line">        PCI 19e5:a230</div><div class="line">        PCI 19e5:a235</div><div class="line">        PCI 19e5:a230</div><div class="line">    NUMANode L#3 (P#3 191GB) + L3 L#3 (24MB)</div><div class="line">      L2 L#72 (512KB) + L1d L#72 (64KB) + L1i L#72 (64KB) + Core L#72 + PU L#72 (P#72)</div><div class="line">      L2 L#73 (512KB) + L1d L#73 (64KB) + L1i L#73 (64KB) + Core L#73 + PU L#73 (P#73)</div><div class="line">      L2 L#74 (512KB) + L1d L#74 (64KB) + L1i L#74 (64KB) + Core L#74 + PU L#74 (P#74)</div><div class="line">      L2 L#75 (512KB) + L1d L#75 (64KB) + L1i L#75 (64KB) + Core L#75 + PU L#75 (P#75)</div><div class="line">      L2 L#76 (512KB) + L1d L#76 (64KB) + L1i L#76 (64KB) + Core L#76 + PU L#76 (P#76)</div><div class="line">      L2 L#77 (512KB) + L1d L#77 (64KB) + L1i L#77 (64KB) + Core L#77 + PU L#77 (P#77)</div><div class="line">      L2 L#78 (512KB) + L1d L#78 (64KB) + L1i L#78 (64KB) + Core L#78 + PU L#78 (P#78)</div><div class="line">      L2 L#79 (512KB) + L1d L#79 (64KB) + L1i L#79 (64KB) + Core L#79 + PU L#79 (P#79)</div><div class="line">      L2 L#80 (512KB) + L1d L#80 (64KB) + L1i L#80 (64KB) + Core L#80 + PU L#80 (P#80)</div><div class="line">      L2 L#81 (512KB) + L1d L#81 (64KB) + L1i L#81 (64KB) + Core L#81 + PU L#81 (P#81)</div><div class="line">      L2 L#82 (512KB) + L1d L#82 (64KB) + L1i L#82 (64KB) + Core L#82 + PU L#82 (P#82)</div><div class="line">      L2 L#83 (512KB) + L1d L#83 (64KB) + L1i L#83 (64KB) + Core L#83 + PU L#83 (P#83)</div><div class="line">      L2 L#84 (512KB) + L1d L#84 (64KB) + L1i L#84 (64KB) + Core L#84 + PU L#84 (P#84)</div><div class="line">      L2 L#85 (512KB) + L1d L#85 (64KB) + L1i L#85 (64KB) + Core L#85 + PU L#85 (P#85)</div><div class="line">      L2 L#86 (512KB) + L1d L#86 (64KB) + L1i L#86 (64KB) + Core L#86 + PU L#86 (P#86)</div><div class="line">      L2 L#87 (512KB) + L1d L#87 (64KB) + L1i L#87 (64KB) + Core L#87 + PU L#87 (P#87)</div><div class="line">      L2 L#88 (512KB) + L1d L#88 (64KB) + L1i L#88 (64KB) + Core L#88 + PU L#88 (P#88)</div><div class="line">      L2 L#89 (512KB) + L1d L#89 (64KB) + L1i L#89 (64KB) + Core L#89 + PU L#89 (P#89)</div><div class="line">      L2 L#90 (512KB) + L1d L#90 (64KB) + L1i L#90 (64KB) + Core L#90 + PU L#90 (P#90)</div><div class="line">      L2 L#91 (512KB) + L1d L#91 (64KB) + L1i L#91 (64KB) + Core L#91 + PU L#91 (P#91)</div><div class="line">      L2 L#92 (512KB) + L1d L#92 (64KB) + L1i L#92 (64KB) + Core L#92 + PU L#92 (P#92)</div><div class="line">      L2 L#93 (512KB) + L1d L#93 (64KB) + L1i L#93 (64KB) + Core L#93 + PU L#93 (P#93)</div><div class="line">      L2 L#94 (512KB) + L1d L#94 (64KB) + L1i L#94 (64KB) + Core L#94 + PU L#94 (P#94)</div><div class="line">      L2 L#95 (512KB) + L1d L#95 (64KB) + L1i L#95 (64KB) + Core L#95 + PU L#95 (P#95)</div><div class="line">  Misc(MemoryModule)</div><div class="line">  Misc(MemoryModule)</div><div class="line">  Misc(MemoryModule)</div></pre></td></tr></table></figure>
<p>图形化查看（打开大图，和前面的intel 对着看）</p>
<p><img src="/images/951413iMgBlog/FkQmi4qpCEyiJ-OlK2MbqfbmbMts.png" alt="img"></p>
<p>思考：看如上鲲鹏机器的结构你应该知道网卡、硬盘怎么插放的了吧，然后想就近搞点优化也是可以的</p>
<h2 id="飞腾2500"><a href="#飞腾2500" class="headerlink" title="飞腾2500"></a>飞腾2500</h2><p>飞腾的解读留给大家当作业</p>
<p><a href="https://plantegg.github.io/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/">https://plantegg.github.io/2021/05/15/%E9%A3%9E%E8%85%BEARM%E8%8A%AF%E7%89%87(FT2500)%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line">#dmidecode -t processor</div><div class="line"># dmidecode 3.0</div><div class="line">Getting SMBIOS data from sysfs.</div><div class="line">SMBIOS 3.2.0 present.</div><div class="line"># SMBIOS implementations newer than version 3.0 are not</div><div class="line"># fully supported by this version of dmidecode.</div><div class="line">Handle 0x0004, DMI type 4, 48 bytes</div><div class="line">Processor Information</div><div class="line">    Socket Designation: BGA3576</div><div class="line">    Type: Central Processor</div><div class="line">    Family: &lt;OUT OF SPEC&gt;</div><div class="line">    Manufacturer: PHYTIUM</div><div class="line">    ID: 00 00 00 00 70 1F 66 22</div><div class="line">    Version: FT2500</div><div class="line">    Voltage: 0.8 V</div><div class="line">    External Clock: 50 MHz</div><div class="line">    Max Speed: 2100 MHz</div><div class="line">    Current Speed: 2100 MHz</div><div class="line">    Status: Populated, Enabled</div><div class="line">    Upgrade: Other</div><div class="line">    L1 Cache Handle: 0x0005</div><div class="line">    L2 Cache Handle: 0x0007</div><div class="line">    L3 Cache Handle: 0x0008</div><div class="line">    Serial Number: 1234567</div><div class="line">    Asset Tag: No Asset Tag</div><div class="line">    Part Number: NULL</div><div class="line">    Core Count: 64</div><div class="line">    Core Enabled: 64</div><div class="line">    Thread Count: 64</div><div class="line">    Characteristics:</div><div class="line">        64-bit capable</div><div class="line">        Multi-Core</div><div class="line">        Hardware Thread</div><div class="line">        Execute Protection</div><div class="line">        Enhanced Virtualization</div><div class="line">        Power/Performance Control</div><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          16</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K   //2M？太大了，不真实，估计和海光一样骚</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-7</div><div class="line">NUMA node1 CPU(s):     8-15</div><div class="line">NUMA node2 CPU(s):     16-23</div><div class="line">NUMA node3 CPU(s):     24-31</div><div class="line">NUMA node4 CPU(s):     32-39</div><div class="line">NUMA node5 CPU(s):     40-47</div><div class="line">NUMA node6 CPU(s):     48-55</div><div class="line">NUMA node7 CPU(s):     56-63</div><div class="line">NUMA node8 CPU(s):     64-71</div><div class="line">NUMA node9 CPU(s):     72-79</div><div class="line">NUMA node10 CPU(s):    80-87</div><div class="line">NUMA node11 CPU(s):    88-95</div><div class="line">NUMA node12 CPU(s):    96-103</div><div class="line">NUMA node13 CPU(s):    104-111</div><div class="line">NUMA node14 CPU(s):    112-119</div><div class="line">NUMA node15 CPU(s):    120-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div><div class="line">node distances:</div><div class="line">node   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15</div><div class="line">  0:  10  20  40  30  20  30  50  40  100  100  100  100  100  100  100  100</div><div class="line">  1:  20  10  30  40  50  20  40  50  100  100  100  100  100  100  100  100</div><div class="line">  2:  40  30  10  20  40  50  20  30  100  100  100  100  100  100  100  100</div><div class="line">  3:  30  40  20  10  30  20  40  50  100  100  100  100  100  100  100  100</div><div class="line">  4:  20  50  40  30  10  50  30  20  100  100  100  100  100  100  100  100</div><div class="line">  5:  30  20  50  20  50  10  50  40  100  100  100  100  100  100  100  100</div><div class="line">  6:  50  40  20  40  30  50  10  30  100  100  100  100  100  100  100  100</div><div class="line">  7:  40  50  30  50  20  40  30  10  100  100  100  100  100  100  100  100</div><div class="line">  8:  100  100  100  100  100  100  100  100  10  20  40  30  20  30  50  40</div><div class="line">  9:  100  100  100  100  100  100  100  100  20  10  30  40  50  20  40  50</div><div class="line"> 10:  100  100  100  100  100  100  100  100  40  30  10  20  40  50  20  30</div><div class="line"> 11:  100  100  100  100  100  100  100  100  30  40  20  10  30  20  40  50</div><div class="line"> 12:  100  100  100  100  100  100  100  100  20  50  40  30  10  50  30  20</div><div class="line"> 13:  100  100  100  100  100  100  100  100  30  20  50  20  50  10  50  40</div><div class="line"> 14:  100  100  100  100  100  100  100  100  50  40  20  40  30  50  10  30</div><div class="line"> 15:  100  100  100  100  100  100  100  100  40  50  30  50  20  40  30  10</div></pre></td></tr></table></figure>
<p>飞腾的核有点多，我省略了一些</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line">#lstopo-no-graphics --logical</div><div class="line">Machine (503GB total)</div><div class="line">  Package L#0 + L3 L#0 (64MB)</div><div class="line">    NUMANode L#0 (P#0 31GB)</div><div class="line">      L2 L#0 (2048KB)  //4个物理core共享2M，是不是和AMD(海光)那个设计有点像</div><div class="line">        L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">        L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">        L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2 + PU L#2 (P#2)</div><div class="line">        L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3 + PU L#3 (P#3)</div><div class="line">      L2 L#1 (2048KB)</div><div class="line">        L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4 + PU L#4 (P#4)</div><div class="line">        L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5 + PU L#5 (P#5)</div><div class="line">        L1d L#6 (32KB) + L1i L#6 (32KB) + Core L#6 + PU L#6 (P#6)</div><div class="line">        L1d L#7 (32KB) + L1i L#7 (32KB) + Core L#7 + PU L#7 (P#7)</div><div class="line">      HostBridge L#0</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 1000:00ac</div><div class="line">                Block(Disk) L#0 &quot;sdh&quot;</div><div class="line">                Block(Disk) L#1 &quot;sdf&quot;  // 磁盘挂在Node0上</div><div class="line">            PCIBridge</div><div class="line">              PCI 8086:1521</div><div class="line">                Net L#13 &quot;eth0&quot;</div><div class="line">              PCI 8086:1521</div><div class="line">                Net L#14 &quot;eth1&quot;       //网卡挂在node0上</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCI 1a03:2000</div><div class="line">              GPU L#15 &quot;controlD64&quot;</div><div class="line">              GPU L#16 &quot;card0&quot;</div><div class="line">    NUMANode L#1 (P#1 31GB) //都被我省略了</div><div class="line">    NUMANode L#2 (P#2 31GB)</div><div class="line">    NUMANode L#3 (P#3 31GB)</div><div class="line">    NUMANode L#4 (P#4 31GB)</div><div class="line">    NUMANode L#5 (P#5 31GB)</div><div class="line">    NUMANode L#6 (P#6 31GB)</div><div class="line">    NUMANode L#7 (P#7 31GB) //第1个Socket的最后一个Node</div><div class="line">      L2 L#14 (2048KB)</div><div class="line">        L1d L#56 (32KB) + L1i L#56 (32KB) + Core L#56 + PU L#56 (P#56)</div><div class="line">        L1d L#57 (32KB) + L1i L#57 (32KB) + Core L#57 + PU L#57 (P#57)</div><div class="line">        L1d L#58 (32KB) + L1i L#58 (32KB) + Core L#58 + PU L#58 (P#58)</div><div class="line">        L1d L#59 (32KB) + L1i L#59 (32KB) + Core L#59 + PU L#59 (P#59)</div><div class="line">      L2 L#15 (2048KB)</div><div class="line">        L1d L#60 (32KB) + L1i L#60 (32KB) + Core L#60 + PU L#60 (P#60)</div><div class="line">        L1d L#61 (32KB) + L1i L#61 (32KB) + Core L#61 + PU L#61 (P#61)</div><div class="line">        L1d L#62 (32KB) + L1i L#62 (32KB) + Core L#62 + PU L#62 (P#62)</div><div class="line">        L1d L#63 (32KB) + L1i L#63 (32KB) + Core L#63 + PU L#63 (P#63)</div><div class="line">  Package L#1 + L3 L#1 (64MB)   //第二个Socket，也是8个Node</div><div class="line">    NUMANode L#8 (P#8 31GB)</div><div class="line">      L2 L#16 (2048KB)</div><div class="line">        L1d L#64 (32KB) + L1i L#64 (32KB) + Core L#64 + PU L#64 (P#64)</div><div class="line">        L1d L#65 (32KB) + L1i L#65 (32KB) + Core L#65 + PU L#65 (P#65)</div><div class="line">        L1d L#66 (32KB) + L1i L#66 (32KB) + Core L#66 + PU L#66 (P#66)</div><div class="line">        L1d L#67 (32KB) + L1i L#67 (32KB) + Core L#67 + PU L#67 (P#67)</div><div class="line">      L2 L#17 (2048KB)</div><div class="line">        L1d L#68 (32KB) + L1i L#68 (32KB) + Core L#68 + PU L#68 (P#68)</div><div class="line">        L1d L#69 (32KB) + L1i L#69 (32KB) + Core L#69 + PU L#69 (P#69)</div><div class="line">        L1d L#70 (32KB) + L1i L#70 (32KB) + Core L#70 + PU L#70 (P#70)</div><div class="line">        L1d L#71 (32KB) + L1i L#71 (32KB) + Core L#71 + PU L#71 (P#71)</div><div class="line">      HostBridge L#7</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCIBridge</div><div class="line">              PCI 15b3:1015</div><div class="line">                Net L#17 &quot;eth2&quot;   //node8 上的网卡，eth2、eth3做了bonding</div><div class="line">              PCI 15b3:1015</div><div class="line">                Net L#18 &quot;eth3&quot;</div><div class="line">            PCIBridge</div><div class="line">              PCI 144d:a808</div><div class="line">            PCIBridge</div><div class="line">              PCI 144d:a808</div></pre></td></tr></table></figure>
<h2 id="不知名的一款CPU"><a href="#不知名的一款CPU" class="headerlink" title="不知名的一款CPU"></a>不知名的一款CPU</h2><p>当练习看看,随便看看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    128</div><div class="line">Socket(s):             1</div><div class="line">NUMA node(s):          2</div><div class="line">Model:                 0</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             64K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-63</div><div class="line">NUMA node1 CPU(s):     64-127</div><div class="line"></div><div class="line">#free -g</div><div class="line">              total        used        free      shared  buff/cache   available</div><div class="line">Mem:           1007         160         511           0         335         840</div><div class="line">Swap:             0           0           0</div><div class="line"></div><div class="line">#lstopo-no-graphics</div><div class="line">Machine (1008GB) + Socket L#0 (1008GB)</div><div class="line">  NUMANode L#0 (P#0 504GB)</div><div class="line">    L3 L#0 (64MB)</div><div class="line">      L2 L#0 (1024KB) + L1d L#0 (64KB) + L1i L#0 (64KB) + Core L#0 + PU L#0 (P#0)</div><div class="line">      L2 L#1 (1024KB) + L1d L#1 (64KB) + L1i L#1 (64KB) + Core L#1 + PU L#1 (P#1)</div><div class="line">      L2 L#2 (1024KB) + L1d L#2 (64KB) + L1i L#2 (64KB) + Core L#2 + PU L#2 (P#2)</div><div class="line">      L2 L#3 (1024KB) + L1d L#3 (64KB) + L1i L#3 (64KB) + Core L#3 + PU L#3 (P#3)</div><div class="line">      L2 L#4 (1024KB) + L1d L#4 (64KB) + L1i L#4 (64KB) + Core L#4 + PU L#4 (P#4)</div><div class="line">      L2 L#5 (1024KB) + L1d L#5 (64KB) + L1i L#5 (64KB) + Core L#5 + PU L#5 (P#5)</div><div class="line">      L2 L#6 (1024KB) + L1d L#6 (64KB) + L1i L#6 (64KB) + Core L#6 + PU L#6 (P#6)</div><div class="line">      L2 L#7 (1024KB) + L1d L#7 (64KB) + L1i L#7 (64KB) + Core L#7 + PU L#7 (P#7)</div><div class="line">      L2 L#8 (1024KB) + L1d L#8 (64KB) + L1i L#8 (64KB) + Core L#8 + PU L#8 (P#8)</div><div class="line">      L2 L#9 (1024KB) + L1d L#9 (64KB) + L1i L#9 (64KB) + Core L#9 + PU L#9 (P#9)</div><div class="line">      L2 L#10 (1024KB) + L1d L#10 (64KB) + L1i L#10 (64KB) + Core L#10 + PU L#10 (P#10)</div><div class="line">      L2 L#11 (1024KB) + L1d L#11 (64KB) + L1i L#11 (64KB) + Core L#11 + PU L#11 (P#11)</div><div class="line">      L2 L#12 (1024KB) + L1d L#12 (64KB) + L1i L#12 (64KB) + Core L#12 + PU L#12 (P#12)</div><div class="line">      L2 L#13 (1024KB) + L1d L#13 (64KB) + L1i L#13 (64KB) + Core L#13 + PU L#13 (P#13)</div><div class="line">      L2 L#14 (1024KB) + L1d L#14 (64KB) + L1i L#14 (64KB) + Core L#14 + PU L#14 (P#14)</div><div class="line">      L2 L#15 (1024KB) + L1d L#15 (64KB) + L1i L#15 (64KB) + Core L#15 + PU L#15 (P#15)</div><div class="line">      L2 L#16 (1024KB) + L1d L#16 (64KB) + L1i L#16 (64KB) + Core L#16 + PU L#16 (P#16)</div><div class="line">      L2 L#17 (1024KB) + L1d L#17 (64KB) + L1i L#17 (64KB) + Core L#17 + PU L#17 (P#17)</div><div class="line">      L2 L#18 (1024KB) + L1d L#18 (64KB) + L1i L#18 (64KB) + Core L#18 + PU L#18 (P#18)</div><div class="line">      L2 L#19 (1024KB) + L1d L#19 (64KB) + L1i L#19 (64KB) + Core L#19 + PU L#19 (P#19)</div><div class="line">      L2 L#20 (1024KB) + L1d L#20 (64KB) + L1i L#20 (64KB) + Core L#20 + PU L#20 (P#20)</div><div class="line">      L2 L#21 (1024KB) + L1d L#21 (64KB) + L1i L#21 (64KB) + Core L#21 + PU L#21 (P#21)</div><div class="line">      L2 L#22 (1024KB) + L1d L#22 (64KB) + L1i L#22 (64KB) + Core L#22 + PU L#22 (P#22)</div><div class="line">      L2 L#23 (1024KB) + L1d L#23 (64KB) + L1i L#23 (64KB) + Core L#23 + PU L#23 (P#23)</div><div class="line">      L2 L#24 (1024KB) + L1d L#24 (64KB) + L1i L#24 (64KB) + Core L#24 + PU L#24 (P#24)</div><div class="line">      L2 L#25 (1024KB) + L1d L#25 (64KB) + L1i L#25 (64KB) + Core L#25 + PU L#25 (P#25)</div><div class="line">      L2 L#26 (1024KB) + L1d L#26 (64KB) + L1i L#26 (64KB) + Core L#26 + PU L#26 (P#26)</div><div class="line">      L2 L#27 (1024KB) + L1d L#27 (64KB) + L1i L#27 (64KB) + Core L#27 + PU L#27 (P#27)</div><div class="line">      L2 L#28 (1024KB) + L1d L#28 (64KB) + L1i L#28 (64KB) + Core L#28 + PU L#28 (P#28)</div><div class="line">      L2 L#29 (1024KB) + L1d L#29 (64KB) + L1i L#29 (64KB) + Core L#29 + PU L#29 (P#29)</div><div class="line">      L2 L#30 (1024KB) + L1d L#30 (64KB) + L1i L#30 (64KB) + Core L#30 + PU L#30 (P#30)</div><div class="line">      L2 L#31 (1024KB) + L1d L#31 (64KB) + L1i L#31 (64KB) + Core L#31 + PU L#31 (P#31)</div><div class="line">      L2 L#32 (1024KB) + L1d L#32 (64KB) + L1i L#32 (64KB) + Core L#32 + PU L#32 (P#32)</div><div class="line">      L2 L#33 (1024KB) + L1d L#33 (64KB) + L1i L#33 (64KB) + Core L#33 + PU L#33 (P#33)</div><div class="line">      L2 L#34 (1024KB) + L1d L#34 (64KB) + L1i L#34 (64KB) + Core L#34 + PU L#34 (P#34)</div><div class="line">      L2 L#35 (1024KB) + L1d L#35 (64KB) + L1i L#35 (64KB) + Core L#35 + PU L#35 (P#35)</div><div class="line">      L2 L#36 (1024KB) + L1d L#36 (64KB) + L1i L#36 (64KB) + Core L#36 + PU L#36 (P#36)</div><div class="line">      L2 L#37 (1024KB) + L1d L#37 (64KB) + L1i L#37 (64KB) + Core L#37 + PU L#37 (P#37)</div><div class="line">      L2 L#38 (1024KB) + L1d L#38 (64KB) + L1i L#38 (64KB) + Core L#38 + PU L#38 (P#38)</div><div class="line">      L2 L#39 (1024KB) + L1d L#39 (64KB) + L1i L#39 (64KB) + Core L#39 + PU L#39 (P#39)</div><div class="line">      L2 L#40 (1024KB) + L1d L#40 (64KB) + L1i L#40 (64KB) + Core L#40 + PU L#40 (P#40)</div><div class="line">      L2 L#41 (1024KB) + L1d L#41 (64KB) + L1i L#41 (64KB) + Core L#41 + PU L#41 (P#41)</div><div class="line">      L2 L#42 (1024KB) + L1d L#42 (64KB) + L1i L#42 (64KB) + Core L#42 + PU L#42 (P#42)</div><div class="line">      L2 L#43 (1024KB) + L1d L#43 (64KB) + L1i L#43 (64KB) + Core L#43 + PU L#43 (P#43)</div><div class="line">      L2 L#44 (1024KB) + L1d L#44 (64KB) + L1i L#44 (64KB) + Core L#44 + PU L#44 (P#44)</div><div class="line">      L2 L#45 (1024KB) + L1d L#45 (64KB) + L1i L#45 (64KB) + Core L#45 + PU L#45 (P#45)</div><div class="line">      L2 L#46 (1024KB) + L1d L#46 (64KB) + L1i L#46 (64KB) + Core L#46 + PU L#46 (P#46)</div><div class="line">      L2 L#47 (1024KB) + L1d L#47 (64KB) + L1i L#47 (64KB) + Core L#47 + PU L#47 (P#47)</div><div class="line">      L2 L#48 (1024KB) + L1d L#48 (64KB) + L1i L#48 (64KB) + Core L#48 + PU L#48 (P#48)</div><div class="line">      L2 L#49 (1024KB) + L1d L#49 (64KB) + L1i L#49 (64KB) + Core L#49 + PU L#49 (P#49)</div><div class="line">      L2 L#50 (1024KB) + L1d L#50 (64KB) + L1i L#50 (64KB) + Core L#50 + PU L#50 (P#50)</div><div class="line">      L2 L#51 (1024KB) + L1d L#51 (64KB) + L1i L#51 (64KB) + Core L#51 + PU L#51 (P#51)</div><div class="line">      L2 L#52 (1024KB) + L1d L#52 (64KB) + L1i L#52 (64KB) + Core L#52 + PU L#52 (P#52)</div><div class="line">      L2 L#53 (1024KB) + L1d L#53 (64KB) + L1i L#53 (64KB) + Core L#53 + PU L#53 (P#53)</div><div class="line">      L2 L#54 (1024KB) + L1d L#54 (64KB) + L1i L#54 (64KB) + Core L#54 + PU L#54 (P#54)</div><div class="line">      L2 L#55 (1024KB) + L1d L#55 (64KB) + L1i L#55 (64KB) + Core L#55 + PU L#55 (P#55)</div><div class="line">      L2 L#56 (1024KB) + L1d L#56 (64KB) + L1i L#56 (64KB) + Core L#56 + PU L#56 (P#56)</div><div class="line">      L2 L#57 (1024KB) + L1d L#57 (64KB) + L1i L#57 (64KB) + Core L#57 + PU L#57 (P#57)</div><div class="line">      L2 L#58 (1024KB) + L1d L#58 (64KB) + L1i L#58 (64KB) + Core L#58 + PU L#58 (P#58)</div><div class="line">      L2 L#59 (1024KB) + L1d L#59 (64KB) + L1i L#59 (64KB) + Core L#59 + PU L#59 (P#59)</div><div class="line">      L2 L#60 (1024KB) + L1d L#60 (64KB) + L1i L#60 (64KB) + Core L#60 + PU L#60 (P#60)</div><div class="line">      L2 L#61 (1024KB) + L1d L#61 (64KB) + L1i L#61 (64KB) + Core L#61 + PU L#61 (P#61)</div><div class="line">      L2 L#62 (1024KB) + L1d L#62 (64KB) + L1i L#62 (64KB) + Core L#62 + PU L#62 (P#62)</div><div class="line">      L2 L#63 (1024KB) + L1d L#63 (64KB) + L1i L#63 (64KB) + Core L#63 + PU L#63 (P#63)</div><div class="line">    HostBridge L#0</div><div class="line">      PCIBridge</div><div class="line">        PCIBridge</div><div class="line">          PCI 1a03:2000</div><div class="line">            GPU L#0 &quot;controlD64&quot;</div><div class="line">            GPU L#1 &quot;card0&quot;</div><div class="line">      PCIBridge</div><div class="line">        PCI 1b4b:9235</div><div class="line">    HostBridge L#4</div><div class="line">      PCI 1ded:8001</div><div class="line">      PCI 1ded:8003</div><div class="line">  NUMANode L#1 (P#1 504GB)</div><div class="line">    L3 L#1 (64MB)</div><div class="line">      L2 L#64 (1024KB) + L1d L#64 (64KB) + L1i L#64 (64KB) + Core L#64 + PU L#64 (P#64)</div><div class="line">      L2 L#65 (1024KB) + L1d L#65 (64KB) + L1i L#65 (64KB) + Core L#65 + PU L#65 (P#65)</div><div class="line">      L2 L#66 (1024KB) + L1d L#66 (64KB) + L1i L#66 (64KB) + Core L#66 + PU L#66 (P#66)</div><div class="line">      L2 L#67 (1024KB) + L1d L#67 (64KB) + L1i L#67 (64KB) + Core L#67 + PU L#67 (P#67)</div><div class="line">      L2 L#68 (1024KB) + L1d L#68 (64KB) + L1i L#68 (64KB) + Core L#68 + PU L#68 (P#68)</div><div class="line">      L2 L#69 (1024KB) + L1d L#69 (64KB) + L1i L#69 (64KB) + Core L#69 + PU L#69 (P#69)</div><div class="line">      L2 L#70 (1024KB) + L1d L#70 (64KB) + L1i L#70 (64KB) + Core L#70 + PU L#70 (P#70)</div><div class="line">      L2 L#71 (1024KB) + L1d L#71 (64KB) + L1i L#71 (64KB) + Core L#71 + PU L#71 (P#71)</div><div class="line">      L2 L#72 (1024KB) + L1d L#72 (64KB) + L1i L#72 (64KB) + Core L#72 + PU L#72 (P#72)</div><div class="line">      L2 L#73 (1024KB) + L1d L#73 (64KB) + L1i L#73 (64KB) + Core L#73 + PU L#73 (P#73)</div><div class="line">      L2 L#74 (1024KB) + L1d L#74 (64KB) + L1i L#74 (64KB) + Core L#74 + PU L#74 (P#74)</div><div class="line">      L2 L#75 (1024KB) + L1d L#75 (64KB) + L1i L#75 (64KB) + Core L#75 + PU L#75 (P#75)</div><div class="line">      L2 L#76 (1024KB) + L1d L#76 (64KB) + L1i L#76 (64KB) + Core L#76 + PU L#76 (P#76)</div><div class="line">      L2 L#77 (1024KB) + L1d L#77 (64KB) + L1i L#77 (64KB) + Core L#77 + PU L#77 (P#77)</div><div class="line">      L2 L#78 (1024KB) + L1d L#78 (64KB) + L1i L#78 (64KB) + Core L#78 + PU L#78 (P#78)</div><div class="line">      L2 L#79 (1024KB) + L1d L#79 (64KB) + L1i L#79 (64KB) + Core L#79 + PU L#79 (P#79)</div><div class="line">      L2 L#80 (1024KB) + L1d L#80 (64KB) + L1i L#80 (64KB) + Core L#80 + PU L#80 (P#80)</div><div class="line">      L2 L#81 (1024KB) + L1d L#81 (64KB) + L1i L#81 (64KB) + Core L#81 + PU L#81 (P#81)</div><div class="line">      L2 L#82 (1024KB) + L1d L#82 (64KB) + L1i L#82 (64KB) + Core L#82 + PU L#82 (P#82)</div><div class="line">      L2 L#83 (1024KB) + L1d L#83 (64KB) + L1i L#83 (64KB) + Core L#83 + PU L#83 (P#83)</div><div class="line">      L2 L#84 (1024KB) + L1d L#84 (64KB) + L1i L#84 (64KB) + Core L#84 + PU L#84 (P#84)</div><div class="line">      L2 L#85 (1024KB) + L1d L#85 (64KB) + L1i L#85 (64KB) + Core L#85 + PU L#85 (P#85)</div><div class="line">      L2 L#86 (1024KB) + L1d L#86 (64KB) + L1i L#86 (64KB) + Core L#86 + PU L#86 (P#86)</div><div class="line">      L2 L#87 (1024KB) + L1d L#87 (64KB) + L1i L#87 (64KB) + Core L#87 + PU L#87 (P#87)</div><div class="line">      L2 L#88 (1024KB) + L1d L#88 (64KB) + L1i L#88 (64KB) + Core L#88 + PU L#88 (P#88)</div><div class="line">      L2 L#89 (1024KB) + L1d L#89 (64KB) + L1i L#89 (64KB) + Core L#89 + PU L#89 (P#89)</div><div class="line">      L2 L#90 (1024KB) + L1d L#90 (64KB) + L1i L#90 (64KB) + Core L#90 + PU L#90 (P#90)</div><div class="line">      L2 L#91 (1024KB) + L1d L#91 (64KB) + L1i L#91 (64KB) + Core L#91 + PU L#91 (P#91)</div><div class="line">      L2 L#92 (1024KB) + L1d L#92 (64KB) + L1i L#92 (64KB) + Core L#92 + PU L#92 (P#92)</div><div class="line">      L2 L#93 (1024KB) + L1d L#93 (64KB) + L1i L#93 (64KB) + Core L#93 + PU L#93 (P#93)</div><div class="line">      L2 L#94 (1024KB) + L1d L#94 (64KB) + L1i L#94 (64KB) + Core L#94 + PU L#94 (P#94)</div><div class="line">      L2 L#95 (1024KB) + L1d L#95 (64KB) + L1i L#95 (64KB) + Core L#95 + PU L#95 (P#95)</div><div class="line">      L2 L#96 (1024KB) + L1d L#96 (64KB) + L1i L#96 (64KB) + Core L#96 + PU L#96 (P#96)</div><div class="line">      L2 L#97 (1024KB) + L1d L#97 (64KB) + L1i L#97 (64KB) + Core L#97 + PU L#97 (P#97)</div><div class="line">      L2 L#98 (1024KB) + L1d L#98 (64KB) + L1i L#98 (64KB) + Core L#98 + PU L#98 (P#98)</div><div class="line">      L2 L#99 (1024KB) + L1d L#99 (64KB) + L1i L#99 (64KB) + Core L#99 + PU L#99 (P#99)</div><div class="line">      L2 L#100 (1024KB) + L1d L#100 (64KB) + L1i L#100 (64KB) + Core L#100 + PU L#100 (P#100)</div><div class="line">      L2 L#101 (1024KB) + L1d L#101 (64KB) + L1i L#101 (64KB) + Core L#101 + PU L#101 (P#101)</div><div class="line">      L2 L#102 (1024KB) + L1d L#102 (64KB) + L1i L#102 (64KB) + Core L#102 + PU L#102 (P#102)</div><div class="line">      L2 L#103 (1024KB) + L1d L#103 (64KB) + L1i L#103 (64KB) + Core L#103 + PU L#103 (P#103)</div><div class="line">      L2 L#104 (1024KB) + L1d L#104 (64KB) + L1i L#104 (64KB) + Core L#104 + PU L#104 (P#104)</div><div class="line">      L2 L#105 (1024KB) + L1d L#105 (64KB) + L1i L#105 (64KB) + Core L#105 + PU L#105 (P#105)</div><div class="line">      L2 L#106 (1024KB) + L1d L#106 (64KB) + L1i L#106 (64KB) + Core L#106 + PU L#106 (P#106)</div><div class="line">      L2 L#107 (1024KB) + L1d L#107 (64KB) + L1i L#107 (64KB) + Core L#107 + PU L#107 (P#107)</div><div class="line">      L2 L#108 (1024KB) + L1d L#108 (64KB) + L1i L#108 (64KB) + Core L#108 + PU L#108 (P#108)</div><div class="line">      L2 L#109 (1024KB) + L1d L#109 (64KB) + L1i L#109 (64KB) + Core L#109 + PU L#109 (P#109)</div><div class="line">      L2 L#110 (1024KB) + L1d L#110 (64KB) + L1i L#110 (64KB) + Core L#110 + PU L#110 (P#110)</div><div class="line">      L2 L#111 (1024KB) + L1d L#111 (64KB) + L1i L#111 (64KB) + Core L#111 + PU L#111 (P#111)</div><div class="line">      L2 L#112 (1024KB) + L1d L#112 (64KB) + L1i L#112 (64KB) + Core L#112 + PU L#112 (P#112)</div><div class="line">      L2 L#113 (1024KB) + L1d L#113 (64KB) + L1i L#113 (64KB) + Core L#113 + PU L#113 (P#113)</div><div class="line">      L2 L#114 (1024KB) + L1d L#114 (64KB) + L1i L#114 (64KB) + Core L#114 + PU L#114 (P#114)</div><div class="line">      L2 L#115 (1024KB) + L1d L#115 (64KB) + L1i L#115 (64KB) + Core L#115 + PU L#115 (P#115)</div><div class="line">      L2 L#116 (1024KB) + L1d L#116 (64KB) + L1i L#116 (64KB) + Core L#116 + PU L#116 (P#116)</div><div class="line">      L2 L#117 (1024KB) + L1d L#117 (64KB) + L1i L#117 (64KB) + Core L#117 + PU L#117 (P#117)</div><div class="line">      L2 L#118 (1024KB) + L1d L#118 (64KB) + L1i L#118 (64KB) + Core L#118 + PU L#118 (P#118)</div><div class="line">      L2 L#119 (1024KB) + L1d L#119 (64KB) + L1i L#119 (64KB) + Core L#119 + PU L#119 (P#119)</div><div class="line">      L2 L#120 (1024KB) + L1d L#120 (64KB) + L1i L#120 (64KB) + Core L#120 + PU L#120 (P#120)</div><div class="line">      L2 L#121 (1024KB) + L1d L#121 (64KB) + L1i L#121 (64KB) + Core L#121 + PU L#121 (P#121)</div><div class="line">      L2 L#122 (1024KB) + L1d L#122 (64KB) + L1i L#122 (64KB) + Core L#122 + PU L#122 (P#122)</div><div class="line">      L2 L#123 (1024KB) + L1d L#123 (64KB) + L1i L#123 (64KB) + Core L#123 + PU L#123 (P#123)</div><div class="line">      L2 L#124 (1024KB) + L1d L#124 (64KB) + L1i L#124 (64KB) + Core L#124 + PU L#124 (P#124)</div><div class="line">      L2 L#125 (1024KB) + L1d L#125 (64KB) + L1i L#125 (64KB) + Core L#125 + PU L#125 (P#125)</div><div class="line">      L2 L#126 (1024KB) + L1d L#126 (64KB) + L1i L#126 (64KB) + Core L#126 + PU L#126 (P#126)</div><div class="line">      L2 L#127 (1024KB) + L1d L#127 (64KB) + L1i L#127 (64KB) + Core L#127 + PU L#127 (P#127)</div><div class="line">    HostBridge L#5</div><div class="line">      PCIBridge</div><div class="line">        PCI 8086:0b60</div><div class="line">    HostBridge L#7</div><div class="line">      PCIBridge</div><div class="line">        PCIBridge</div><div class="line">          PCIBridge</div><div class="line">            PCI 1af4:1001</div><div class="line">          PCIBridge</div><div class="line">            PCI 1ded:1001</div><div class="line">            PCI ffff:ffff</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>希望通过具体又不同的CPU案例展示，让你对CPU的结构有一些整体认识</p>
<p>请问：Hygon C86 7260 这块CPU每个Die的L2、L3分别是多大？</p>
<p>请思考，最近10年CPU的性能没啥大的进不了(如下图红色部分，每年3%)，但是这么多年工艺还在进步，集成的晶体管数量</p>
<p><img src="/images/951413iMgBlog/FvXLnPB8aqT7iJJuKdMfc_rpypsa.jpeg" alt="img"></p>
<p>//这张图每一本计算机体系结构的教材都有引用(没有的话这教材可以扔了)，你知道我博客里哪篇文章放了这图吗？从这个图你还能解析出来哪些东西？</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;几款不同的CPU一些数据–备查&quot;&gt;&lt;a href=&quot;#几款不同的CPU一些数据–备查&quot; class=&quot;headerlink&quot; title=&quot;几款不同的CPU一些数据–备查&quot;&gt;&lt;/a&gt;几款不同的CPU一些数据–备查&lt;/h1&gt;&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;
    
    </summary>
    
      <category term="CPU" scheme="https://plantegg.github.io/categories/CPU/"/>
    
    
      <category term="海光" scheme="https://plantegg.github.io/tags/%E6%B5%B7%E5%85%89/"/>
    
      <category term="超线程" scheme="https://plantegg.github.io/tags/%E8%B6%85%E7%BA%BF%E7%A8%8B/"/>
    
      <category term="Zen" scheme="https://plantegg.github.io/tags/Zen/"/>
    
      <category term="hygon" scheme="https://plantegg.github.io/tags/hygon/"/>
    
      <category term="AMD" scheme="https://plantegg.github.io/tags/AMD/"/>
    
  </entry>
  
  <entry>
    <title>你要不要搞副业</title>
    <link href="https://plantegg.github.io/2023/12/21/%E4%BD%A0%E8%A6%81%E4%B8%8D%E8%A6%81%E6%90%9E%E5%89%AF%E4%B8%9A/"/>
    <id>https://plantegg.github.io/2023/12/21/你要不要搞副业/</id>
    <published>2023-12-21T04:30:03.000Z</published>
    <updated>2024-02-23T13:47:39.146Z</updated>
    
    <content type="html"><![CDATA[<h1 id="你要不要搞副业？"><a href="#你要不要搞副业？" class="headerlink" title="你要不要搞副业？"></a>你要不要搞副业？</h1><p>最近网上看到很多讨论搞副业和远程工作的，我也说点自己的经验+看法</p>
<p>当然这完全是出于个人认知肯定不是完全对的、也不一定适合你，看看当个参考，经验重在真实</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>年轻人最好的<strong>副业</strong>就是做好本职工作，深耕多积累自己的专业方向，只有当你在主业上再也无法精进的时候可以考虑跳槽或者<strong>副业</strong>， 搞副业相对适合大多年纪大的人，他们触碰到了自己的天花板，可以折腾玩玩等等</p>
<h2 id="我搞过的副业"><a href="#我搞过的副业" class="headerlink" title="我搞过的副业"></a>我搞过的副业</h2><p>我搞过很多副业，多到我不好意思说出来。low到檫玻璃，大到开厂、买船，但是你看就是没去折腾抄房子(这些年只有炒房子的这个副业赚钱最稳、最快)。我也特别关心别人的副业、主业，熟的会打破砂锅问到底，所以下面说的只保证真实</p>
<h3 id="最大一笔副业"><a href="#最大一笔副业" class="headerlink" title="最大一笔副业"></a>最大一笔副业</h3><p>通过SEO接了一个国外一个订单，交给长三角的工厂代工，赚了几十万，一次性，几乎没有成本</p>
<p>当时帮一个做工厂的朋友做网站，域名空间都是我掏钱(要给我我没好意思要，本身不值钱)，让留个邮箱厂长没有，后来留的我的。</p>
<p>然后来了几个咨询的介绍给厂里了，最后成了两个客户。但是有一个韩国客户(采购是广州一个提篮子的公司)，去厂里谈了几次细节谈不好，我就出马给把细节、打样、交货谈好了。</p>
<p>最后做好后发货直接到韩国，发一次运费几万块(到付)，其中有一批压坏了点那个区的顺丰经理过来道歉、给定做包装箱……</p>
<p>缺点是做完就没有了，那个产品不具有持续性，如果可以持续我应该能继续搞，另外借着这个客户去厂里跑得多，也发展了一些其他客户利润太薄加上后来真个行情不好就实在做不下去了，产品烂大街没人要了，珠三角那个生产模仿能力都太强了</p>
<p>之前介绍给厂里的两个客户，厂里自己对接的，其中一个厂里赚了一些钱，另外一个飞单好几十万，人家直接注销公司赖账的玩法，所以你看风险很多。不过要是去接这个单就不会出现这种情况，你最后尾款飞几千万把块我是有预期的，整个一个订单一分钱都没拿到简直就是傻子做生意，也纵容了坏人</p>
<p>比如很多人靠白嫖样品吃饭，我的策略是：样品、打样都要收钱，但是正式下单就抵扣货款，这么做能淘汰90%的虚假用户，节省自己的时间。比如便宜样品可以免费但是邮费到付、你亲自上门当然可以送几个。</p>
<h3 id="知识星球总结"><a href="#知识星球总结" class="headerlink" title="知识星球总结"></a>知识星球总结</h3><p>做星球的话10万粉丝算是凑合，百万粉丝洒洒水啦，几万粉丝很痛苦</p>
<p>知识星球不适合IT技术类，他们有平台的流量，全靠自己运营；相对来说极客时间、慕课之类的能有平台给你导流；</p>
<p>星球的优点是入门门槛低</p>
<h4 id="我的星球数据"><a href="#我的星球数据" class="headerlink" title="我的星球数据"></a>我的星球数据</h4><p>开星球的时候就承诺过了，要公布数据，当时也有一部分原因是对运营一个星球的数据有着好奇</p>
<p>9个月的星球运营500多成员，一年收入大几万，这还只是第一年，主要靠我的推特3万多粉丝里面划拉人员过去，第二年就不会有这么多成员了，因为你不可能一年再涨2万新粉丝</p>
<p>我的粉丝转化率是2%，算是还不错的了，所以如果你有10万粉丝大概能有1000-2000铁粉，那差不多一年能靠这些有个20来万的收入，所以算还凑合，可以简单养家。</p>
<p>上点我的星球运营真实数据，先看最重要的收入数据</p>
<p><img src="/images/951413iMgBlog/image-20231221090708084.png" alt="image-20231221090708084"></p>
<p>星球刚开通前三个月收入最高，把一年的收入都提前拿走了，我这虽然才9个月，后面三个月也不用看了，几乎可以忽略：</p>
<p><img src="/images/951413iMgBlog/image-20231221090758574.png" alt="image-20231221090758574"></p>
<p>运营效果，来估算转化率</p>
<p><img src="/images/951413iMgBlog/image-20231221090420085.png" alt="image-20231221090420085"></p>
<p>我的星球讲究干货，宁缺毋滥，所以也没有其他星球常用的运维手段：作业、打卡(我恨死打卡这种傻逼行为了)</p>
<p>续费的话，我的星球是本月15号开通续费，我也没发通知，居然有人续费了，我猜应该是平台自动通知的：</p>
<p><img src="/images/951413iMgBlog/image-20231221094647500.png" alt="image-20231221094647500"></p>
<h4 id="星球总结"><a href="#星球总结" class="headerlink" title="星球总结"></a>星球总结</h4><ul>
<li>程序员成功的星球都是靠贩卖焦虑、offer、算法、面试，所以你真要想搞不要想着自己技术多好，要想想你有没有适合拿offer(这个活该赚钱)的本领</li>
<li>星球的活跃度靠打卡</li>
<li>搞一些有流量的好朋友互相吹捧、交换粉丝</li>
</ul>
<h3 id="带货"><a href="#带货" class="headerlink" title="带货"></a>带货</h3><p>这个门槛最低，你看到好的产品复制链接，到淘宝联盟上做下链接转换：<a href="https://pub.alimama.com/?forward=http%3A%2F%2Fpub.alimama.com%2Fportal%2Feffect%2Forder%2FoverviewOrder%2Fpage%2Findex.htm#!/index?curValue=nav_0&amp;forward=" target="_blank" rel="external">https://pub.alimama.com/?forward=http%3A%2F%2Fpub.alimama.com%2Fportal%2Feffect%2Forder%2FoverviewOrder%2Fpage%2Findex.htm#!/index?curValue=nav_0&amp;forward=</a></p>
<p>到处发然后就能拿佣金了，目前国内个人带货扛把子就是个程序员，还是个高中毕业考不上大学找个培训班入行的程序员，会用Delphi写个群发工具，然后管理一堆微信、QQ群；让别人去帮他带货他能提成，这个段位又高级了一层</p>
<p>只靠自己的朋友圈肯定是不行的，起步得是百万粉丝才行，或者你有渠道总能搞到好的货品</p>
<p>给你们贴个我2023年10月的带货数据，当个参考，就是在3万粉丝的推特上带的货，转换率肯定是很惨的，为这131块的佣金你可以搜搜我发了多少推：</p>
<p><img src="/images/951413iMgBlog/image-20231221092640430.png" alt="image-20231221092640430"></p>
<p>这个工作完全可以远程——算是你们理想中的远程工作吗？但是这个市场必然只能容纳很少的人，搞好了是可以发财的 :) </p>
<p>如果你口才好、煽动力强不去搞自播带货都对不住自己</p>
<h2 id="为什么不推荐搞副业"><a href="#为什么不推荐搞副业" class="headerlink" title="为什么不推荐搞副业"></a>为什么不推荐搞副业</h2><p>副业就是副业，要不怎么不叫主业呢？真搞好了、容易搞好必然有更多的人进来把他从副业做成主业！</p>
<p>先把主业搞好，尤其是年轻人。副业超过主业的毕竟是极少极少，还有点运气和背景成分</p>
<p>投入小(钱、时间都算)可以轻度参与混点经验，但不要抱太高期望</p>
<p>比如我就做过统计：</p>
<blockquote>
<p>拉了一下记账软件上历年的数据，古早年代没记账就没有了，最近几年<strong>收入</strong>的话95%以上都是工资性收入，投资大概率是亏钱的，房租能有点、外快能有点，放到整体几乎可以忽略 </p>
<p>开支的话也他妈主要是买房+房贷，如果不考虑首付+提前还贷倒是占比不夸张，日常开支真用不了多少钱，万幸几乎没有医疗开支</p>
</blockquote>
<p>主业确定没法精进、跳槽之类的，这时可以考虑下副业，当然如果你碰到了副业的“好机会” 也可以尝试一下</p>
<h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><p>先试试做做博客、公众号，看自己能运营到多少粉丝，你平时上网刷口水文章也是打发，然后试试带货</p>
<p>程序员方向基本不来钱，虽然这些行业很赚钱，但是这里也聚集了相对聪明人，你能搞他们也能搞相对更红海一些</p>
<p>可以跳出技术方向或者横向关联的方向多动动脑子，门槛低竞争就必然大，比如教英语和教程序员肯定英语的市场大多了</p>
<p>组织活动，比如组织大家打羽毛球、滑雪，羽毛球需要水平差不多的、人多一点才好玩，一般去场馆8折拿下场地，然后大家AA费用，赚这2折的差价，一次一般能赚80块，一周多组织几次，搞得好的话一个月也有2000块，关键是顺便自己打打球，真当副业的话也很香！再要多赚也很难，不过可续性很强</p>
<p>上次从黄牛手里买了个医院的专家号，2000块，你以为他们有渠道？其实他们建个微信群，找一堆有闲缺钱的人，接到需求了就到群里喊一嗓子，谁有本事抢到了从2000块里分几百，这种专家号根据难易程度从几百块到几千块，真是市场化了</p>
<p>当然还有一些灰产黑产大家就不要碰了我也不说了，大家耗子尾汁，赚钱是应该的但是要合法</p>
<p>写得很零散，没有什么详细的分析和套路，就是罗列事实和数据，你可以根据自己的情况来分析考虑</p>
<p>你要有什么好建议和经验欢迎在推特上 <a href="https://twitter.com/plantegg" target="_blank" rel="external">@plantegg</a> 给我留言、私信，特别好的我会收集到博客上，这篇博客我会持续更新……</p>
<p>最后放个我<a href="https://plantegg.github.io/2024/02/20/%E5%BF%85%E8%AF%BB%20%E6%98%9F%E7%90%83%E6%88%90%E9%95%BF%E8%B7%AF%E5%BE%84/">星球的广告</a>：</p>
<p><img src="/images/951413iMgBlog/image-20230407232314969.png" alt="image-20230407232314969" style="zoom:50%;"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;你要不要搞副业？&quot;&gt;&lt;a href=&quot;#你要不要搞副业？&quot; class=&quot;headerlink&quot; title=&quot;你要不要搞副业？&quot;&gt;&lt;/a&gt;你要不要搞副业？&lt;/h1&gt;&lt;p&gt;最近网上看到很多讨论搞副业和远程工作的，我也说点自己的经验+看法&lt;/p&gt;
&lt;p&gt;当然这完全是
    
    </summary>
    
      <category term="others" scheme="https://plantegg.github.io/categories/others/"/>
    
    
      <category term="星球" scheme="https://plantegg.github.io/tags/%E6%98%9F%E7%90%83/"/>
    
      <category term="副业" scheme="https://plantegg.github.io/tags/%E5%89%AF%E4%B8%9A/"/>
    
      <category term="带货" scheme="https://plantegg.github.io/tags/%E5%B8%A6%E8%B4%A7/"/>
    
      <category term="赚钱" scheme="https://plantegg.github.io/tags/%E8%B5%9A%E9%92%B1/"/>
    
  </entry>
  
  <entry>
    <title>王强2012在北大的演讲——读书毁了我</title>
    <link href="https://plantegg.github.io/2023/12/19/%E7%8E%8B%E5%BC%BA2013%E5%9C%A8%E5%8C%97%E5%A4%A7%E7%9A%84%E6%BC%94%E8%AE%B2%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E6%AF%81%E4%BA%86%E6%88%91/"/>
    <id>https://plantegg.github.io/2023/12/19/王强2013在北大的演讲——读书毁了我/</id>
    <published>2023-12-19T04:30:03.000Z</published>
    <updated>2023-12-19T03:26:17.413Z</updated>
    
    <content type="html"><![CDATA[<h1 id="王强2012在北大的演讲——读书毁了我"><a href="#王强2012在北大的演讲——读书毁了我" class="headerlink" title="王强2012在北大的演讲——读书毁了我"></a>王强2012在北大的演讲——读书毁了我</h1><p>视频版本50分钟，不含问答，建议看文字版，这是视频： <a href="https://weibo.com/6033438343/Nxw2Fj2oN?pagetype=profilefeed" target="_blank" rel="external">https://weibo.com/6033438343/Nxw2Fj2oN?pagetype=profilefeed</a> </p>
<h2 id="我为什么要发这篇"><a href="#我为什么要发这篇" class="headerlink" title="我为什么要发这篇"></a>我为什么要发这篇</h2><p>到处都是私域、卖货、视频等，好的文字不多了，这篇对应视频的文字版找起来不容易，所以特意在我的博客上备一份(我的博客极少极少极少发别人的东西)，也希望你备份一下。</p>
<p>王强是新东方合伙人，口才一流、演讲技能一流，当脱口秀看吧。</p>
<p>我就只能羡慕这种智商一流的人，这人智商在北大里估计都是前10%，而你我是北大都考不上的，所以<strong>他说的方法你就看看好了，不适合你</strong>，但值得你从中间提炼适合你的不分，读经典拿书，读不懂就不要像他一样死磕，找些浅显的、增加你经验的书先看看，回头再来读经典</p>
<p>但大多时候我们都不知道哪些是经典，对别人是经典对你还是经典吗？</p>
<p>这人是个程序员，学了C 和CPP，对你有点参考意义</p>
<p>在我的知识星球就一直强调：不要跟着信息流跑，多去看最早发表的东西(多年沉淀的干货等等)</p>
<p><img src="/images/951413iMgBlog/image-20231219105757910.png" alt="image-20231219105757910"></p>
<p>下面是正文，扯淡栩栩如生，那不是重点。我就不给大家划重点了，都是重点:) ，文字版来自这里：<a href="https://book.douban.com/review/10286767/" target="_blank" rel="external">https://book.douban.com/review/10286767/</a></p>
<h2 id="演讲正文——读书毁了我"><a href="#演讲正文——读书毁了我" class="headerlink" title="演讲正文——读书毁了我"></a>演讲正文——读书毁了我</h2><p>王强：谢谢小平。因为小平在读书上花的时间比较少，因为我都替他读了，他只问我结论是什么，他的知识并没有落后，而我视力在衰减。当然老俞，当年我引他进入读黄色小说的境界，至今老俞还不肯自拔，他是黄种人的代表，所以他成功了。作为人生，我今年51岁，我和老俞同年同月生，不是同一天，也不是同一个地方，因为老俞比我大一周，小平比我大六岁，是我的兄长，当年克强同志是北大团委书记，他直接受克强同志领导的北大团委文化部部长，我是直接受徐小平同志掌管的第一任北大学生艺术团团长，我当时管的是英达、英壮这样的人。而俞敏洪是北大最有特权的艺术团的观众，因为经常拉幕的时候缺一个人，我们说老俞能不能帮帮忙，老俞说能让我看吗，我说当然。所以从此老俞锻炼了强大拉幕能力。所以任何细节不要忽略，都是人生。</p>
<p>​    </p>
<p>我今天想跟大家分享为什么读书在人的生命成长中非常重要。我这个题目叫”读书毁了我”，很多读者没看到这本书的内容就开始评论，说我是标题党，撒狗血。我说不是我撒，因为当年我的很多文章结集的时候徐晓，她是中国最伟大的女编辑之一，被称为京城四大美编，美女编辑。当年我说马云怎么有领袖魅力，他有领子有袖子，但没有领袖魅力，走到街上城管一定第一个扑向他，因为连人长的都不一样，像是从外星回来的，而俞敏洪长的就跟季羡林一样，就像去外星的人。小平虽然是天使，但是从体重来说，给他四双翅膀他也飞不起来。所以人啊，当你不知道要做什么事情，当你做的事情不能带给社会意义的时候，当你做的事情的意义不能给人的生命产生共鸣的时候，你的存在实际上是被人忽略的。</p>
<p>我现在自豪的是，我现在经常回忆，北大这个地方怎么产生企业家？因为我是内蒙古来的，我以为是学术的殿堂，清华可能产生企业家，因为他们搞科技，高科技，北大当年我们就是精神自由的三角地，都是自焚的地方，它只是结束肉体的地方，让灵魂再生的地方，从来不是做什么上市，这些好象与北大没关，但是人生经历这么多年，我发现北大为什么产生这样的人。</p>
<p>我就拿32楼举例，我们住的16楼没了，当时我和老俞作为北大年轻教师住在16楼，但是拿32楼文科男科楼讲，当时北大英文系来说，我们住在二层，这些年一过，发现诞生一个伟大的企业，那就是在教育界的俞敏洪为代表的新东方。再往第三层，我忽然发现当年有一个来自山西的青年，天天在水房里光着上半身，一盆冷水浇下来，唱着夜里寻他千百度，你在哪呢，天天念百度两个字，因为他是北大图书馆系的，后来诞生了百度李彦宏，当时哪能想到，因为从任何知识储备，他不能做企业，他不仅是学图书馆系，而且专业简直离成功太远，他是古典文献编目专业，清朝以后的事他都不管了，他直接奔甲骨文去了。所以他天天念where  are  you，那时一下雨雨水就没过膝盖，当时找不到了，where are you,搜索就开始了。</p>
<p>​    </p>
<p>再往上走，四层楼住着北大中文系的，当年都是产生愤怒诗人，连名字都是愤怒的不得了，黄怒波。这么多年刮目相看，他要买下冰岛,他成为了中坤集团的创始人。更匪夷所思的是，北大中文系的女生楼里出来一个长相非常平和的人，她充满着激情，最后由于自己解决终身的情感问题，她就是后来创造了世纪佳人。这些人，是中文系的、图书馆系、英文系，这些与金融、融资、管理完全没关，但是我后来想怎么会出现这么一些奇特的企业，由这些人做的，我就想到北大给了一个东西，就是怎么样塑造你生命的东西，那是对知识的渴望、饥饿，超过了性本身。当年我们对性的渴望，但是校规非常严格，同性只能找同性。但是我们还没有得到同性方面的启蒙，当时洗澡堂，一个水龙头下，十个男生光溜溜的彼此互帮互学，那一个水龙头下十个手，像董存瑞炸碉堡的感觉。</p>
<p>​    </p>
<p>但是我们就这么过来的，为什么我发现北大这个氛围是崇尚超越世俗吸引力的更伟大的东西，那就是对知识的诉求。我不知道你们现在读书状况什么样，整个八十年代北大最神圣的地方两个地方，一个是厕所，一个是图书馆，图书馆从早上六点，如果你不能到达写着邓小平题字的北京大学图书馆下面排队，你这一天与图书馆的座位已经无缘了，所以大部分人凌晨四点就起来了，然后带着一个冷馒头，从厨房吃剩下的或者从同学那偷来的，俞敏洪经常偷我馒头。然后借一堆书放在这里，睡也睡在桌子前面。所以当年读书氛围非常好，如果市场上出现一本书，你如果去晚了根本的得不到。我在中文系选了中国现代文学史，第一次讲到围城，我赶快到北大图书馆，没下课我就去了，但是没想到没了，结果等到快毕业的时候我才借到这本书，这就是当年北大的状况。而正是这样，读经典，读那些能够改变我们生命轨迹的那些书籍，成了北大人最后离开校门走到世界，不管你走到哪个领域，最后比别人走的稍微远一点的保证，因为那些书不是字，它也是生命，而这些生命比起你自己的生命来说，它能引领你的生命，它能型塑你的生命，所以我说这个世界上只有两种文字，一类文字是文字垃圾，（Informed ）随处可得；但是有一类是非常好的，（Form you ）就是它能够把你变成完全不同的另一个。所以我这个书题目叫读书毁了我，当年起的时候，徐晓给我提的题目，说这个题目在她心中好多年。她说你这个文字挺适合这个，我说”读书毁了我”，这个东西大家看到以后会非常奇怪，怎么会毁了你吗？她说毁就跟北京人说的，一团泥逐渐成型，就成了崭新的东西。我想如果毁用在这个意义上，它必须能够彻底摧毁你旧我，过去的我，狭隘封闭的我，然后诞生一个崭新的、开阔的、阳光的我，那读书就全部有了意义，这也就是当年北大为什么那些人天天想到的不是世俗的追求，但是到了世俗里一看，稍微一动他就得到了所谓世俗追求的东西呢？我觉得这是北大给了我们吸取信息的能力，分析问题能力，所以我今天想跟大家分析分析读书。</p>
<p>​    </p>
<p>我当年在新东方接受采访的时候，我说要读书只读一流的书，做人只做一流的人。为什么这么说？因为现在信息充斥的海洋里，我们人生有幸，但是我们要读的接受的信息太多了，如何辨别书？什么东西该读呢？跟大家分享一下我读书的选择，第一，畅销书我坚决不读，不是我牛，看不起畅销，因为我知道我生命有限，已经51岁了，再向苍天借30年，我已经80岁了，所以我还有30年读书的时间，我只能读人类历史上没被大浪淘沙过的东西，所以我现在读书越来越往前读，中国的典籍越读越遇到先秦，西方也顶多读到二十世纪中叶，因为我觉得那个时候的人，他们创作文字，他们的文字是他生命的写照。比如说现在翻译小说，坦率的讲，我只选择那些真正的以生命完成一部译作的大家们的作品，哪怕这个作品并不时髦。比如说《悲惨世界》，李丹翻译，本来他可以成为另一个徐悲鸿，但是他们放弃了，几十年如一日，文革如此惨烈，李丹最后剩几卷没有翻，他的太太继续翻，这本著作我是一读再读。像朱生豪翻了27本莎士比亚的剧，但是你现在再读任何一本，哪能找到朱生豪当年用汉字表现出的莎士比亚。所以我常常更小平说，有一天我们一定要拍朱生豪的电影，这个电影叫做《莎士比亚在中国》，如果没有朱生豪，全世界四分之一的人不会第一时间知道还有莎士比亚，所以莎士比亚的墓地应该旁边有一个朱生豪的碑，多么伟大，四分之一的人口是通过朱生豪第一时间知道的英国还有一个莎士比亚。</p>
<p>​    </p>
<p>所以我觉得读一流的书就要衡量，这个作家进入书前的状态是什么？他是为了满足市场的需求，所谓市场的利益，还是他倾其鲜血、生命和经历融入的东西呢？坦率的讲，我在北大整整呆了十年，做了四年学生，当了六年老师，离开的时候是英语系的讲师，当然我的宿命也从此定了，只能讲，没当教授，坐不下来，更没有博导那个肌肉。但是我作为见证，俞敏洪、小平他们当年都是如饥似渴的在读书，尽管领域不同。老俞主管肉体，小平是超越肉体和灵魂的东西。当年小平是我们当中第一个出国的，我记得那天下着毛毛细雨，小平当年住在北大小院，32楼前面的一个小院，最早北大出版社的地方，他住在那里，因为他是团委干部，所以有四合院的那种感觉。那说要离开了，要到美国，然后到加拿大去追求他的音乐梦，我就知道，他当时为凑足他的机票，他珍藏了作为任何一个学生很难想象的格罗夫音乐辞典，到处拍卖，他希望获得飞到美国的机票。他终于卖出了，用一半的钱请我在西门一个火锅店吃了火锅，最后大家挥泪离别，从此我步上小平的后尘，我也要到国外去，老俞也想步我们的后尘，但是国外暂时不需要他。</p>
<p>​    </p>
<p>为什么读经典能够改变我们呢？文学的功能是什么呢？在我看，文学的功能就像我在序里说的，如果一个真正有力量的文字，它一定是能够对我们的审美产生奇异的再造，它对我们对真的追求有奇异的启示，它对我们对善的追求有如饥似渴的充电的感觉，所以我们对人类最高的价值，真的、善的和美的就会变成我们的血液，一旦人身体里有这三样东西，你在社会上走向现实中，你就不会轻易的被世俗的所谓流行的价值、暂时的价值，甚至非常糟糕的价值轻易扭转。我的这个读书基因从这开始，从我中学，我分两个阶段，一个是中学，一个是北大。我之所以能进北大，一半我认为是老天眷顾了我，因为大家知道，我是第三届大学生，小平是第一届，克强是78级，克强比你低一级，但现在比你高很多级，这就是人生最后不一样的东西。所以人生，体重太大，最后他也走不太远，所以大家现在要减肥。</p>
<p>​    </p>
<p>高中我是来自内蒙古，我们那个学校在当地有一个叫包头的地方，都不算是优秀学校，但是为什么我能够走进北大呢？我忽然怀念起我当时在高中遇到的一批中国我认为最顶级的老师，为什么这些老师会到包头呢？感谢文化大革命，全是右派，一个一个发配到包头，结果被我遇上了，他们教会我全部的东西都是以他们各自的方式告诉我，真的、善的、美的，一定是从那些流传在人类时间长河里面没被淘汰的文字中，存在那里。你如果不断的在这样的文字中熏陶的时候，当你离开这些文字的时候，这些文字就变成了你的世界，所以从单词word到world中间只差一个字l，这个L，这就是文字、阅读和真正人生世界的完全最简单的逻辑关系。如果你读到的不是真文字，你遇到的不是真语言，你最后见到的一定是虚幻的世界，不是真实的世界。这也是为什么读书真正要对你产生作用，会产生什么呢？它一定要和你真正的生命融汇在一起，而几千百年来，没有被淘汰的著作，因为一代代人如果都这么选择的话，你一定要相信人类的选择，而不是现在市场的选择，更不是广告词的选择。所以这是非常关键的，我在序言里提到，去年我写了一篇文章，其中谈到葡萄牙诗人佩索阿，其中有一个诗写的是小河和村庄的关系，点清了我心目中文字怎么和你生命世界在一起，它必须对你生命产生极强的冲击，这个书才值得读，或者你真正领悟这本书，所以他的诗也是我从英文翻译过来的，他说，塔古斯河美过我村庄的那条小河，但是塔古斯河又美不过流进我村庄的小河，因为塔古斯河不是流经我村庄的小河。太美了，为什么？文字如果不属于你的村庄，它不能流穿你的灵魂，这个书不值得一读，而真正传统的经典有穿透生命力的这种力量。</p>
<p>​    </p>
<p>我回到高中，我怎么认识到什么是一流的书呢？随便举个例子，我感谢文化大革命，把这些有文化的人推到内蒙古这个没文化的地方，教我古典文学的王传真老师，现在这些老师全都去世了，包括我大学的老师，大部分都已经不在了。但是这些高中老师教我古典文学的王传真老师，我第一次上他课的时候忽然发现什么叫大师，王老师告诉我们去新华书店买《古文观止》，中华书局第一版的。然后他说，你们要听懂我的课，这个假期必须做一件事，买来这个课本，他不讲，他拿出一套油印印出来的厚厚一叠古文，标点全部隐去了，他说你们这个假期玩完了以后，你就去读读我这个自己刻印出来的东西，然后按照你全部的理解，使出你全部的工具来给这些文章，按照你的理解给它们加以标点，我们在没有走进古文的世界，这个东西既刺激也似乎不可能，但是我为了下学期听懂王传真老师的课，我从我爸箱子里翻出他爸给他留下的当年最老版的辞海，我开始一个一个的，每天以十个字的速度往前运行，整整三个月我没干别的，因为越往前走越觉得这里深不可测，但是我的梦想是一定要听到王老师的讲解，因为这是他对我们唯一要求。结果就乱标点，但是我一天以十个字的功夫不断的往前进，最后50篇文章被我标点了。等到王老师到我面前给我面试的时候，他随便说了几句，我基本背出来之后，他说了两点，第一，你的标点全错了。第二，孺子可教，因为你全标了，就是你这个努力，我觉得可以。其实当老师，有的时候非常充满智慧，我们的胡校长胡适，胡适不判作文的，他没有时间，他有时间要搞新文化运动，作业算什么。但是据说，上作文的课每次都能给出学生成绩，后来据他的学生回忆，胡适判作业那是胡判，他今天晚上吃完饭，收了几十份作业，你写了文章，他开始把桌椅放在离靠门半米远的地方，泡一杯清茶，然后扔作业，哪个扔的最远最高分，为什么？写的多，不管你写的怎么样，你下了苦功。别人一扔不远，零分，写的不多。扔的远，够份量，一百分，胡判定就要开始出来。</p>
<p>​    </p>
<p>而且我当时，我怎么走到英文这个道路上，一流的书上来直接读《古文观止》就可以了，看似很艰难，但是读完全部启蒙的古文书，我再读人教的那些太简单了，因为你的制高点不一样，一流书、二流书、三流书区别在这。比如英文，老俞就没有遇到我这样的老师，今天还说着印度人非常理解的英语，但是到了美国就崩溃了，因为他是印度籍的移民。我这个英文老师学俄语，英文不太懂。但是这个老师一片真诚，他知道该给学生什么样重要的价值，怎么让英文走进你的生命。上了他第一堂课，他觉得我的两个眼睛不断的盯着他，两耳竖着，像狼犬一样，他说你真心想学英文吧？我说当然，上您的课厕所都忘了。他说王强你到我办公室。当天下午在他办公室他说了一句话，他说从此你要上我的课。我说老师我就想学英文。他说我教不了正经的英文，我的底子我自己知道，你要想学真正的英文，我给你想办法，你就不用上我的课。第二天下午4点，下了自习，他把我叫到他办公室，从黑皮兜里掏出旧报纸包的东西，把慢慢打开，一打开，我一看，是一个断了一角的黑色的绞盘，唱盘，叫LP，大唱盘，你们现在连CD都不用了，那个大唱盘这么大，他说王强你要跟这个学，这是什么呢？这是我从废品站几年前搜集到的东西，它是BBC英国广播公司出的一套经典英文教材，从明天起，每天下午四点你只要答应我一件事，不要回家，来跟我学。后来我就非常兴奋，第二天我拿到这个光盘以后就跟着他，他把我领到学校的广播间，那时候他把团旗往窗户上一盖，门外面挂着闲人莫进，正在录音。然后他用当年我们中学唯一的手摇唱机，跪在地上，他一边给我摇，一边让我赶快重复，而且说你这个课本永远在我手里，等到你全部的课本能够背答入流的时候，你就成就了。结果他做了一件事，每个礼拜都这样，最后倒背如流的时候，他把这页撕掉了，所以我这个课本越学越少，最后只剩下封底的时候，他说王强你可以毕业了。我忽然意识到，我离开了文字的课本，但这些东西全在我身上，所以等到我到北大，作为英语系的学生第一年入的时候，在我们班50个人中，只有我说的着流畅的英语。为什么？他们不知道来自一个内蒙古包头的，别说英语，汉语都不沾边际的，说蒙古话的人，能说如此好的英语。其实我没有学任何东西，就是破唱盘和破唱机，一摇、一摇，摇过了一两百页的篇幅，这些篇幅被老师扔进垃圾堆的时候，我发现他让一流的英文教材完全引入到我的灵魂中，我感谢他。</p>
<p>​    </p>
<p>教我历史的老师让我有了进北大的冲动，为什么？他是南京大学太平天国专业毕业的，学了五年，最后被打到包头，他讲历史，我听的如痴如醉。这个老师爱流鼻涕，历史长河，源源不断。而且这些老师，我不仅跟他们学读书，我从他们做人也学到了品性，就是一个字-真，最崇尚的就是真。这个老师非常有意思，他看我非常好学，他希望我每个礼拜三天到他家，那时候肉是供应的，那时候我已经是中学学生，老师为了让我安心在他家读历史著作，在他的引导下从《左传》开始，一篇一篇给我解释，每个月他家四个人，一人二两肉的份额，炒完以后只是我俩来分享，所以我非常歉疚。他说王强你要学好知识，肉体先要活着，他说我觉得你是可培养的，他展示了一流思想和一流文字真正的胶合。他上课非常有特点，从来不备课，这样一个顶级的老师，在我们学校从来没评过优秀老师，所以优秀是靠你真正生命才能支撑的。而且这个老师从来不服学校的规矩，从来不备课，他觉得跟其他老师没法备课。我记得每天早上九点都是历史课，大冬天穿着棉袄，历史书插在裤腰上，带着历史的温暖就进来了，而且第一个动作就是背向我们，掏历史，那是他的故事，他对知识如此娴熟，书没有打开一页，因为历史都在他的心里。而且他讲任何一个孤零零的事件都要放到更大的范围，讲完五四运动，他一定看看亚洲在干什么，欧洲在干什么，全世界在干什么，我们通过上中国史已经连通了世界，从此我才知道原来读懂中国史必须放在世界历史的框架中才可能。这样的老师简直让我叹为观止，就是他一句话让我升起了北大梦。他说我这个岁数这辈子实现一个梦想没戏了，什么梦想呢？他说我是学历史出身的，但是我对历史上的宏观描述，社会主义、共产主义的发展描述我有疑问，什么是社会主义，什么是共产主义呢？当时国内翻译说，社会主义是各尽所能，按劳分配的社会，这里各尽所能，但是按照你能够多做多得，能够给你分配你应该得的东西，这是社会主义分配原则。共产主义当时分析说，各尽所能，按需分配，他说同学们，作为我一个学历史的人，我的历史意识告诉我这个翻译不精准，如果共产主义和社会主义，一个按劳分配，一个按需分配，都存在”分配”的话，这两个社会没有区别，按照我的理解，那个时候人类精神极为发达，那个世界应该是各尽所能各取所需的时代，你自己决定你贡献什么，你拿回什么，这才是他向往的共产主义，和社会主义你需要我给你，不需要我不给你，这个没有什么本质区别他。他们说你们将来如果报答我作为你们的师恩，你们如果想学外语的话，读读马克思的原典，告诉我这个是不是对。八十年代的时候，所有发达国家，最后管理这个国家的都是学文的，学文的人可以看到全部，甚至看到没有存在的东西。所以你们学文的人应该比学理的更加聪明。后来我带着这个准备报考北大中文系，因为当时我的作文非常好，他说王强你千万别报北大中文系，你的中文已经完全达到了自学成才的程度，你将来要毙掉所有北大中文系的学生，你只需要一个东西，比他们多学一种语言，就这句话让我改了志愿，变成了英文系，因为老师告诉我，你看世界要多一种语言，你的世界就会宽广一下。</p>
<p>就是这样，我最后终于改换了志愿，到了北大英文系。我到校第一件事就是搞清楚，马克思论断是不是我的老师想像的，正好朱光潜先生翻完经济学手稿我一看与我老师的论断一字不差，社会主义分配原则是各尽所能按劳分配，共产主义一定会达到人类精神高度发达和自由，然后各尽所能，各取所需，我告诉我老师消息的时候，他说你真是我的学生。就是这样一个老师，他让我知道，历史你要读懂要站在什么高度。</p>
<p>​    </p>
<p>再讲一个例子，教数学的老师，南开大学数学系毕业，我当时非常讨厌数学，我喜欢文，我们班一大半学生学不懂数学，但是只有这个老师的课上没有人上厕所，为什么？他对数学知识的了如指掌，比如他讲几何，他只带三只粉笔，从来不带教具，他要画个圆，先点圆心，往后一站，再往上一扑，动作一点都不停，你下课以后发现这个圆在哪衔接的不知道。他说画40几度角，他画完以后，很多学生下来拿两角尺去量非常准。所以后来上他这个班的学生，连不喜欢数学都要盯着他，因为觉得这是艺术课，结果这个班最后90%多的人都进了理科大学。当时令我难忘的是，八十年代，那时候我记得是考大学前一年，出来一个陈景润，数学家，非常伟大，突然光明日报第一版发了《哥德巴赫猜想》，当天下午我平生第一次知道有讲座的形式，说让大家带着板凳到操场上听讲座，讲《哥德巴赫猜想》，前面部分讲什么是哥德巴赫猜想，第二部由讲汉语的老师讲这个报告文学为什么是优秀的报告文学。结果我们坐着小板凳，太阳底下，第一次听什么叫偶数等等，听完以后没听明白，但是觉得陈景润很伟大，后来我的数学尽管是考文科的，那年我还考了59分。我们那年，80年和你进清华是同样一个卷子，77分就可以被清华大学数学系录取，我们59分，我们这是参考分，但是俞敏洪参考分0分，太悲惨了，一点没参考价值。</p>
<p>​    </p>
<p>就是那个东西把我引到数论，所以在中学时我就读华罗庚、王袁的这些论著，懵懵懂懂，试图要读点爱因斯坦的著作，而且读了徐池报告文学我知道优秀报告文学是这样产生的，以后我也写了无数的小的报告文学，结果没有一处发表，所以到了北大之后我一直想写诗，我的诗集叫《野性的14行》，俞敏洪最后也写诗，他是北大最后一个没有自焚的未遂诗人。我们当年带着这个，知道了各个领域，要想走进这个领域，必须站在最高的地方，当时至少最优秀的地方我才能一览众山小。</p>
<p>​    </p>
<p>到了北大更不得了，因为我们见到的那些人，都是大家见不到的那些大师级的人物。比如我是英语系的，英语系所有泰斗都是直接教过我们的，像李副宁（音）先生，不论刮风下雨，李先生的裤脚总是捻上来，一尘不染，他总是提前五分钟走进教室，也是把新概念往上一放就侃侃而谈，上第一个星期我们忽然觉得，每次上完课李先生这四块黑板没有擦过一个字，但是他写满了，在往下一周忽然发现，每当李先生写到这的时候，我们能推算出什么时候下课铃响起来，这真是大师，所以我说我将来当老师一定要当李先生这样的老师，他是中国英语教学的泰斗，像当年朱光潜老师，操着一口安徽桐城话讲什么是美学，尽管我们听不懂，他的桐城话非常难懂，但是就是在这样的情况下，我们看着朱先生最后完成了他的一步一步伟大译作，在他生命走到90多岁的时候，还每天馋着拐棍颤颤巍巍的到北大图书馆完成他的最后一部译作《新科学》。</p>
<p>​    </p>
<p>这些老师给我们震撼如此之大，所以我们一下子扑到了北大的读书氛围中。他们给我们开了全部的书单，都是人类历史上经典的东西，因为他们说过，如果你没窥探过人类过去的最高的封边的时候，你就不知道你现在站到的地方究竟离海平面多高。所以当时所有教授都跟我们说，要读那些真正经过时间考验而不被淘汰的东西。所以在北大我的读书激情一下子被点燃起来，当然俞敏洪也被我的激情点燃起来了，但是俞敏洪呢，他当时基础稍微弱一点，有一次他得了肺结核，他住在西边享受那个传染病院，我去看他，他说王班长，我是他的班长，他是我帮助的同学，我们班四年始终保持倒数第一的同学，底子非常厚，这种人一站起来非常稳的，你想连续四年保持不变，倒数第一，太难。他说王班长，你从北大寄给一本莎士比亚的14行诗怎么样？我记得我回去以后给他写了长长的信，大概50多页，最后结论说，老俞读书要从基本功抓起，你一年以后我再替你借莎士比亚14行，至今老俞没读过14行，但是他用人生写出了15行。所以这就是当年我们在北大读书的氛围，就是读这些经典，人类熟悉的，甚至很多人追求时髦不屑一读的东西，对我们的生命，对我们的审美，对我们对真理的理解和渴望，对我们对语言和世界的关系，以及型塑生命的力量有了直接的感觉，就是这样一步一步推着我们走到今天。无论我在北大当年教书的时候，还是到了美国，还是从美国回来，我的读书的这个激情，选择所谓一流书的概念一直伴随着我，所以我认为我人生最大捷径就是花了时间非常痛苦啃了一流的书。举个例子，当年我到了美国，我改行，我不学英美文学，因为我发现到了美国来错地方，不能在美国生存，我学了十年的英文，在美国一点用没有，我不能教美国人英文来生存，那是李阳要做的事。我知道在美国生存要有一个技能，就改成计算机，但是学计算机谈何容易，计算机在八十年代是第一代计算机时代，主机，主机两个特点，体积庞大，造价昂贵，一台上百万，当时直属教育部重点院校才拨一台，安放在北大的南北阁。那个时候特别羡慕计算机系的，因为只有计算机系当年在北大四年，他们有一方面特权是任何系没法超过的，就是洗澡，到洗澡堂，计算机系人优惠洗澡，为什么？他们要消毒。为什么消毒？因为计算机如此昂贵，发展初期人们搞不清楚计算机病毒是怎么出来的。这个也应该拍成电影，北大当年就两个澡堂，一男一女，我们当时分的非常清楚。老头老太太管的非常严，比你们现在门卫森严多了，不仅要有洗澡票，还要有学生证，两证具全才能进去，而且还要看哪个系。你说哪系的？中文系的，明天再来，今天比较紧张。那个人回去了，一看哪个系的？计算机系的，赶快进去，今天你们是专场。另外一个，刚打了篮球，老师我必须洗，晚上要跟女朋友约会。老师说拿出学生证，考古系的，捣什么乱，明天也不要来，他们只有校庆的时候才能来，这才代表北大的历史。所以当时我觉得世界上两个东西我没见过，一个是上帝，一个是计算机，我到了美国学了计算机，我崩溃了，但是我想到老师教我的读书，为什么崩溃？因为到了纽约州立大学，录取我很容易，我记得第一堂课让我崩溃，第一堂课上微积分，十年我没摸过数学，上来我就危机了，就分裂了，而且讲课的是印度籍的老师，我想当时在北大练听力怎么没练过这个东西呢？所以同学们，学习不一定标准就是最实用的，我崩溃了。而且这个老师头上缠了发黑的白布，我听的越来越崩溃，我多少次想冲上去问他，你也是人，我也是人，咱们俩怎么这么难沟通。后来我想到，什么叫君子，该动手的时候不动手，该出手的时候不出手。</p>
<p>​    </p>
<p>我想，我作为北大六年老师，我也没白练啊，我赶快到书店拿下计算机两本一流的著作，学西语言，上面有几百种西语言，但是我找到薄薄的不到两百页的著作，我不断的在读，不断的读，又不像我北大读经典一样，这本书我最后读的基本上找不到页玛的时候，我忽然发现我对C语言找到奇特的理解，我知道它为什么诞生，它优越在哪，它比较其他的语言，比如纯粹的学术语言，比较机器的语言，它好在哪。后来我学C++语言的时候我又找到了发明C++语言写的东西，看似非常精简，因为在他来说都不是问题，仍然不到两百页的书，我苦读整整一年，最后忽然我对这之间的世界完全了如指掌，最后我是我们班被老师评价为优秀的学生，当你熟悉一种语言的思维方式的时候，你很难跳到其他世界，因为是完全不同的，他是解决C不能解决的问题，而我由于掌握全部一流的平台，我非常正确的走进了两条道路，而且走的非常正确，老师给我非常高的评价，这就导致了我后来在纽约州立大学，尽管第一学期几乎想要抹去自己，我常常说这哪能听懂，尤其是印度籍教授。我经常利用上厕所的时间跑到操场上想，上帝，你把我微积分了吧。但是这两本一流的著作，让我走进真正这两个语言思维的精髓，我后来一下在这两个中间，一旦跳跃，我就变成超越所有本科学生天天在市场上抓关于C++这个介绍、那个介绍，读十本书也没有摸到真正C++核心的东西，所以我的读书基因在美国又一次拯救了我，使我经过两年半的艰难困苦的努力获得了纽约州立大学数学系机系的科学硕士学位，是我们班第一个走进美国一家伟大的软件公司，叫做贝尔传讯公司，我完成了我的转折，后来才有了95年一天深夜，老俞一番鬼魅的电话打到了我家，我做了人生的选择，才有了三个合伙人的雏形。</p>
<p>​    </p>
<p>这就是我跟大家分享的，读书要读一流的书，做人要做一流的人。谢谢大家。</p>
<h2 id="提问"><a href="#提问" class="headerlink" title="提问"></a>提问</h2><p>​    主持人：感谢王强老师分享的读书经历，下面进入提问环节。</p>
<p>​    提问：王强老师刚才说读书要读一流的书，做人要做一流的人，在您看来什么样的人才是一流的人？</p>
<p>​    王强：第一，真诚。第二，有激情。第三，开放，对什么都容易吸收。第四，阳光，你如果自己自焚，你也让别人照亮。第五，要有梦想，而且为了梦想不断往前走。第六，在大是大非面前，一定要有原则，而原则高于一切，善的就是善的，恶的就是恶的，所以我们做新东方，我就是按照这样的东西走到今天，也面对老俞基本是这样，所以我在老俞面前随时就拍桌子，因为只要偏离任何原则的东西，所以新东方的人给我一个外号。</p>
<p>​    徐小平：说王强老师叫做脆弱如钢，俞敏洪老师叫坚强如芦苇，我叫芦苇钢。王老师说的第一词叫真诚，有这样一个细节，俞敏洪拿着书说，你有一天会让我嫉妒的。当时我在加拿大学完英文硕士，做一个私人老师，非常不成功，回到新东方的时候老俞说了一句话，老俞说小平，你很快就让我嫉妒的，他把对朋友的一种赞美、认同表达出来。我们三个人在一起的时候真的是坦诚相见的，虽然我们从来没有在一起洗过澡，大家心里有什么东西说出来，所以新东方历史上所谓的争吵，恰恰使新东方成为伟大企业的真髓所在，有什么说出来。所以在合伙人里面，俞敏洪说过一句话，他说我们来美国之前，我们不是真吵，我们是不同观点、不同角度的交锋，是思想的汇集，所以你们今后做人要学会这种东西，就是真诚、沟通、交流。</p>
<p>​    </p>
<p>​    提问：我今天注意到俞敏洪发了一篇博客，特别澄清电影和新东方之间的差别，一再想撇清这中间的关系，我想听听您怎么说，您在单口相声当中总是把他当成一个捧哏，不断的调侃。</p>
<p>​    王强：他现在也是这样，老俞看完这个电影说，这个主人公离我比较远吧，怎么没有雄起的时候，我说这个电影最大的意义就在这，连这样的人都能成功，别人更能成功。</p>
<p>​    徐小平：这个电影，第一他没有参与，事实上是这样的，2011连的3月份，韩三平找我，要拍摄一般部关于中国梦的电影，然后我找俞老师，我说我来写，我在新东方一直负责新东方的宣传公关、企业形象、品牌建设、营销，当时老俞说千万不要写，后来我告诉韩三平我们不写了，他说不行，你不写我们就找别人写，你不写我们就把新东方写的很坏。事实上后来我用两个礼拜拿出那个剧本，但是既然俞敏洪不想写，就写了海归回国创业的故事，海归回国和两个朋友创办了英语学校，是一个爱情故事，后来陈导说新东方会不会告我们，我说这个片子如果出来不符合我们之间的价值观、我们的友谊观，我根本不跟你合作，一部电影算什么。一直到了11年的年底，他来找我，我是3月份写出来的，剧本出来以后，我把我的剧本寄给王老师和俞老师，我提供了最初在新东方的素材，我的剧本给你们看，我要经得起友谊的审查，而陈导的剧本要经得起市场的审查。等到最后电影出来以后，俞老师看完以后觉得我这么伟大的人物怎么写的这么窝囊。这就是电影的目的，如果你这样窝囊的人都能够做到这么成功，对当代青年是有意义的嘛。所以俞老师也就一如既往忍气吞声的接受了这个片子。</p>
<p>​    提问：您刚才说一流的书，您给我们推荐一些一流的书。</p>
<p>​    王强：一流的书很多的，但是确实很难，因为我也特别怕推荐这个书，如果读完以后跟你生命确实没有交际的话，确实浪费时间。比如对于西方文明史的理解，至少有几部著作大家一定要读，从文艺复兴时代就是博格哈特的《意大利文艺复兴史文化史》，但是荷兰大史学家写的《中世纪的秋天》，读完这两部作品你对中世纪文艺复兴的本质有非常好的了解。到了《历史的研究》，汉语翻了一卷的结本，这个是作者花了三十多年的时间，用五千多页的篇幅研究各个存在的文明形态，研究他们怎么繁荣消亡的，最后得出两个东西，所有文明符合两个东西，如何面对挑战和回应，所以读完这几个东西，从中世纪到文艺复兴，再到二十世纪人的历史，有了非常宏观的东西，按照他们所指引的方向再往近读。</p>
<p>​    提问：我想问王强老师一个问题，我感觉王洋的角色是最温情的，最初他似乎是愤青，你在创业中是否也扮演这样的角色？</p>
<p>​    王强：我在三人创业中更接近邓超的角色，前一部分挺像我的，小平这个角色也是相反，在新东方我称之为小平是最有远见人，新东方所有历史大发展第一启动者就是小平同志。但是小平的性格，我过于钢，我是直接和老俞yes  or  no，小平有一点像王洋那样的，你这拍两下，那拍两下。</p>
<p>​    提问：在合伙创业过程中难免冲突的时候，每个人应该怎么做？</p>
<p>​    徐小平：制度，议事规则。</p>
<p>​    提问：是什么让你们最终要合伙的？是因为个人感情吗？</p>
<p>​    徐小平：有一个学生转了我们三个人的照片，说他们三个人搞鸡搞了三十年。我想简单说，创业一开始，合伙人往往是互补，互相需要。如果能坚持到最后靠的是什么呢？共同的价值观。什么是价值观？什么东西最重要，当两个东西摆在一起，什么最重要，比如你爱上一个人，你妈妈说他不行，我们不喜欢，你为此让你爸爸妈妈难受，还是你追求你的真爱，这就是价值观。比如说新东方的价值观是什么，就是新东方这个品牌，我们对同学的吸引力，包含我们对学生的承诺，我们相信这个东西有价值，比起我多一个点、少一个点，一个点新东方能值五千美元，但是我们共同的把这个品牌做好做大，你的东西才用不完。所以新东方有非常杰出的人，他不认同这个品牌，他就离开了。但是我跟王强、俞敏洪，我们在最痛苦的时候都知道这个品牌是我们共同的价值观，新东方要把中国最优秀的人才，让他们看到另外一个世界，最终能够把中国这个世界变得和最美好的世界一样美好，我们完成这个历史使命。</p>
<p>​    提问：我也是非常喜欢读书的，在看很多作品的时候本来就非常晦涩难懂，你刚才说你读很难懂的书的时候还反复读，我想问是什么样的心态让你读不懂还可以反复读。</p>
<p>​    王强：书写出来的文字两种，有力量和没有力量。书有两种，一类是硬性的书，一类是软性的书，黑格尔、康德、尼采、柏拉图这些都是硬书，硬书你要想从中获得养分，唯有一个捷径，就是不断的读，因为你不可能靠一遍，畅销书一遍不用读完你就理解了，这些畅销书和那些真正书籍的区别。所以当你一遍一遍进入的时候……</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;王强2012在北大的演讲——读书毁了我&quot;&gt;&lt;a href=&quot;#王强2012在北大的演讲——读书毁了我&quot; class=&quot;headerlink&quot; title=&quot;王强2012在北大的演讲——读书毁了我&quot;&gt;&lt;/a&gt;王强2012在北大的演讲——读书毁了我&lt;/h1&gt;&lt;p&gt;视频
    
    </summary>
    
      <category term="技巧" scheme="https://plantegg.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="知识积累" scheme="https://plantegg.github.io/tags/%E7%9F%A5%E8%AF%86%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="读经典书" scheme="https://plantegg.github.io/tags/%E8%AF%BB%E7%BB%8F%E5%85%B8%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>time_zone 是怎么打爆你的MySQL的</title>
    <link href="https://plantegg.github.io/2023/10/03/time_zone%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%93%E7%88%86%E4%BD%A0%E7%9A%84MySQL%E7%9A%84/"/>
    <id>https://plantegg.github.io/2023/10/03/time_zone是怎么打爆你的MySQL的/</id>
    <published>2023-10-03T09:30:03.000Z</published>
    <updated>2023-10-07T06:38:57.811Z</updated>
    
    <content type="html"><![CDATA[<h1 id="time-zone-是怎么打爆你的MySQL的"><a href="#time-zone-是怎么打爆你的MySQL的" class="headerlink" title="time_zone 是怎么打爆你的MySQL的"></a>time_zone 是怎么打爆你的MySQL的</h1><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p>这篇关于time_zone 的总结写得非常好<a href="https://opensource.actionsky.com/20211214-time_zone/" target="_blank" rel="external">Time_zone</a> ，建议先读完做个基础知识的打底</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>一般MySQL都会设置 time_zone 为 system，方便MySQL部署在不同的国家、时区也都能很好兼容，这是很符合逻辑的设置。</p>
<p>如果我们的查询中有一个列类型是 timestamp 的话，意味着：</p>
<blockquote>
<p>timestamp 数据类型会存储当时 session的时区信息，读取时会根据当前 session 的时区进行转换；而 datetime 数据类型插入的是什么值，再读取就是什么值，不受时区影响。也可以理解为已经存储的数据是不会变的，只是 timestamp 类型数据在读取时会根据时区转换</p>
</blockquote>
<p>如果MySQL 读取 timestamp 字段时，需要做时区转换，当 time_zone 设置为 system 时，意味着MySQL 要去follow OS系统时区，也就是把读到的timestamp 根据OS系统时区进行转换，这个转换调用OS 的glibc 的时区函数来获取 Linux OS 的时区，在这个函数中会加 mutex 锁，当并发高时，会出现 mutex 竞争激烈，每次只有一个线程获得锁，释放锁时会唤醒所有等锁线程，但最终只有一个能获取，于是一下子导致系统 sys飙高、上下文切换飙高。每读取一行带 timestamp 字段时，都会通过这个 glibc 的时区函数导致锁竞争特别激烈最终 QPS 拉胯厉害。</p>
<p>想一想，你一个SQL查1万行，10个并发这点流量其实一点都不过分，但是这里需要10*1万次转换，锁争抢就激烈了。</p>
<p>分析参考这个： <a href="https://opensource.actionsky.com/20191112-mysql/" target="_blank" rel="external">https://opensource.actionsky.com/20191112-mysql/</a></p>
<p>perf 以及火焰图如下：</p>
<p><img src="/images/951413iMgBlog/image-20230830101924021.png" alt="image-20230830101924021"></p>
<p><img src="/images/951413iMgBlog/1682500623154-5834bcae-4c74-4c72-bfec-f67717f71c91.png" alt="img"></p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>在中国可以将 time_zone=’+8:00’ 将 time_zone 固定死，不再需要follow OS 时区，所以也不需要调用glibc 获取系统时区，避免了前面所说的锁竞争</p>
<p>这个经验来自无数次线上故障复盘，因为 time_zone 设置为 system 是个默认行为，所以要全部改过来还真不容易，给了我们就业机会 :)</p>
<p>当然学习总是希望交叉起来，既有深度又有宽度你才能掌握更好，所以请趁热打铁：</p>
<h2 id="进一步学习"><a href="#进一步学习" class="headerlink" title="进一步学习"></a>进一步学习</h2><p><a href="https://juejin.cn/post/7029291622537887774" target="_blank" rel="external">东八区CST 被JDBC 驱动错误</a>识别成了美国的中央时间，<a href="https://dev.mysql.com/doc/relnotes/connector-j/8.0/en/news-8-0-23.html" target="_blank" rel="external">官方修复</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;time-zone-是怎么打爆你的MySQL的&quot;&gt;&lt;a href=&quot;#time-zone-是怎么打爆你的MySQL的&quot; class=&quot;headerlink&quot; title=&quot;time_zone 是怎么打爆你的MySQL的&quot;&gt;&lt;/a&gt;time_zone 是怎么打爆你的
    
    </summary>
    
      <category term="MySQL" scheme="https://plantegg.github.io/categories/MySQL/"/>
    
    
      <category term="CPU" scheme="https://plantegg.github.io/tags/CPU/"/>
    
      <category term="MySQL" scheme="https://plantegg.github.io/tags/MySQL/"/>
    
      <category term="time_zone" scheme="https://plantegg.github.io/tags/time-zone/"/>
    
  </entry>
  
  <entry>
    <title>localhost和127.0.0.1的区别</title>
    <link href="https://plantegg.github.io/2023/09/24/localhost%E5%92%8C127.0.0.1%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://plantegg.github.io/2023/09/24/localhost和127.0.0.1的区别/</id>
    <published>2023-09-24T09:30:03.000Z</published>
    <updated>2024-02-20T09:57:08.563Z</updated>
    
    <content type="html"><![CDATA[<h1 id="localhost和127-0-0-1的区别"><a href="#localhost和127-0-0-1的区别" class="headerlink" title="localhost和127.0.0.1的区别"></a>localhost和127.0.0.1的区别</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>有人告诉我localhost和127.0.0.1的区别是localhost 不经过网卡，把我惊到了，因为我还真不知道这个知识点，于是去特别去验证了一下，这是个错误的理解，localhost会解析成127.0.0.1 然后接下来的流程和127.0.0.1 一模一样</p>
<p>我用Google搜了下标题，果然得到如下图:</p>
<p><img src="/images/951413iMgBlog/image-20230910100147730.png" alt="image-20230910100147730"></p>
<p>红框里是排第一、第四的文章，都大言不惭地说localhost不经过网卡、不收防火墙网管限制等。</p>
<p>我也看了下第二、第三的文章，这两篇都是说在MySQL命令行中连 localhost 的时候，MySQL命令行会判断 localhost 这个字符串然后不走DNS 解析流程(走的话就肯定解析成了127.0.0.1)，因为是本地连接，可以绕过OS 的内核栈用MySQLD 启动的时候生成的 unix-socket 管道直接连上MySQLD，这样效率更高。</p>
<p>错误信息大概就是在MySQL这个特殊场景下演变而来的，<strong>英文搜索就没有这个错误污染信息</strong></p>
<p>但这不是我要说的重点，我想说的是自己动手去求证！这一直都是我们星球里强调的能力和目标，我把<a href="https://twitter.com/plantegg/status/1700011179324920117" target="_blank" rel="external">这条发到Twitter上后有无数的傻逼跑出来质疑或者一知半解不去验证就丢一个结论，这是我最痛恨的</a>。比如：</p>
<ul>
<li><p>Localhost 写死了在 /etc/hosts(那我就要问，你清空/etc/hosts localhost还能工作吗？)</p>
</li>
<li><p>Localhost 不走网卡（但凡抓个包就知道走了，我估计他们抓了，抓的是eth0. 这里有个小小的歧义 loopback 本地回环网卡算不算网卡）</p>
</li>
</ul>
<p>所以我特意再写篇文章再验证下各种质疑，并让大家看看是怎么验证的，我希望你们可以跟着验证一遍而不是只要知道个结论</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>Localhost 会按<a href="https://plantegg.github.io/2019/06/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">dns解析流程进行解析</a>，然后和127.0.0.1 一样。在特殊的程序中比如MySQL 命令行会对localhost提前做特别处理。</p>
<p>完整的区别见<a href="https://www.tutorialspoint.com/difference-between-localhost-and-127-0-0-1#:~:text=The%20most%20significant%20difference%20between,look%20up%20a%20table%20somewhere." target="_blank" rel="external">这篇英文</a>(Google 英文第一篇就是)总结：</p>
<p><img src="/images/951413iMgBlog/image-20230910101843256.png" alt="image-20230910101843256"></p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="问题1：经过网卡吗？"><a href="#问题1：经过网卡吗？" class="headerlink" title="问题1：经过网卡吗？"></a>问题1：经过网卡吗？</h3><p>Ping localhost，然后 tcpdump -i any（抓所有网卡）icmp (精确点只抓ping包)，可以明显抓到网络包，所以肯定经过网卡</p>
<h3 id="问题2：localhost和127-0-0-1-的关系"><a href="#问题2：localhost和127-0-0-1-的关系" class="headerlink" title="问题2：localhost和127.0.0.1 的关系"></a>问题2：localhost和127.0.0.1 的关系</h3><p>如图是我在centos、微软azure(应该是个ubuntu)、macos下做的测试：</p>
<p><img src="/images/951413iMgBlog/image-20230910103644707.png" alt="image-20230910103644707"></p>
<h3 id="问题3：如果-etc-hosts-中没有写死-localhost-127-0-0-1-会怎么样？"><a href="#问题3：如果-etc-hosts-中没有写死-localhost-127-0-0-1-会怎么样？" class="headerlink" title="问题3：如果/etc/hosts 中没有写死 localhost 127.0.0.1 会怎么样？"></a>问题3：如果/etc/hosts 中没有写死 localhost 127.0.0.1 会怎么样？</h3><p>如下图，ping的时候即使没有 /etc/hosts 也可以把localhost 解析成127.0.0.1，为什么呢？所以接着我就 nslookup 看一下是哪个 DNS server做的这事，最后我用114.114.114.114 这个公网的DNS 做了解析，就不认识localhost了，说明去掉 /etc/hosts 之后 会把localhost 发给dns server解析，标准的dns(比如114.114.114.114,8.8.8.8) 都不会返回127.0.0.1 ，但是有些特定实现的为了省事帮你解析到127.0.0.1了</p>
<p><img src="/images/951413iMgBlog/image-20230910104133832.png" alt="image-20230910104133832"></p>
<h3 id="问题4：127-0-0-1比localhost少了查-etc-hsots-到底快多少"><a href="#问题4：127-0-0-1比localhost少了查-etc-hsots-到底快多少" class="headerlink" title="问题4：127.0.0.1比localhost少了查/etc/hsots 到底快多少?"></a>问题4：127.0.0.1比localhost少了查/etc/hsots 到底快多少?</h3><p>这个问题来自这个评论：<a href="https://twitter.com/InnerHack/status/1700012845302436087" target="_blank" rel="external">https://twitter.com/InnerHack/status/1700012845302436087</a>  所以我去验证了一下，特别强调这个数据意义不大，但是你们可以学会用strace，命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">strace -tt ping -c 1 localhost</div></pre></td></tr></table></figure>
<p>然后你得到如下图，从strace时间戳你可以看到 localhost 解析成127.0.0.1 的过程，再后面就是ping 127.0.0.1(这里也说明了前面的结论，两者是一样的，就是多了域名解析)</p>
<p><img src="/images/951413iMgBlog/image-20230910104733229.png" alt="image-20230910104733229"></p>
<p>域名解析的时候，先去找/etc/hosts 没找到再去找 /etc/resolv.conf 拿dns server ip然后把localhost发给这个dns  server 解析，tcpdump抓包如下，红框是dns server返回的结果：</p>
<p><img src="/images/951413iMgBlog/image-20230910105107629.png" alt="image-20230910105107629"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>唯有动手能解释一切，不要空逼逼(不是说你们，是说Twitter上那帮人，我是被他们留言多了逼着写了这篇)</p>
<p>我是欢迎一切有理有据的质疑，事实文中很多信息来源于别人的质疑，然后我去验证</p>
<p>然后好多验证手段你们可以学学，比如nslookup/tcpdump/strace 等。</p>
<p>我给的文章链接也可以仔细读读，能学到很多东西，每一次进步都来自你深挖、展开能力。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;localhost和127-0-0-1的区别&quot;&gt;&lt;a href=&quot;#localhost和127-0-0-1的区别&quot; class=&quot;headerlink&quot; title=&quot;localhost和127.0.0.1的区别&quot;&gt;&lt;/a&gt;localhost和127.0.0.1的
    
    </summary>
    
      <category term="network" scheme="https://plantegg.github.io/categories/network/"/>
    
    
      <category term="Linux" scheme="https://plantegg.github.io/tags/Linux/"/>
    
      <category term="localhost" scheme="https://plantegg.github.io/tags/localhost/"/>
    
      <category term="dns" scheme="https://plantegg.github.io/tags/dns/"/>
    
  </entry>
  
  <entry>
    <title>解决Java/MySQL性能问题的思路</title>
    <link href="https://plantegg.github.io/2023/08/28/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E6%80%9D%E8%B7%AF/"/>
    <id>https://plantegg.github.io/2023/08/28/解决问题思路/</id>
    <published>2023-08-28T02:30:03.000Z</published>
    <updated>2024-02-20T09:57:13.333Z</updated>
    
    <content type="html"><![CDATA[<h1 id="解决-Java-MySQL-性能问题的思路"><a href="#解决-Java-MySQL-性能问题的思路" class="headerlink" title="解决 Java/MySQL 性能问题的思路"></a>解决 Java/MySQL 性能问题的思路</h1><p>10年前写的，重新发一下</p>
<h2 id="系统性能问题"><a href="#系统性能问题" class="headerlink" title="系统性能问题"></a>系统性能问题</h2><ul>
<li>CPU（基本上WEB服务器没有多少IO，主要是CPU有瓶颈）<ul>
<li>top/vmstat 观察CPU使用率，Load负载，r/b线程数量等；</li>
<li>IO（数据库大多数时候瓶颈是IO，主要是索引没建好；如果数据库CPU紧张的话，检查一下是不是order by/group by 等操作太多）</li>
<li>vmstat 观察IO/Util吞吐，磁盘最怕随机读写了（比如：索引命中后，需要离散地从磁盘读数据）</li>
<li>对于数据库来说最怕内存不够的时候使用Swap了，所以尽量增大分配给数据库的内存，一旦有Swap就要引起注意了</li>
</ul>
</li>
</ul>
<h2 id="Java程序问题（运行慢）"><a href="#Java程序问题（运行慢）" class="headerlink" title="Java程序问题（运行慢）"></a>Java程序问题（运行慢）</h2><p>​    先通过 top 查看整个CPU资源使用情况；<br>​    通过top -Hp pid查看java进程的每一个线程占用CPU的情况；<br>​        如果有一个线程占用CPU过高，有两种可能：<br>​            没有内存了，Java垃圾回收线程不停地运行尝试回收内存，但是每次无法收回，确认：<br>​                jstat -gcutil pid 1s   观察10多秒钟就能发现了，看是不是内存使用率接近100%了<br>​            类似于死循环（hash冲突攻击），就是一个线程一直占用一个核的所有CPU资源（其实一个线程总是占用一个核超过50%的资源都是不太正常的），解决：<br>​                用我的checkPerf脚本，定位这个线程具体执行的任务（能具体到某一行），对应看代码解决。            </p>
<pre><code>    如果有很多线程，每个线程占用的CPU都不多(基本都在10%以下)，那基本是正常的，只是程序并发确实很高。

如果死锁：
    jstack -l pid 多执行几次，统计一下stack中总是在等待哪些锁，可以对锁id进行排序统计（sort uniq grep）
上面列出来的都是明显的瓶颈，最可怕的是哪里都没有明显的瓶颈，哪里都要偷一点点CPU资源走，这是可以试试JProfiler这样更专业一点的工具，同时要配合自己对业务的了解来解决。

一旦触发频繁地抛出异常，CPU占用率会急剧地上升（抛异常比正常情况下会慢2个数量级）主要是由于：Throwable的构造函数中会调用native的fillInStackTrace()，这个方法就会构造整个异常栈了。
</code></pre><p>Java内存的问题，如果有内存泄露（就是执行完fgc/old gc后不能回收的内存不断地增加）：<br>    怎么确认没有内存了：<br>        jps -lmv pid 先确认你的参数，也就是你给JVM分配了多大的堆(-Xmx 比如1G); 然后jstat -gcutil pid 1s 看看GC运行情况，如果(O/E 两列基本接近100%的话就是内存不够了)<br>            内存不够分两种：一种是真的不够，就是你们的系统很庞大需要1G以上的内存，而你只分配了1G，这个没什么好说的，增大内存，物理内存不够就投钱买；<br>            第二一种是你们的代码写的烂，有内存泄露，这样的话分配多少内存都不够，得找出是否有内存泄露，看接下的解决方案        </p>
<pre><code>快速解决：jmap -histo:live pid  来统计所有对象的个数（String/char/Integer/HashEntry 这样的对象很多很正常，主要是盯着你们公司的包名下的那些对象）
每隔一分钟执行一次上面的命令，执行5次以上，看看你们公司报名下的对象数量哪个在一直增加，那基本上就是这个对象引起了泄露；
用课堂上的工具HouseMD(java -Xbootclasspath/a:/usr/java/jdk1.6.0_29/lib/tools.jar -jar housemd-assembly-0.2.2.jar pid)来动态监控创建这个对象的地方（一般来说很多时候创建了这些对象把他们丢到一个HashMap然后就不管了），分析一下有没有释放！
    &gt;trace -s -d ClassName

上面的方法实在没法定位就用: jmap -dump:live,format=b,file=heap.bin pid 导出整个内存（耗时间，需要很大的内存的机器才能对这个导出文件进行分析，会将JVM锁住一段时间）
    在Eclipse的插件EMA中打开这个文件（2G的物理文件需要4G以上的内存，5G以上的需要将近20G的内存来分析了）
    盯着你们公司报名的那些对象，看看引用关系，谁拿着这些对象没释放（是否是必要的），可以一直追查的RootReference
</code></pre><h2 id="MySQL-数据库的性能问题"><a href="#MySQL-数据库的性能问题" class="headerlink" title="MySQL 数据库的性能问题"></a>MySQL 数据库的性能问题</h2><p>大部分情况下是磁盘IO的问题（索引没建好、查询太复杂）；</p>
<ul>
<li><p>索引问题的话分析慢查询日志，explain 他们挨个解决。</p>
</li>
<li><p>偶尔也有数据库CPU不够的情况，如果并发高CPU不够很正常，如果并发不高，那很可能就是group by/order by/random之类的操作严重消耗了数据库的CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mysql -e &quot;show full processlist&quot; | grep -v Sleep | sort -rnk6 查看那些SQL语句执行的太长</div><div class="line">拿出这个SQL语句分析他们的执行计划: explain SQL 然后改进；</div><div class="line">分析慢查询日志，统计top10性能杀手的语句，挨个explain他们，然后改进（具体改进办法具体分析，这里只谈思路）</div></pre></td></tr></table></figure>
</li>
</ul>
<p>总结一下数据库问题就只有这三招：show full processlist/分析慢查询日志/explain（然后建好联合索引）</p>
<p>补充一个数据库连接数不够的问题，很多人碰到了，不知道怎么解决：</p>
<ul>
<li>在mysql 命令行里执行：show variables like ‘%max_connections%’;  看看你们的数据实际配置是多少（比如1000）</li>
<li>show full processlist 数一下多少行，一行代表一个连接，比如这里是1000行，那基本上就是连接数不够了，你要解决的为什么你的数据库需要这么多连接</li>
<li>接下来分析这些连接是从哪来的IP，然后问你自己：根据你们的服务类型的特点需要这么多连接吗？</li>
</ul>
<h3 id="数据库性能问题提问请给出："><a href="#数据库性能问题提问请给出：" class="headerlink" title="数据库性能问题提问请给出："></a>数据库性能问题提问请给出：</h3><ul>
<li>show full processlist;</li>
<li>查询语句;</li>
<li>表结构(包括索引结构);</li>
<li>数据库引擎类型;    </li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;解决-Java-MySQL-性能问题的思路&quot;&gt;&lt;a href=&quot;#解决-Java-MySQL-性能问题的思路&quot; class=&quot;headerlink&quot; title=&quot;解决 Java/MySQL 性能问题的思路&quot;&gt;&lt;/a&gt;解决 Java/MySQL 性能问题的思路&lt;/
    
    </summary>
    
      <category term="performance" scheme="https://plantegg.github.io/categories/performance/"/>
    
    
      <category term="performance" scheme="https://plantegg.github.io/tags/performance/"/>
    
      <category term="MySQL" scheme="https://plantegg.github.io/tags/MySQL/"/>
    
      <category term="Java" scheme="https://plantegg.github.io/tags/Java/"/>
    
      <category term="思路" scheme="https://plantegg.github.io/tags/%E6%80%9D%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>如何从几百万个抓包中找到一个异常的包</title>
    <link href="https://plantegg.github.io/2023/08/23/%E5%A6%82%E4%BD%95%E4%BB%8E%E5%87%A0%E7%99%BE%E4%B8%87%E4%B8%AA%E6%8A%93%E5%8C%85%E4%B8%AD%E6%89%BE%E5%88%B0%E4%B8%80%E4%B8%AA%E5%BC%82%E5%B8%B8%E7%9A%84%E5%8C%85/"/>
    <id>https://plantegg.github.io/2023/08/23/如何从几百万个抓包中找到一个异常的包/</id>
    <published>2023-08-23T04:30:03.000Z</published>
    <updated>2023-12-19T03:05:20.151Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何从几百万个抓包中找到一个异常的包"><a href="#如何从几百万个抓包中找到一个异常的包" class="headerlink" title="如何从几百万个抓包中找到一个异常的包"></a>如何从几百万个抓包中找到一个异常的包</h1><p>这篇算是对抓包定位原因在哪里的落地篇，没什么高深的技术，都是很low但是你一定可以照着操作的，算是星球内必须学会和带走的内容</p>
<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p><img src="/images/951413iMgBlog/image-20230620150119963.png" alt="image-20230620150119963"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>一次业务请求包含160个拖数据的SQL查询，通过160个连接，发给160个Database，但是过几分钟后总有报错。几分钟抓包文件10G左右，网络包几百万个，怎么找到报错的那个？</p>
<p>几个麻烦的地方</p>
<ul>
<li>虽然问题每次稳定重现，但是每次重现的Database不是固定的；</li>
<li>从开始拖到出现问题需要几分钟不等，抓包量巨大</li>
<li>有一个连接报错后剩下的其它连接也会断开</li>
<li>这么多端口怎么解析成MySQL协议，请看：<a href="https://t.zsxq.com/0f7nMlKax" target="_blank" rel="external">https://t.zsxq.com/0f7nMlKax</a></li>
</ul>
<h3 id="问题发生条件"><a href="#问题发生条件" class="headerlink" title="问题发生条件"></a>问题发生条件</h3><ul>
<li>一个Client同时开160条连接，发160个类似的SQL去160个MySQL Database上拖数据时必现</li>
<li>如果将拖数据的SQL拖取数量改小一点就不再出现——拖取少执行更快，没达到触发bug条件</li>
<li>网络传输得慢一点、JDBC streaming 模式下发生，比如streaming流模式拖数据是几MB每秒，去掉流模式拖数据是几十MB每秒且不报错。这里可以通过设置内核 tcp rmem/加大rtt延时来模拟重现——和我们的<a href="https://wx.zsxq.com/dweb2/index/topic_detail/181428425525182" target="_blank" rel="external">必做实验callback一下</a>，无时不刻不展示下我们必做实验的用途。</li>
</ul>
<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>分析技巧和步骤：</p>
<ol>
<li>抓包，从握手到报错断开全抓下来，时间跨度3分多钟，抓下来10个G左右，怎么分析？</li>
<li>editcap -c 200000 把抓包切小，每个文件20万个包，保证wireshark打开不太慢（editcap 是安装wireshark附带的小命令，附带的还有tshark、capinfos等）</li>
<li>wireshark打开切小后的最后一个文件，搜reset/fin 找到<strong>第一个</strong>断开的连接(如下图)，找到9913/42909这对连接端口</li>
<li>回到10个G的抓包中，用 tshark -r ./big.pcap -Y “tcp.port==42909”   -w 42909.pcap 把42909这条连接所有包过滤出来，-r 读，-w 写</li>
<li>wireshark 打开42909.pcap 傻子也能看到问题在哪里了</li>
</ol>
<p>切完后的包，切完后的文件会加时间戳，时间戳可以和报错时间对应：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">-rw-r--r--  1 root  root   329M Jun 16 17:46 big00_00000_20230616170456.pcap</div><div class="line">-rw-r--r--  1 root  root   1.1G Jun 16 17:46 big00_00001_20230616170524.pcap</div><div class="line">-rw-r--r--  1 root  root  1022M Jun 16 17:46 big00_00002_20230616170546.pcap</div><div class="line">-rw-r--r--  1 root  root   1.1G Jun 16 17:46 big00_00003_20230616170608.pcap</div><div class="line">-rw-r--r--  1 root  root  1012M Jun 16 17:46 big00_00004_20230616170630.pcap</div><div class="line">-rw-r--r--  1 root  root   982M Jun 16 17:46 big00_00005_20230616170652.pcap</div><div class="line">-rw-r--r--  1 root  root   938M Jun 16 17:46 big00_00006_20230616170714.pcap</div><div class="line">-rw-r--r--  1 root  root   1.1G Jun 16 17:46 big00_00007_20230616170735.pcap</div><div class="line">-rw-r--r--  1 root  root   661M Jun 16 17:46 big00_00008_20230616170759.pcap</div></pre></td></tr></table></figure>
<p>搜reset/fin 找到第一个断开的连接，第一个断开的连接才是罪魁祸首：</p>
<p><img src="/images/951413iMgBlog/image-20230620143248344.png" alt="image-20230620143248344"></p>
<h3 id="进一步分析发生问题的连接"><a href="#进一步分析发生问题的连接" class="headerlink" title="进一步分析发生问题的连接"></a>进一步分析发生问题的连接</h3><p>知识点：</p>
<blockquote>
<p>MySQL 协议是一来一回，也就是client发查询然后等查询结果全部返回，然后再发下一个</p>
<p>按协议在一个SQL查询的数据传输完毕前client不能再发任何请求，MySQL Server负责一直发送查询结果直到发送完毕。</p>
</blockquote>
<p>如下两个截图是从42909.pcap文件中过滤到的抓包从握手到断开的全过程，图1过滤条件：tcp.srcport eq 42909 and tcp.len&gt;0  (42909是客户端，9913是MySQL端口)，可以看到客户端 login（连数据库肯定得要user、password认证），然后是client查了MySQL的一堆服务端参数(下图第二行)，再然后是client设置了几个参数(set 那些)。关键的是倒数第二行client发了一个SQL给MySQL需要拉取大量数据(建立连接17.98秒的时候)，然后是数据传数据过程，第190秒的时候client发了 Quit断开连接</p>
<p><img src="/images/951413iMgBlog/image-20230620140921134.png" alt="image-20230620140921134"></p>
<p>上图因为加了过滤条件，只看client端并去掉ack后的所有包，没看到全貌，这个过程9913的MySQL 服务端又做了啥呢？因为太长前面漫长的传数据就不截图了，只看最后连接的断开。</p>
<p>但是下图红框所示的地方可以看到MySQL Server 传着传着居然带了个 fin 包在里面，表示MySQL Server要断开连接了，无奈Client只能也发送quit 断开连接。红框告诉我们一个无比有力的证据MySQL Server 在不应该断开的地方断开了连接，问题在 MySQL Server 端</p>
<p><img src="/images/951413iMgBlog/image-20230620141017987.png" alt="image-20230620141017987"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>就抓包结论来看是 MySQL 在不应该断开的时候发送了 fin 主动断开连接，可能是MySQL的bug</p>
<p>题外话，这个包证据抓了有一周了，但是MySQL研发同学始终绕来绕去(比如我的代码没记录下这个SQL就是没收到，我的代码没问题——熟悉的味道)跟我打了一周太极(异地)，我一查发现我和他老板认识且在一层楼，赶紧面对面找他老板讲清楚这个问题，且签字画押承认是MySQL的问题，然后继续推进排查，最终结果是为啥我跟你们一起期待吧，有了结果我再来update。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>找个MySQL，然后开始抓包，用mysql-client连一下MySQL Server随便发几个SQL，然后看看一来一回的响应</p>
<p>如果哪怕在星球一年你只要好好掌握这一篇用到的技能也能帮助你在日常工作中互相扯皮的时候快速给出精准定位和分析，值回星球票价，加油</p>
<p>比如这个案例我同时打开了5/6个wireshark分析不同的流、整体搜索等</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>这些技巧不只是用在MySQL 上，其它微服务、redis等涉及网络调用场景的扯皮的地方都可以用</p>
<p><a href="https://plantegg.github.io/2019/06/21/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E6%8A%93%E5%8C%85--WireShark%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%89%88tshark/">wireshark 附带的一些小工具</a></p>
<blockquote>
<p>capinfos rsb2.cap</p>
<p>tshark -q -n -r rsb2.cap  -z “conv,ip”   分析流量总况</p>
<p>tshark -q -n -r rsb2.cap  -z “conv,tcp”  分析每一个连接的流量、rtt、响应时间、丢包率、重传率等等</p>
<p>editcap -c 100000 ./rsb2.cap  rsb00.cap  //把大文件rsb2.cap按每个文件100000个package切成小文件</p>
</blockquote>
<p>存放在这里：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">/usr/sbin/capinfos</div><div class="line">/usr/sbin/dftest</div><div class="line">/usr/sbin/dumpcap</div><div class="line">/usr/sbin/editcap</div><div class="line">/usr/sbin/mergecap</div><div class="line">/usr/sbin/randpkt</div><div class="line">/usr/sbin/rawshark</div><div class="line">/usr/sbin/reordercap</div><div class="line">/usr/sbin/text2pcap</div><div class="line">/usr/sbin/tshark</div></pre></td></tr></table></figure>
<h2 id="net-write-timeout-报错"><a href="#net-write-timeout-报错" class="headerlink" title="net_write_timeout 报错"></a>net_write_timeout 报错</h2><p>最后回答一下<a href="https://t.zsxq.com/0ftY9WNVv" target="_blank" rel="external">上一篇</a>中提到的流模式下 net_write_timeout 报错</p>
<p>如下图，JDBC 在 streaming 模式下，不断读取下一行，如果这个过程只要报错抛出的异常就是 StreamingNotifiable 异常</p>
<p><img src="/images/951413iMgBlog/image-20230620173111706.png" alt="image-20230620173111706"></p>
<p>错误信息定义如下，这个报错误导太严重，从以上JDBC 代码可以看到只要读取下一行报错了就会报调大 net_write_timeout 错误，但是实际原因却是连接异常断开，和 timeout 没有一点关系，你看久经考验的 JDBC  代码也不是那么完善还得你会 Debug</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">CommunicationsException.ClientWasStreaming=Application was streaming results when the connection failed. Consider raising value of &apos;&apos;net_write_timeout&apos;&apos; on the server.</div></pre></td></tr></table></figure>
<p>这个报错误导了排查分析方向，不知道坑了多少人了！当然如果MySQL 因为net_write_timeout 超时断开连接当然应该报如上错误，但是 JDBC 搞不清楚MySQL 为啥断开，就瞎猜是 timeout 了，然后只要是连接异常读数据错误(包含断开)就报这个错误。希望你们不要被坑</p>
<p>记住这个坑人的报错堆栈：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Application was streaming results when the connection failed. Consider raising value of &apos;net_write_timeout&apos; on the server.</div><div class="line">    at sun.reflect.GeneratedConstructorAccessor150.newInstance(Unknown Source)</div><div class="line">    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</div><div class="line">    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</div><div class="line">    at com.mysql.jdbc.Util.handleNewInstance(Util.java:425)</div><div class="line">    at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989)</div><div class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3749)</div><div class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3649)</div><div class="line">    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4090)</div><div class="line">    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:972)</div><div class="line">    at com.mysql.jdbc.MysqlIO.nextRow(MysqlIO.java:2123)</div><div class="line">    at com.mysql.jdbc.RowDataDynamic.nextRecord(RowDataDynamic.java:374)</div><div class="line">    at com.mysql.jdbc.RowDataDynamic.next(RowDataDynamic.java:354)</div><div class="line">    at com.mysql.jdbc.RowDataDynamic.close(RowDataDynamic.java:155)</div><div class="line">    at com.mysql.jdbc.ResultSetImpl.realClose(ResultSetImpl.java:6726)</div><div class="line">    at com.mysql.jdbc.ResultSetImpl.close(ResultSetImpl.java:865)</div><div class="line">    at com.alibaba.druid.pool.DruidPooledResultSet.close(DruidPooledResultSet.java:86)</div></pre></td></tr></table></figure>
<p>不过你要仔细看的话，它还是有caused by，如下，但是绝大部分工程师看到这个堆栈会忽视，上面都有 net_write_timeout 我还管个屁 Can not read response from server, 不过要是结合抓包的话就能理解：at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3186) 这个根本的原因是 JDBC 从服务端读取数据的时候报错了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Caused by: java.io.EOFException: Can not read response from server. Expected to read 405 bytes, read 272 bytes before connection was unexpectedly lost.</div><div class="line">    at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3186)</div><div class="line">    at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3709)</div><div class="line">    ... 40 common frames omitted</div></pre></td></tr></table></figure>
<p>最后希望你没被绕晕，再去看看<a href="https://t.zsxq.com/0ftY9WNVv" target="_blank" rel="external">上一篇</a>中推荐的流模式原理，把代码和网络应用层完美地结合起来</p>
<p>完整堆栈也可以参考网络上别人碰到的：<a href="https://github.com/brettwooldridge/HikariCP/issues/1771" target="_blank" rel="external">https://github.com/brettwooldridge/HikariCP/issues/1771</a> </p>
<p>看 Google 里面对这个问题的分析基本都没入门：<a href="https://www.google.com/search?q=Caused+by%3A+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException%3A+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&amp;hl=en&amp;sxsrf=APwXEddTwJGjFpkKuWHyXjlTvwTo2OUMhA%3A1687226872136&amp;ei=-AmRZI7gB6-C0PEPmOGbwAE&amp;ved=0ahUKEwiOvPny4dD_AhUvATQIHZjwBhgQ4dUDCBE&amp;uact=5&amp;oq=Caused+by%3A+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException%3A+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&amp;gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABgAGgAcAF4AIABAIgBAJIBAJgBAKABAqABAQ&amp;sclient=gws-wiz-serp" target="_blank" rel="external">https://www.google.com/search?q=Caused+by%3A+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException%3A+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&amp;hl=en&amp;sxsrf=APwXEddTwJGjFpkKuWHyXjlTvwTo2OUMhA%3A1687226872136&amp;ei=-AmRZI7gB6-C0PEPmOGbwAE&amp;ved=0ahUKEwiOvPny4dD_AhUvATQIHZjwBhgQ4dUDCBE&amp;uact=5&amp;oq=Caused+by%3A+com.mysql.jdbc.exceptions.jdbc4.CommunicationsException%3A+Application+was+streaming+results+when+the+connection+failed.+Consider+raising+value+of+%27net_write_timeout%27+on+the+server.&amp;gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABgAGgAcAF4AIABAIgBAJIBAJgBAKABAqABAQ&amp;sclient=gws-wiz-serp</a></p>
<p>下次在你们的业务代码里如果出现查询结果太大导致JVM OOM的话你可以站出来说把拉取数据改成 流 模式会有奇效 :) , 当然随之而来的是会有 net_write_timeout 报错，嗯，你的机会来了，业务技术上按照你的指引发展，出了问题你能顶得上</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;如何从几百万个抓包中找到一个异常的包&quot;&gt;&lt;a href=&quot;#如何从几百万个抓包中找到一个异常的包&quot; class=&quot;headerlink&quot; title=&quot;如何从几百万个抓包中找到一个异常的包&quot;&gt;&lt;/a&gt;如何从几百万个抓包中找到一个异常的包&lt;/h1&gt;&lt;p&gt;这篇算是对抓
    
    </summary>
    
      <category term="tcpdump" scheme="https://plantegg.github.io/categories/tcpdump/"/>
    
    
      <category term="tcpdump" scheme="https://plantegg.github.io/tags/tcpdump/"/>
    
      <category term="RT" scheme="https://plantegg.github.io/tags/RT/"/>
    
      <category term="Wireshark" scheme="https://plantegg.github.io/tags/Wireshark/"/>
    
      <category term="capinfos" scheme="https://plantegg.github.io/tags/capinfos/"/>
    
  </entry>
  
  <entry>
    <title>扑朔迷离的根因分析</title>
    <link href="https://plantegg.github.io/2023/07/23/%E6%89%91%E6%9C%94%E8%BF%B7%E7%A6%BB%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    <id>https://plantegg.github.io/2023/07/23/扑朔迷离根因分析/</id>
    <published>2023-07-23T04:30:03.000Z</published>
    <updated>2023-07-24T11:28:19.586Z</updated>
    
    <content type="html"><![CDATA[<h1 id="扑朔迷离的根因分析"><a href="#扑朔迷离的根因分析" class="headerlink" title="扑朔迷离的根因分析"></a>扑朔迷离的根因分析</h1><h2 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h2><p>追着RT 跑，不断加压力，到瓶颈前随着并发的增加RT很稳定。</p>
<p>但是你要对你的RT怎么来的，包含哪些环节的消耗，这样才不会出错。</p>
<p>如下图左边是QPS不停地增加，每一次台阶(增加20%流量)都是一次加压过程，右边是对应的 RT，可以看到在绿线阶段几乎是平稳的，直到最后的红色箭头 RT略微有一点点提升，但是整体也还好，说明基本没到瓶颈</p>
<p><img src="/images/951413iMgBlog/image-20230520101758175.png" alt="image-20230520101758175"></p>
<p>当然这个图是经过长时间调优的结果，来之不易，是理想的期望系统状态，但在这之前是长时间的痛苦分析和瓶颈在哪里的定位过程。</p>
<p>凡是复杂的实际业务总是有很多干扰项出现在你的理论图上，你得很好地识别他们</p>
<h2 id="业务结构"><a href="#业务结构" class="headerlink" title="业务结构"></a>业务结构</h2><p><img src="/images/951413iMgBlog/image-20230517113148916.png" alt="image-20230517113148916"></p>
<p>概念说明：</p>
<p>黑色=Database=被依赖业务=物理</p>
<p>蓝色=Tomcat=上游业务=逻辑</p>
<p>上游响应时间=下游业务响应时间+网络时间+上游自身处理耗时</p>
<p>响应时间=RT=耗时监控</p>
<p>tcprt：从内核网络取Database的响应时间</p>
<p>实际很魔幻的是同样流量有时候压测很稳定，有时候又不稳定，性能上不去(稳定时可能是压测数据、没有触发Database雪崩之类的问题)，所以导致问题</p>
<p><strong>所有压测过程中肯定是没有任何资源上的瓶颈(CPU、内存、网络带宽、磁盘等等)</strong></p>
<h2 id="监控数据"><a href="#监控数据" class="headerlink" title="监控数据"></a>监控数据</h2><p>如图，蓝线表示Tomcat，黑线表示Database被调用方，可以看到每次黑色 RT上升QPS下跌很猛(符合预期)，奇怪的是黑色RT很快降下来后蓝色RT还会维持较高一段时间，监控频率每5秒采集一次，以下所有监控图时间范围是一样的，但采集频率不一样</p>
<p><img src="/images/951413iMgBlog/image-20230516150350614.png" alt="image-20230516150350614"></p>
<p>(图1)</p>
<p>上图的两个 RT 监控数据都是Tomcat的业务代码记录下来的，比如Database的响应时间就包含网络+Database的处理时间</p>
<p>如下图通过网络监控看响应时间(tcprt <a href="https://help.aliyun.com/document_detail/181331.html" target="_blank" rel="external">阿里云文档</a>，从OS 内核中取到网络包的响应时间)，蓝线表示Tomcat，紫线表示Database，监控力度每1分钟采集一次，有被平均</p>
<p><img src="/images/951413iMgBlog/image-20230516150812485.png" alt="image-20230516150812485"></p>
<p>以上两个监控图的矛盾点：如果从网络层面记录的Database RT 可以看到上升幅度不明显，但是Tomcat 的RT上升很明显，但是Tomcat记录的RT则又是Database 上升明显。</p>
<h4 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a><a href="https://help.aliyun.com/document_detail/181331.html" target="_blank" rel="external">补充知识</a></h4><p>tcprt和tomcat业务进程记录的 Database rt差异，tcprt记录到的是RDS/Database的响应时间+网络时间，tomcat在这个基础上还要加入自己进程调出处理时间，比如tomcat进程取到数据库连接的时候连接需要排队等待1秒钟(后面有分析)，那么这个一秒钟对tcprt来说是不会记录进去的，但是客户端感知到的这次调用是1秒以上。当然业务记录的Database 还可以更精准，比如在连接池Druid(或者其它连接池的实现)内取记录，但是无论如何从业务进程到OS内核这里的差距总是存在的。</p>
<p><img src="/images/951413iMgBlog/6f6862dec810933f34b7793018cfb0da.png" alt="image.png"></p>
<h3 id="Tomcat-CPU-监控"><a href="#Tomcat-CPU-监控" class="headerlink" title="Tomcat CPU 监控"></a>Tomcat CPU 监控</h3><p><img src="/images/951413iMgBlog/image-20230516150950383.png" alt="image-20230516150950383"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>可以很清楚看到 QPS 下降是因为 RT上升，那么究竟是Database的RT上升导致的还是Tomcat的RT上升导致的。</p>
<p>但是我们从监控图也能看到Database RT降下来后Tomcat RT还维持高水位，所以有点迷惑了。</p>
<p>继续看另外案例</p>
<h2 id="案例2-yy"><a href="#案例2-yy" class="headerlink" title="案例2 yy"></a>案例2 yy</h2><p>两次压测监控数据，左右两个图标是同一时间的QPS和RT，蓝线表示Tomcat，黑线表示Database被调用方</p>
<p><img src="/images/951413iMgBlog/image-20230519170255718.png" alt="image-20230519170255718"></p>
<p><img src="/images/951413iMgBlog/image-20230519172225890.png" alt="image-20230519172225890"></p>
<p>从两个图来看，随着并发加高(QPS加高) 黑色RT增加明显，但是跑着跑着降下去了，可以理解成突发流量导致黑色RT增加，但是很快黑色RT稳住了阵脚，降回去了，但是蓝色 RT没降，所以表面看起来是蓝色(Tomcat)处理能力到了瓶颈</p>
<p>上图时间点内核监控的tcprt，可以看到还是Database 处理耗时增加，和上图的黑色RT下降根本不匹配，上图黑色RT最后在2.96ms，下图内核监控到的Database的tcprt在8.49，差异矛盾点</p>
<p><img src="/images/951413iMgBlog/image-20230519172519802.png" alt="image-20230519172519802"></p>
<p>第三次压测图</p>
<p><img src="/images/951413iMgBlog/image-20230519165825977.png" alt="image-20230519165825977"></p>
<p>从第一个图来看，随着并发加高(QPS加高) 黑色RT增加明显，蓝色 RT去掉黑色部分也有增加，并且黑色、蓝色都没降回去，看起来主要是黑色(Database)处理能力到了瓶颈</p>
<p>纠结的时候就在Tomcat上抓包确认一下，如下图黑色 Database服务端口是5493，可以看到Tomcat 发request总是很快，但是Database 响应都是几十毫秒(下图红色框)，和监控一致。其实监控可以说明问题，但是我担心业务记录时间不准，以及建连接时间都考虑在内，所以想抓包微观上印证一下，这种项目牵扯到很多人你搞错了方向丢人不说，大家合作联调浪费很大，所以必须稳！</p>
<p><img src="/images/951413iMgBlog/image-20230519203620163.png" alt="image-20230519203620163"></p>
<p>如果说问题在Database上，那为什么会有Database RT忽上忽下，Database RT降下去了Tomcat RT不降？我们要继续分析一下 Tomcat RT以及Database RT是怎么记录和实现的</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>问题解决后的原因分析以及数据整理</p>
<p>这个时候我们再把Tomcat部分的业务调用和RT记录再细化一下，如下图：</p>
<p><img src="/images/951413iMgBlog/image-20230520111102697.png" alt="image-20230520111102697"></p>
<h3 id="Druid分析"><a href="#Druid分析" class="headerlink" title="Druid分析"></a><a href="https://github.com/alibaba/druid" target="_blank" rel="external">Druid分析</a></h3><p>作为Tomcat和Database的连接点、枢纽点搞清楚Druid的逻辑对理解Tomcat和Database之间的问题的理解很关键。</p>
<p>比如以下要说的三个Druid 错误状态如果你不放到一起比较，看到这个错误你最多反应就是连接池不够了，什么原因不知道。但是如果放到一次比较一次后你以后对详细错误提示会积极敏感，进而发现第四、第五种错误提示</p>
<p>这就是综合比较、总结的好处。</p>
<p>Druid 最核心的类是 DruidDataSource，连接的构建，入池，获取，收缩，销毁，以及核心监控数据都在这个类维护</p>
<p><img src="/images/951413iMgBlog/image-20230721170334688.png" alt="image-20230721170334688"></p>
<p>连接池初始化流程：初始化驱动实例 -&gt; 加锁 -&gt; 初始化属性 -&gt; 初始化过滤器 -&gt; 校验参数 -&gt; <strong>创建初始化连接并校验后加入池中</strong> -&gt; 创建logStatsThread、createConnectionThread和destroyConnectionThread -&gt; 注册MBean，用于支持JMX -&gt; 如果设置了keepAlive，通知createConnectionThread创建连接对象 -&gt; 解锁</p>
<h4 id="Druid报错1"><a href="#Druid报错1" class="headerlink" title="Druid报错1"></a>Druid报错1</h4><p>获取连接排队是基本不消耗CPU，下图右上角是获取失败的日志打堆栈消耗，可以看到异常非常多。</p>
<p><img src="/images/951413iMgBlog/image-20230519174633172.png" alt="image-20230519174633172"></p>
<p><img src="/images/951413iMgBlog/image-20230519175029396.png" alt="image-20230519175029396"></p>
<p>Druid最大连接数默认是30，多次调大，30-&gt;60-&gt;120-&gt;160，一直调下去对调大能解决问题都没有信心了，总是报错</p>
<blockquote>
<p>maxWaitThreadCount 30, current wait Thread count 0 </p>
</blockquote>
<p>调大到160后的报错堆栈，<a href="https://sourcegraph.com/github.com/alibaba/druid/-/blob/core/src/main/java/com/alibaba/druid/pool/DruidDataSource.java?L1733:92" target="_blank" rel="external">对应源码 </a> 这个报错说明报错时已经有160个线程在等连接了，别等了，先快速报错返回吧</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">Caused by: java.sql.SQLException: maxWaitThreadCount 160, current wait Thread count 0</div><div class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnectionInternal(DruidDataSource.java:1620)</div><div class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnectionDirect(DruidDataSource.java:1404)</div><div class="line">        at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:5059)</div><div class="line">        at com.alibaba.druid.filter.FilterAdapter.dataSource_getConnection(FilterAdapter.java:2756)</div><div class="line">        at com.alibaba.druid.filter.FilterChainImpl.dataSource_connect(FilterChainImpl.java:5055)</div><div class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1382)</div><div class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:1374)</div><div class="line">        at com.alibaba.druid.pool.DruidDataSource.getConnection(DruidDataSource.java:98)</div><div class="line"></div><div class="line">对应代码：</div><div class="line">                   final Lock lock = this.lock;</div><div class="line">                    lock.lock();</div><div class="line">                    try &#123;</div><div class="line">                        if (activeCount &lt; maxActive) &#123;</div><div class="line">                            activeCount++;</div><div class="line">                            holder.active = true;</div><div class="line">                            if (activeCount &gt; activePeak) &#123;</div><div class="line">                                activePeak = activeCount;</div><div class="line">                                activePeakTime = System.currentTimeMillis();</div><div class="line">                            &#125;</div><div class="line">                            break;</div><div class="line">                        &#125; else &#123;</div><div class="line">                            discard = true;</div><div class="line">                        &#125;</div><div class="line">                    &#125; finally &#123;</div><div class="line">                        lock.unlock();</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    if (discard) &#123;</div><div class="line">                        JdbcUtils.close(pyConnInfo.getPhysicalConnection());</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            final ReentrantLock lock = this.lock;</div><div class="line">            try &#123;</div><div class="line">                lock.lockInterruptibly();</div><div class="line">            &#125; catch (InterruptedException e) &#123;</div><div class="line">                connectErrorCountUpdater.incrementAndGet(this);</div><div class="line">                throw new SQLException(&quot;interrupt&quot;, e);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            try &#123;</div><div class="line">                if (maxWaitThreadCount &gt; 0</div><div class="line">                        &amp;&amp; notEmptyWaitThreadCount &gt;= maxWaitThreadCount) &#123;</div><div class="line">                    connectErrorCountUpdater.incrementAndGet(this);</div><div class="line">                    throw new SQLException(&quot;maxWaitThreadCount &quot; + maxWaitThreadCount + &quot;, current wait Thread count &quot;</div><div class="line">                            + lock.getQueueLength());//bug? lock.getQueueLength()永远为0，应该改成：lock.getWaitQueueLength(notEmpty)</div><div class="line">                &#125;</div></pre></td></tr></table></figure>
<p>以下两个Druid 报错这次压测没有出现但是可以放一起比较一下，其它项目场景经常出现</p>
<h4 id="Druid报错2"><a href="#Druid报错2" class="headerlink" title="Druid报错2"></a>Druid报错2</h4><p>Druid类似报错，明显是等了5秒最大等待时间还没有获取到连接：<img src="/images/951413iMgBlog/image-20230519191317489.png" alt="image-20230519191317489"></p>
<p>红色错误信息表示等了5006毫秒（设置的5000毫秒超时）还没有取到连接，所以超时了，然后抛出错误堆栈。</p>
<p>红色信息还提示我们当前连接池最大10，目前 active 0, 说明不是连接池满了取不到，而是连接池里一直是空的。</p>
<p>看到这个错误不能说明数据库、访问数据库有啥问题，只能说明Druid 连接池取不到连接，要继续分析Druid创建连接的线程栈。或者比如Druid 参数设置不合理，可以把min、init、max 连接数设置为相同的值，避免压力高峰期再去创建连接。</p>
<p>Druid通过另外一个task（thread）异步给连接池补充连接，也就是这里可能是Druid创建连接失败，比如密码错误、比如连不上数据库，比如创建的thread卡死了、报其他异常了</p>
<p><strong>Druid创建 连接 和业务取连接是两个线程，所以业务取连接报错是看不到创建连接报错的堆栈和原因的</strong></p>
<h4 id="Druid-报错3"><a href="#Druid-报错3" class="headerlink" title="Druid 报错3"></a>Druid 报错3</h4><p><img src="/images/951413iMgBlog/image-20230520092224080.png" alt="image-20230520092224080"></p>
<p>借出连接为0(active 0)，creating也是0，没有新连接正在创建。</p>
<p>分析方法：</p>
<ol>
<li>dump Java应用内存，用MAT内存分析工具打开dump文件</li>
<li>使用OQL，select * from com.alibaba.druid.pool.DruidDataSource where createTaskCount=3</li>
<li>选出来的DruidDataSource即为有问题的datasource</li>
</ol>
<p>原因</p>
<p>Druid中有个计数器createTaskCount，用来记录每个连接池当前正在创建连接的任务数，默认不能超过3。Druid中，在keepAlive=true的情况下，这个计数器有bug，存在加了但没减的情况，导致这个值涨到3之后没有减回去，从而无法提交新的创建连接任务。</p>
<p> 注意，进入这个状态后的连接池，是无法自动恢复的。Druid升级到1.1.24可以修复这个问题。</p>
<h3 id="分片逻辑"><a href="#分片逻辑" class="headerlink" title="分片逻辑"></a>分片逻辑</h3><p>因为数据量太大，一台Database存放不下，自然会分片，或者说单表几千万之后也是建议分片。</p>
<p>分片逻辑是取业务id最后两位的字符去取string hashcode，再对16个Database分片</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">如果对id后两位字符(从00-99供100个数字，因为不排除id里面有字符，但实际主要是0-9的数字)的ascii码取hash然后按16取模的结果：</div><div class="line">0</div><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9  --开始不正常，10-14号分片没有直接跳到15号分片</div><div class="line">15</div><div class="line">0</div><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">14</div><div class="line">15</div><div class="line">……</div><div class="line"></div><div class="line">//分片求模代码</div><div class="line">for(int i=0;i&lt;10;++i) //0的ascii码是48，依此类推</div><div class="line">	for(int j=0;j&lt;10;++j)</div><div class="line">		 int value=((48+i)*31+j) mod 16;</div></pre></td></tr></table></figure>
<p>补充个小八卦</p>
<blockquote>
<p>为什么取某几位尾数来求模？比如很多业务按user_id拆分片，然后希望这个用户的所有订单拆分也落在一个分片内。于是他们想到的办法是在订单id最后几位上追加进去下单人的user_id后几位，对订单拆分会取订单id后几位hash，这样同一个用户肯定到同一个分片</p>
<p>这样查询某个用户的所有订单时(高频需求)就只需要查一个分片，否则就要扫描所有分片。</p>
<p>掏出你的某宝、某东看看你的订单后几位</p>
</blockquote>
<p>分片后的数据，明显两头的多中间的少，这必然导致后面的 Database 负载不均衡：</p>
<p><img src="/images/951413iMgBlog/image-20230519181628114.png" alt="image-20230519181628114"></p>
<p>Java源码：</p>
<p><img src="/images/951413iMgBlog/image-20230519181451384.png" alt="image-20230519181451384"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>问题的根本原因？</p>
<p>多个Database中的某几个瓶颈，为什么会这样见数据分布部分的分析</p>
<p>为什么Database RT监控能降下来？</p>
<p>业务Tomcat 帮Database拦截了流量，一旦Database响应慢 Druid 连接就会不够，请求都堵在Tomcat中，导致Tomcat RT升高(包含等待连接时间)——替人堵了枪眼，很好，Tomcat crash总比 Database crash要好，但是业务要清楚这是替人挨枪子，该往哪里去查瓶颈。</p>
<p>比如加流量20%，开始Database RT升高，很快连接不可用，可能有接近20%的流量被Tomcat拦截，这个时候Database RT能稳定，也有可能拦截的不够多，这个时候Database RT还是很高，但Tomcat RT更高，进入一种平衡状态</p>
<p>为什么有时候压测能过？</p>
<p>应该是数据分布比较巧，刚好压测流里面的数据分布没那么不均衡，没触发数据库雪崩</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;扑朔迷离的根因分析&quot;&gt;&lt;a href=&quot;#扑朔迷离的根因分析&quot; class=&quot;headerlink&quot; title=&quot;扑朔迷离的根因分析&quot;&gt;&lt;/a&gt;扑朔迷离的根因分析&lt;/h1&gt;&lt;h2 id=&quot;原则&quot;&gt;&lt;a href=&quot;#原则&quot; class=&quot;headerlink&quot; 
    
    </summary>
    
      <category term="performance" scheme="https://plantegg.github.io/categories/performance/"/>
    
    
      <category term="performance" scheme="https://plantegg.github.io/tags/performance/"/>
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="druid" scheme="https://plantegg.github.io/tags/druid/"/>
    
      <category term="RT" scheme="https://plantegg.github.io/tags/RT/"/>
    
  </entry>
  
  <entry>
    <title>扑朔迷离的根因分析--抖动和并发</title>
    <link href="https://plantegg.github.io/2023/07/23/%E6%89%91%E6%9C%94%E8%BF%B7%E7%A6%BB%E7%9A%84%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90--%E6%8A%96%E5%8A%A8%E5%92%8C%E5%B9%B6%E5%8F%91/"/>
    <id>https://plantegg.github.io/2023/07/23/扑朔迷离的根因分析--抖动和并发/</id>
    <published>2023-07-23T04:30:03.000Z</published>
    <updated>2023-08-28T06:04:41.249Z</updated>
    
    <content type="html"><![CDATA[<h1 id="扑朔迷离的根因分析–抖动和并发"><a href="#扑朔迷离的根因分析–抖动和并发" class="headerlink" title="扑朔迷离的根因分析–抖动和并发"></a>扑朔迷离的根因分析–抖动和并发</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们之前说过根因分析第一就是要追着 RT跑，随着并发的增加哪里RT增加快哪里就是瓶颈，这是我们的基本原则，但总有一些例外，我们今天想说说例外</p>
<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>如下图，应用是多个Tomcat集群，Tomcat节点可以随意增加，后端是一组DB集群，有几百个Database实例，每一次业务请求都会对应多个Database查询</p>
<p><img src="/images/951413iMgBlog/image-20230609204957690.png" alt="image-20230609204957690"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>开始的时候客户端压2个Tomcat集群，QPS 700，Tomcat节点CPU 90%，Database每个节点CPU 20%左右，于是增加1个Tomcat 节点这个时候QPS 还是700，Tomcat的RT增加了50%，Tomcat CPU 降低到60%，继续增加Tomcat 节点 RT、QPS保持稳定，CPU使用率下降。</p>
<p>所以这里要搞清楚哪里是瓶颈，如果Tomcat是瓶颈加Tomcat节点为什么没有效果。如果Database是瓶颈但是增加Tomcat节点的时候Database 的RT有一点点增加，远远没有到增加50%的RT 程度</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>首先最容易想到的是Tomcat 和 Database之间的网络、网关、LVS 等资源到了瓶颈，但是经过排查分析这些环节都排除了，另外也排除了Tomcat到Database的连接池、Database的磁盘等瓶颈，另外Tomcat 访问Database全是查询，没有事务。</p>
<p><img src="/images/951413iMgBlog/20230609210244.jpg" alt="image.png"></p>
<p>看起来事情比想象的复杂，于是进行了如下压测：</p>
<p>先用一个压力端压3个Tomcat中的2个，QPS 跑到700，然后新开一个压力端压第三个Tomcat(新开压力端是排查压力机的问题，新开Tomcat是想排除Tomcat 的问题)，如果Tomcat是瓶颈的话QPS应该上去，或者说后端没有问题的话那两个Tomcat 的700 QPS得保持基本稳定不变或略微下降才对。</p>
<p>实际上第二个压力端跑起来后，前两个Tomcat的QPS 铛就掉下去了，总QPS 保持稳定不变，也就是随着Tomcat给后端并发压力的增加后端肯定给了一个负反馈给那两Tomcat，导致那两Tomcat QPS掉下去了。这个负反馈明显得是Database的RT在增加，但是从监控来看Database的RT 从0.6增加到了0.8，但是Tomcat 的RT 增加更快从19.7增加到了29.8.</p>
<p>单独压DB，DB的QPS能高5倍，CPU 也可以跑到100%。看起来单压都没问题，一组合就不行了</p>
<h3 id="问题在Database"><a href="#问题在Database" class="headerlink" title="问题在Database"></a>问题在Database</h3><p>绕过Tomcat 用相同的SQL 压Database QPS 一下子就能上去，Database 的CPU 也跑到了100%，但是只要走Tomcat 就会上不去。</p>
<p>打开Tomcat 日志将所有Database的响应时间拉出来分析，发现随着并发的增加 100 ms的响应也多了很多，实际上这些查询都是1ms就应该返回</p>
<p>具体分析过程看这里：<a href="https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/">https://plantegg.github.io/2019/12/16/Intel%20PAUSE%E6%8C%87%E4%BB%A4%E5%8F%98%E5%8C%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E8%87%AA%E6%97%8B%E9%94%81%E4%BB%A5%E5%8F%8AMySQL%E7%9A%84%E6%80%A7%E8%83%BD%E7%9A%84/</a></p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>当压力增加的时候MySQL端等锁导致的 RT 抖动或者说长尾越来越多，虽然没有数据库的写，但是查询的时候优化器也需要统计行数等数据来为查询优化器做选择依据，这个统计动作会触发加锁排队(极短)，但是因为这一代Intel CPU指令的变化导致这个锁被放大了10 被，所以最终Tomcat 端看到的长尾就多了</p>
<h2 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h2><h4 id="为什么同样的环境、同样的SQL-绕过Tomcat-就能压上去？"><a href="#为什么同样的环境、同样的SQL-绕过Tomcat-就能压上去？" class="headerlink" title="为什么同样的环境、同样的SQL 绕过Tomcat 就能压上去？"></a>为什么同样的环境、同样的SQL 绕过Tomcat 就能压上去？</h4><p>绕过后的压测场景没有业务逻辑，每次请求就是一条SQL，虽然有抖动但是对平均RT拉升不明显。</p>
<h4 id="走业务逻辑压Tomcat-为什么不行？"><a href="#走业务逻辑压Tomcat-为什么不行？" class="headerlink" title="走业务逻辑压Tomcat 为什么不行？"></a>走业务逻辑压Tomcat 为什么不行？</h4><p>业务逻辑是一次请求会发256条SQL，等这256条SQL全部返回来了业务请求才会返回！请反复读这句话3遍再往下看</p>
<p>如果256条SQL 中有一条花了100 ms返回那么整个业务逻辑的RT 就是100ms，假设1%的概率一条SQL是100ms，99%的SQL 是 1ms，你可以先停下来算一算这种业务模型下的平均RT是多少</p>
<h4 id="计算抖动下的平均RT"><a href="#计算抖动下的平均RT" class="headerlink" title="计算抖动下的平均RT"></a>计算抖动下的平均RT</h4><p>关于这个抖动对整体rt的影响计算：</p>
<p><img src="/images/951413iMgBlog/1575880425321-79c7ea4a-fcf1-41f9-afb9-6e553d9eaf8f.png" alt="img"></p>
<p>注:假设正常查询rt 1ms，逻辑平均rt=(1-power(1-抖动概率,物理查询次数))<em>抖动大小+(power(1-抖动概率,物理查询次数))</em>1ms </p>
<p>当前场景下，逻辑QPS:物理QPS=1:256，假如每次查询有1%的物理（RDS）rt抖动到100ms，则会导致逻辑平均rt恶化到92.44ms.</p>
<p>在一次逻辑查询里，只有所有物理查询都不抖整体才是不抖，RT正常；如果有一个或多个物理查询抖了，那么逻辑RT就是抖动RT。</p>
<p>所以一次逻辑查询不抖的概率是： power(1-抖动概率, 物理查询次数)</p>
<p>反过来想这256条SQL都不碰上抖动这次业务请求才会1ms返回(概率极低)，否则就是256ms返回</p>
<h4 id="为什么要讲这个案例"><a href="#为什么要讲这个案例" class="headerlink" title="为什么要讲这个案例"></a>为什么要讲这个案例</h4><p>倒不是出于原因分析，这个原因几年前就分析清楚了，但是这个场景：一次业务请求会涉及多次SQL、Redis、MQ的调用，只要其中有一个有短板、抖动这次业务请求就慢了。这简直太常见了</p>
<p>但难在别人的抖动很低被平均掉了，但是业务(Tomcat) 就要替别人背锅了，因为别人的RT 几乎没有增加或者加很少，但是Tomcat RT增加很明显，瓶颈当然看着像是在Tomcat 上。背锅吧也不可怕可怕的是你增加Tomcat 节点也不能解决问题，这才是你要从这个案例里学到的。</p>
<p>如果你的Tomcat 调后端因为短板(抖动)导致压力打不到后端，因为抖动导致Tomcat不能快速返回</p>
<h5 id="上游影响下游："><a href="#上游影响下游：" class="headerlink" title="上游影响下游："></a>上游影响下游：</h5><p>和本文无关但是可以放一起综合来看上下游互相影响的复杂性</p>
<p>以前认为事务不提交的主要代价是行锁持有时间变长(这确实是个问题)，今天见识到了新代价，事务不提交会导致事务活跃链表变长，增加copy readview的代价，进而导致DB的RT 增高，实际导致DB RT高的根本原因是DB前面的业务早到了瓶颈，来不及发送commit，导致DB端事务堆积严重。也就是业务瓶颈导致了后端DB RT高，只看RT就会被蒙蔽——怎么解决？可以抓包看commit发送慢</p>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;扑朔迷离的根因分析–抖动和并发&quot;&gt;&lt;a href=&quot;#扑朔迷离的根因分析–抖动和并发&quot; class=&quot;headerlink&quot; title=&quot;扑朔迷离的根因分析–抖动和并发&quot;&gt;&lt;/a&gt;扑朔迷离的根因分析–抖动和并发&lt;/h1&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;
    
    </summary>
    
      <category term="performance" scheme="https://plantegg.github.io/categories/performance/"/>
    
    
      <category term="performance" scheme="https://plantegg.github.io/tags/performance/"/>
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="druid" scheme="https://plantegg.github.io/tags/druid/"/>
    
      <category term="RT" scheme="https://plantegg.github.io/tags/RT/"/>
    
  </entry>
  
  <entry>
    <title>实战瓶颈定位-我的MySQL为什么压不上去--写场景</title>
    <link href="https://plantegg.github.io/2023/06/30/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB--%E5%86%99%E5%9C%BA%E6%99%AF/"/>
    <id>https://plantegg.github.io/2023/06/30/实战瓶颈定位-我的MySQL为什么压不上去--写场景/</id>
    <published>2023-06-30T09:30:03.000Z</published>
    <updated>2023-06-28T08:44:11.022Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实战瓶颈定位-我的MySQL为什么压不上去–写场景"><a href="#实战瓶颈定位-我的MySQL为什么压不上去–写场景" class="headerlink" title="实战瓶颈定位-我的MySQL为什么压不上去–写场景"></a>实战瓶颈定位-我的MySQL为什么压不上去–写场景</h1><p>纠结好久要不要写这篇，因为原因非常坑爹，你们基本不会遇到，想了很久觉得思路还是有些价值，所以还是写一下，我尽量简单</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>继续上文 <a href="https://plantegg.github.io/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/">https://plantegg.github.io/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/</a> ，纯读场景问题解决后，继续压纯写场景，比另外一套类似环境差了很多，大概是2折。</p>
<p>纯写肯定有预期：会有锁、磁盘瓶颈等问题</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>先看top，结果很明显CPU上不去，并且有一个单核长时间 100%，然后 top -Hp mysqld-pid 展开所有线程，果然一直有一个线程几乎一直 100%，这就太明显了，这个线程遇到了瓶颈，导致整体上不去。</p>
<p><img src="/images/951413iMgBlog/image-20230515083125494.png" alt="image-20230515083125494"></p>
<p>top -Hp mysqld-pid 看到165935 线程一直几乎是 100% 的CPU 状态</p>
<p><img src="/images/951413iMgBlog/image-20230515083309083.png" alt="image-20230515083309083"></p>
<p>所以接下来要搞清楚这个线程在忙什么，刷盘？抢锁？</p>
<p>如果是Java应用就简单了，直接jstack一看就很清楚了，但是MySQLD没这么容易，另外环境里没有 pstack也没法安装，所以这条路走不通。</p>
<p>但是大概率能猜出来和磁盘有点关系，于是iostat -x -d 看看磁盘情况，好家伙果然ioutil 100%，磁盘 IO TPS 好几万。如下nvme0n1是MySQLD 使用的SSD 数据盘，vdb 是OS 系统盘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#iostat  -d vdb nvme0n1 3</div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">nvme0n1       45317.33        37.33    322150.67        112     966452</div><div class="line">vdb               0.00         0.00         0.00          0          0</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">nvme0n1       45215.33        37.33    319228.00        112     957684</div><div class="line">vdb               0.00         0.00         0.00          0          0</div><div class="line"></div><div class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</div><div class="line">nvme0n1       45146.00        42.67    320677.33        128     962032</div><div class="line">vdb               0.00         0.00         0.00          0          0</div></pre></td></tr></table></figure>
<p>通过 ：iostat -x -d vdb nvme0n1 3 可以看到如下图</p>
<p><img src="/images/951413iMgBlog/image-20230515083645463.png" alt="image-20230515083645463"></p>
<p>但这是不是正常情况不好说，于是找到家里同样的环境跑起来(没有单线程 100%问题，QPS 比问题环境高了 5倍)，于是也看一下 iostat 做一个对比，对比发现 ioutil 很小，然后磁盘 IO TPS 才我问题环境的30%，在QPS 5倍，IO TPS才 30%的情况下傻子也能看出来这两场景肯定不一样。一个QPS触发的IO TPS差了 15倍了。</p>
<p>不啰嗦，将问题环境的sysbench 脚本复制到正常环境，这下问题重现了，再diff看看两个脚本果然被人改了。问题环境使用的sysbench是别人装的，经过分析后发现里面被改动过一些东西。</p>
<p>之所以一直没有怀疑 sysbench 的问题，也有之前测试只读场景的时候符合预期，所以忽视了sysbench的差异。</p>
<p>这让我想起贝尔实验室Ken Thompson’s “cc hack” 的八卦(有兴趣的同学可以自行查证一下)：</p>
<blockquote>
<p>当年在贝尔实验室，人们都用Unix系统，但是只有Ken可以绕过密码直接登录，让其他人百思不得其解。按理说整个Unix系统是开源的，很多人检查了系统代码，尤其是登录部分， 并没有发现任何漏洞或者后门。</p>
<p>Ken的同事们不断重新编译Unix， 但是Ken依旧如幽灵一般来去自如。</p>
<p>有人怀疑编译Unix的编译器里面有代码，但是当他们反复检查编译器源码，甚至重新编译c编译器后，依旧没有任何发现。</p>
<p>多年后，在Turing Award Lecture中，Ken终于道出了事情真相，登录源码和编译器源码都是干净的。事实上，这个幽灵般的木马在编译器的可执行文件中。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这里的思路是：单线程100%-&gt;磁盘IO TPS非常高-&gt;和正常环境对比(常用手段，也要运气好有两个环境可以对比)-&gt;一个QPS 对应的IO TPS差异巨大-&gt;压测脚本问题</p>
<p>这算是个坑爹的小问题，大家也不会碰到，比网络限速难查多了，网络限速那里我们有放之四海而皆准的 RT 逻辑+抓包，所以很好定位。但是查证分析过程我觉得有一定的参考性，所以记录下。</p>
<p>如果MySQLD能提供一个内部任何一个操作的时间就好了，实际很难实现。当然通过火焰图去看异常偏高的调用是另外一个方向。</p>
<p>跨网络我们有抓包很好界定，但是问题到进程内部的时候反而没了抓包这种一锤定影的工具了</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;实战瓶颈定位-我的MySQL为什么压不上去–写场景&quot;&gt;&lt;a href=&quot;#实战瓶颈定位-我的MySQL为什么压不上去–写场景&quot; class=&quot;headerlink&quot; title=&quot;实战瓶颈定位-我的MySQL为什么压不上去–写场景&quot;&gt;&lt;/a&gt;实战瓶颈定位-我的My
    
    </summary>
    
      <category term="performance" scheme="https://plantegg.github.io/categories/performance/"/>
    
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="MySQL" scheme="https://plantegg.github.io/tags/MySQL/"/>
    
      <category term="sysbench" scheme="https://plantegg.github.io/tags/sysbench/"/>
    
  </entry>
  
  <entry>
    <title>等额本息和等额本金以及提前还贷误区</title>
    <link href="https://plantegg.github.io/2023/06/30/%E7%AD%89%E9%A2%9D%E6%9C%AC%E9%87%91%E5%92%8C%E7%AD%89%E9%A2%9D%E6%9C%AC%E6%81%AF%E4%BB%A5%E5%8F%8A%E6%8F%90%E5%89%8D%E8%BF%98%E8%B4%B7/"/>
    <id>https://plantegg.github.io/2023/06/30/等额本金和等额本息以及提前还贷/</id>
    <published>2023-06-30T04:30:03.000Z</published>
    <updated>2024-02-20T09:57:12.753Z</updated>
    
    <content type="html"><![CDATA[<h1 id="等额本息和等额本金以及提前还贷误区"><a href="#等额本息和等额本金以及提前还贷误区" class="headerlink" title="等额本息和等额本金以及提前还贷误区"></a>等额本息和等额本金以及提前还贷误区</h1><h5 id="1-等额本金和等额本息的差异"><a href="#1-等额本金和等额本息的差异" class="headerlink" title="1 等额本金和等额本息的差异"></a>1 等额本金和等额本息的差异</h5><p>没有差异。等额本金=等额本息+每月提前还贷一点点()</p>
<h5 id="2-为什么等额本金总利息少"><a href="#2-为什么等额本金总利息少" class="headerlink" title="2 为什么等额本金总利息少"></a>2 为什么等额本金总利息少</h5><p>因为每个月等额本金还款多，第一个月后欠本金少了，后面每个月都是这样，所还本金更多，最终总利息自然更少</p>
<blockquote>
<p>其实可以用极限思维来分析他们的差异：假设等额本息和等额本金都借100万，周期一个月(没看错，一个月还清，极限假设)，所以一个月后他们还钱一样多！所以这个时候没有任何区别；现在继续假设，假如还款周期是2个月，那么等额本金在第一个月还钱多，导致等额本金在第二个月的时候欠钱少了，到第二个月月底还清所有欠款的时候利息要少(本金少了)——这才是他们的差异，所以是没区别的。等额本金这两个月相当于欠了银行150万一个月(第一个月欠100万，第二个月欠50万) 应还利息就是150万 乘以 月利率；等额本息相当于欠了银行 151万（第一个月欠100万，第二个月51万，因为第一个月还钱的时候只还了49万本金），所以应还利息就是 151万 乘以 月利率；欠得多利息就多天经地义这里没有投机、没有人吃亏</p>
<p>再或者换个思路：第一个月借100万，月底都还清，此时利息一样多；然后再借出来99.X万，这时等额本金借得少这个X更小，所以从第二个月开始等额本金还的利息少，归根结底换利息少是因为借得少(即现实中的还本金多)</p>
</blockquote>
<p>把上面的极限思维图形化就是下图中的灰色部分面积代表你的欠款(每个月的欠款累加)，等额本息的方式欠得多，自然利息多：</p>
<p><img src="/images/951413iMgBlog/image-20230704214346239.png" alt="image-20230704214346239"></p>
<h5 id="3-为什么总有等额本金划得来的说法"><a href="#3-为什么总有等额本金划得来的说法" class="headerlink" title="3 为什么总有等额本金划得来的说法"></a>3 为什么总有等额本金划得来的说法</h5><p>同样贷款金额下等额本金总还款额少，也就是总利息少，所以给了很多人划得来的感觉，或者给人感觉利息便宜。其实这都是错的，解释如上第二个问题</p>
<h5 id="4-利息的计算方式"><a href="#4-利息的计算方式" class="headerlink" title="4 利息的计算方式"></a>4 利息的计算方式</h5><p>利息每个月计算一次，这个月所欠本金*月利率。所以利息只和你欠钱多少有关（我们假设所有人的利率都一样）。每个月的月供，都是先还掉这个月的利息，多余的再还本金</p>
<p>等额本金因为每个月还掉的本金多，所以计算下来每个月的利息更少</p>
<h5 id="5-如何理解等额本金和等额本息"><a href="#5-如何理解等额本金和等额本息" class="headerlink" title="5 如何理解等额本金和等额本息"></a>5 如何理解等额本金和等额本息</h5><p>同样贷款额+利率的话等额本金开始还款一定比等额本息要多一些，那么你可以把等额本金分成两块，一块和等额本息一样，多出来的部分你把他看成这个月额外做了一次提前还款。你提前还款了后面的总利息自然也会更少一些，然后每个月的等额本息也会减少，以此类推每个月都是这样额外做一次提前还款直到最后一个月。</p>
<p>总结：等额本金=等额本息+提前还贷</p>
<p>额本金开始还款一定比等额本息要多一些，可以把等额本金分成两块，一块和等额本息一样，多出来的部分把他看成这个月额外做了一次提前还款。提前还款后总利息也会更少一些，然后每个月的等额本息也会减少，以此类推每个月都是这样额外做一次提前还款直到最后一个月。</p>
<h5 id="6-提前还款划不划得来"><a href="#6-提前还款划不划得来" class="headerlink" title="6 提前还款划不划得来"></a>6 提前还款划不划得来</h5><p>钱在你手里没法赚到比利息更高的收益的话(99%的人属于这种)提前还贷划得来，之所以以前不建议大家提前还贷，是因为以前普遍涨薪快、通胀厉害、房价涨得块，把钱留出来继续买二套、三套更赚钱。另外钱留在手里会有主动权和应急方便</p>
<h5 id="7-提前还贷会多付利息吗？"><a href="#7-提前还贷会多付利息吗？" class="headerlink" title="7 提前还贷会多付利息吗？"></a>7 提前还贷会多付利息吗？</h5><p>不会，见第四条利息的计算方式。担心提前还贷的时候这比贷款把后面10年的利息收走了的是脑子不好使的人。但有些银行提前还贷会有违约金</p>
<h5 id="8-为什么等额本金和等额本息给了这么多人错觉"><a href="#8-为什么等额本金和等额本息给了这么多人错觉" class="headerlink" title="8 为什么等额本金和等额本息给了这么多人错觉"></a>8 为什么等额本金和等额本息给了这么多人错觉</h5><p>从知识的第一性出发，他们都没理解第4条，受社会普遍意识影响都预先留下了错误经验。本质就是利息只和贷款额、利率有关。</p>
<h5 id="9-贷款30年和10年利率有差异吗？"><a href="#9-贷款30年和10年利率有差异吗？" class="headerlink" title="9 贷款30年和10年利率有差异吗？"></a>9 贷款30年和10年利率有差异吗？</h5><p>没有</p>
<h5 id="10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？"><a href="#10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？" class="headerlink" title="10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？"></a>10贷款30年，还了6年了，然后一次还清所有欠款会多还利息吗？</h5><p>不会，你前6年只是还了前6年的利息，没为之后的6年多付一分利息</p>
<h5 id="11-那为什么利率不变我每个月利息越来越少"><a href="#11-那为什么利率不变我每个月利息越来越少" class="headerlink" title="11 那为什么利率不变我每个月利息越来越少"></a>11 那为什么利率不变我每个月利息越来越少</h5><p>因为你欠的钱越来越少了，不是你提前还了利息，是你一直在还本金</p>
<h5 id="12-网购分期合适吗？"><a href="#12-网购分期合适吗？" class="headerlink" title="12 网购分期合适吗？"></a>12 网购分期合适吗？</h5><p>大部分小贷公司的套路就是利用你每个月已经在还本金的差异，利息自然越来越少，然后计算一个大概5%的年息误导你，实际这种网购分期的实际利息要是他计算的2倍……好好想想</p>
<p>等额本金、本息都搞不清楚的人就不要去搞分期了，你的脑瓜子在这方面不好使。</p>
<p>聪明人只看第4条就能在大脑里得出所有结论，普通人除了要有第4条还需要去看每个月的还款额、还款额里面的本金、还款额里的利息等实践输入才能理解这个问题，这就是差异</p>
<p><img src="/images/951413iMgBlog/房贷.jpg" alt="房贷"></p>
<p><a href="https://zhuanlan.zhihu.com/p/161405128" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/161405128</a></p>
<h2 id="提前还贷"><a href="#提前还贷" class="headerlink" title="提前还贷"></a>提前还贷</h2><h5 id="要不要提前还贷"><a href="#要不要提前还贷" class="headerlink" title="要不要提前还贷"></a>要不要提前还贷</h5><p>要</p>
<h5 id="提前还贷划得来吗？"><a href="#提前还贷划得来吗？" class="headerlink" title="提前还贷划得来吗？"></a>提前还贷划得来吗？</h5><p>划不划得来要看这笔钱在你手里能否获得比房贷利息更高的收入以及你对流动资金的需要。其实万一有个啥事也可以走消费贷啥的，现在利息都很低</p>
<h5 id="等额本息比等额本金提前还贷更划得来？"><a href="#等额本息比等额本金提前还贷更划得来？" class="headerlink" title="等额本息比等额本金提前还贷更划得来？"></a>等额本息比等额本金提前还贷更划得来？</h5><p>一样的，你这个问题等价于我欠100万，老婆欠50万，所以我提前还贷比朋友合算吗？显然你两谁提前还贷合算只和你两的贷款利率是否有差别</p>
<p>等额本息和等额本金利率一样的，所以没有差别</p>
<h5 id="20年的房贷我已经还了15年了是不是不值得提前还贷了？"><a href="#20年的房贷我已经还了15年了是不是不值得提前还贷了？" class="headerlink" title="20年的房贷我已经还了15年了是不是不值得提前还贷了？"></a>20年的房贷我已经还了15年了是不是不值得提前还贷了？</h5><p>错误！利率还是那个利率，跟你还剩10年和还剩5年没关系，提前还贷都是等价的。记住有闲钱就提前还</p>
<h5 id="问题的本质"><a href="#问题的本质" class="headerlink" title="问题的本质"></a>问题的本质</h5><p>搞清楚每个月的利息怎么计算出来的  利息=欠款额*月利率，月供都是把本月利息还掉多出来的还本金，也就是每个月欠款额会变少</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>每个领域都有一些核心知识点代表着这些问题的本质，你只有把核心知识点或者说问题本质搞懂了才能化繁为简、不被忽悠！</p>
<p>那贷款这里的本质是什么？就是利息只和你每个月欠款以及利率有关！这简直是屁话，太简单了，但你不能理解他，就容易被套上等额本金、等额本息、提前还贷的外壳给忽悠了。</p>
<p>再或者说这里的本质就是：你去搞清楚每个月的还款是怎么计算的。月供=本月所欠X利率+本月还掉的本金  这是个核心公式，差别在每个月还掉的本金不一样！</p>
<p>就这样吧该懂的也该看懂了，看不懂的大概怎么样也看不懂！只能说是蠢，这些人肯定理科不好、逻辑不行，必定做不了程序员。</p>
<p>比如网上流传的如图总结的所有结论都是错的：</p>
<p><img src="/images/951413iMgBlog/image-20230704215506179.png" alt="image-20230704215506179"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;等额本息和等额本金以及提前还贷误区&quot;&gt;&lt;a href=&quot;#等额本息和等额本金以及提前还贷误区&quot; class=&quot;headerlink&quot; title=&quot;等额本息和等额本金以及提前还贷误区&quot;&gt;&lt;/a&gt;等额本息和等额本金以及提前还贷误区&lt;/h1&gt;&lt;h5 id=&quot;1-等额本
    
    </summary>
    
      <category term="技巧" scheme="https://plantegg.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="贷款" scheme="https://plantegg.github.io/tags/%E8%B4%B7%E6%AC%BE/"/>
    
  </entry>
  
  <entry>
    <title>实战瓶颈定位-我的MySQL为什么压不上去</title>
    <link href="https://plantegg.github.io/2023/06/20/%E5%AE%9E%E6%88%98%E7%93%B6%E9%A2%88%E5%AE%9A%E4%BD%8D-%E6%88%91%E7%9A%84MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8E%8B%E4%B8%8D%E4%B8%8A%E5%8E%BB/"/>
    <id>https://plantegg.github.io/2023/06/20/实战瓶颈定位-我的MySQL为什么压不上去/</id>
    <published>2023-06-20T09:30:03.000Z</published>
    <updated>2024-02-20T09:57:14.449Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实战瓶颈定位-我的MySQL为什么压不上去"><a href="#实战瓶颈定位-我的MySQL为什么压不上去" class="headerlink" title="实战瓶颈定位-我的MySQL为什么压不上去"></a>实战瓶颈定位-我的MySQL为什么压不上去</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>环境两台云上相同 128C的EC2(有点豪)，一台当压力机一台当服务器，用Sysbench测试MySQL纯读场景，不存在任何修改，也就几乎没有锁</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#uname -r</div><div class="line">5.10.84.aarch64</div><div class="line"></div><div class="line">Server:            MySQL</div><div class="line">Server version:        8.0.18 Source distribution</div></pre></td></tr></table></figure>
<p>EC2机器128核，故意只给MySQLD绑定了其中的24Core，网卡32队列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#ethtool -l eth0</div><div class="line">Channel parameters for eth0:</div><div class="line">Pre-set maximums:</div><div class="line">RX:        0</div><div class="line">TX:        0</div><div class="line">Other:        0</div><div class="line">Combined:    32</div><div class="line">Current hardware settings:</div><div class="line">RX:        0</div><div class="line">TX:        0</div><div class="line">Other:        0</div><div class="line">Combined:    32</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/FlDlXFTuGa0BPv1YxR3KQZaP40de.png" alt="img"></p>
<h2 id="压测过程"><a href="#压测过程" class="headerlink" title="压测过程"></a>压测过程</h2><p>走同一交换机内网IP压MySQL跑不满CPU，跑压力和不跑压力时ping rtt 分别是 0.859/0.053(RTT 有增加–注意点), 此时TPS：119956.67 1000并发 RT 8.33</p>
<p>下图是压测时 htop 看到的MySQLD 所在EC2的 CPU使用情况，右边65-88是MySQLD进程(绿色表示us, 红色表示sys+si CPU)</p>
<p><img src="/images/951413iMgBlog/image-20230511125934259.png" alt="image-20230511125934259"></p>
<p>用top查看详细的每个 core 使用(只展示MySQLD使用的24core ，top 然后按1–还可以试试2/3，有惊喜)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">top - 13:49:55 up 160 days, 18:10,  3 users,  load average: 555.26, 720.12, 462.21</div><div class="line">Tasks: 1065 total,   1 running, 499 sleeping,   0 stopped,   0 zombie</div><div class="line">%Node1 : 10.1 us,  5.3 sy,  0.0 ni, 83.3 id,  0.0 wa,  0.0 hi,  1.3 si,  0.0 st</div><div class="line">%Cpu64 : 29.3 us, 16.5 sy,  0.0 ni, 54.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu65 : 37.0 us, 18.5 sy,  0.0 ni, 26.9 id,  0.0 wa,  0.0 hi, 17.5 si,  0.0 st</div><div class="line">%Cpu66 : 34.2 us, 17.8 sy,  0.0 ni, 47.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu67 : 26.0 us, 15.1 sy,  0.0 ni, 58.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu68 : 26.1 us, 14.8 sy,  0.0 ni, 59.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu69 : 27.2 us, 13.8 sy,  0.0 ni, 59.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu70 : 25.7 us, 11.8 sy,  0.0 ni, 62.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu71 : 18.3 us, 10.6 sy,  0.0 ni, 71.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu72 : 29.7 us, 12.6 sy,  0.0 ni, 57.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu73 : 21.2 us, 13.0 sy,  0.0 ni, 65.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu74 : 18.9 us, 10.8 sy,  0.0 ni, 70.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu75 : 28.9 us, 15.1 sy,  0.0 ni, 36.1 id,  0.0 wa,  0.0 hi, 19.9 si,  0.0 st</div><div class="line">%Cpu76 : 30.3 us, 15.5 sy,  0.0 ni, 54.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu77 : 25.1 us, 13.2 sy,  0.0 ni, 61.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu78 : 18.2 us, 10.3 sy,  0.0 ni, 71.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu79 : 14.9 us,  8.8 sy,  0.0 ni, 76.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu80 : 23.4 us, 12.2 sy,  0.0 ni, 64.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu81 : 35.3 us, 17.6 sy,  0.0 ni, 30.2 id,  0.0 wa,  0.0 hi, 16.9 si,  0.0 st</div><div class="line">%Cpu82 : 28.2 us, 16.1 sy,  0.0 ni, 55.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu83 : 37.5 us, 16.9 sy,  0.0 ni, 27.0 id,  0.0 wa,  0.0 hi, 18.6 si,  0.0 st</div><div class="line">%Cpu84 : 35.4 us, 18.5 sy,  0.0 ni, 46.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu85 : 27.9 us, 16.8 sy,  0.0 ni, 55.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu86 : 28.2 us, 13.7 sy,  0.0 ni, 58.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu87 : 27.2 us, 11.0 sy,  0.0 ni, 61.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu88 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div></pre></td></tr></table></figure>
<p>继续尝试用2000并发，TPS、CPU、ping rtt都和1000并发没有区别，当然按照我们以前QPS、RT理论2000并发的时候RT应该翻倍，实际确实是16.66，<strong>所以这里的问题就是翻倍的 RT哪里来的瓶颈就在哪里</strong>。</p>
<p>也试过用两个压力机每个压力机分别用1000并发同时压，QPS一样稳定——目的快速排除压力端、链路上有瓶颈。</p>
<p>写到这里RT 刚好翻倍16.66=8.33*2 数字精准得好像编故事一样，不得不贴一下原始数据证实一下：</p>
<p><img src="/images/951413iMgBlog/image-20230511130851332.png" alt="image-20230511130851332"></p>
<p>1000 并发和2000并发时的ping RTT对比(ttl 64说明内网直达)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">#ping mysqld27</div><div class="line">PING yt27 (mysqld217) 56(84) bytes of data.</div><div class="line">---以下是2000并发</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=1 ttl=64 time=0.867 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=2 ttl=64 time=0.952 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=3 ttl=64 time=0.849 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=4 ttl=64 time=0.857 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=5 ttl=64 time=0.987 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=6 ttl=64 time=0.860 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=7 ttl=64 time=0.909 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=8 ttl=64 time=0.875 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=9 ttl=64 time=0.979 ms  </div><div class="line">---终止压测，无无压力的rtt</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=10 ttl=64 time=0.104 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=11 ttl=64 time=0.079 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=12 ttl=64 time=0.075 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=13 ttl=64 time=0.075 ms </div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=14 ttl=64 time=0.074 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=15 ttl=64 time=0.078 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=16 ttl=64 time=0.075 ms</div><div class="line">---开启1000并发时的rtt</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=17 ttl=64 time=0.872 ms </div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=18 ttl=64 time=0.969 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=19 ttl=64 time=0.862 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=20 ttl=64 time=0.877 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=21 ttl=64 time=0.961 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=22 ttl=64 time=0.828 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=23 ttl=64 time=0.098 ms</div><div class="line">64 bytes from mysqld27 (mysqld217): icmp_seq=24 ttl=64 time=0.083 ms</div></pre></td></tr></table></figure>
<h3 id="抓包证明"><a href="#抓包证明" class="headerlink" title="抓包证明"></a>抓包证明</h3><p>在抓保证明前推荐一个工具快速绕过抓包(原理也是通过pcap lib去分析网络包，tcpdump也会调用pcap lib)</p>
<p><a href="https://github.com/y123456yz/tcprstat" target="_blank" rel="external">监控tcprstat</a>，从网络层抓包来对比两个并发下的RT：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">#tcprstat -p 14822 -t 1 -n 0 -l mysqld217 -f &quot;%T\t\t%n\t\t%a\n&quot;</div><div class="line">timestamp        count        avg</div><div class="line">1683785023        50743        626</div><div class="line">1683785024        120004        100</div><div class="line">1683785025        120051        103</div><div class="line">1683785026        120042        102</div><div class="line">1683785027        120031        103</div><div class="line">1683785028        120034        104</div><div class="line">1683785029        120034        104</div><div class="line">1683785030         55209        103    ---以上是2000并发</div><div class="line">1683785038        0        0</div><div class="line">1683785039        0        0</div><div class="line">1683785040         55224        614    ---以下是1000并发</div><div class="line">1683785041        119998        104</div><div class="line">1683785042        120039        105</div><div class="line">1683785043        120039        105</div><div class="line">1683785044        120026        107</div><div class="line">1683785045        120039        108</div><div class="line">1683785046        120047        108</div><div class="line">1683785047        120037        108</div><div class="line">1683785048        120032        108</div><div class="line">1683785049        120041        108</div></pre></td></tr></table></figure>
<p>也就是网卡层面<strong>确认了压不上去瓶颈不在MySQL</strong> 上，加并发后网卡的RT没变(网卡RT包含MySQLD RT)，因为ping RTT 在1000和2000并发也没有差异，推测交换机不是瓶颈，大概率出网卡的虚拟层面</p>
<p>在客户端的机器上抓包，上面我们说过了1000并发的RT是8.33毫秒：</p>
<p><img src="/images/951413iMgBlog/image-20230511141508811.png" alt="image-20230511141508811"></p>
<p>注意上图，我把RT排序了，明显看到5ms到17ms 中间没有这个RT范围的包，但是有很多25ms的RT，平均下来确实是8.33毫秒，留下一个疑问：RT分布不符合正态，而且中间有很大一段范围镂空了！这是不应该的。</p>
<p>同样我们再到MySQLD 所在机器抓包分析(注：正常路径先抓MySQLD上的包就行了)：</p>
<p><img src="/images/951413iMgBlog/image-20230511141925557.png" alt="image-20230511141925557"></p>
<p>同样是对RT 排序了，但是慢的RT都是对端发慢了(注意最右边的select， MySQL相应是 response)，同样对这个抓包求平均时间就是tcprstat 看到的103微秒，也就是0.1毫秒。如下图红框是请求，请求的间隔是11毫米，绿框是响应，响应的间隔都是0.2ms不到</p>
<p><img src="/images/951413iMgBlog/image-20230513084610300.png" alt="image-20230513084610300"></p>
<p>同样在2000并发时也对MySQLD所在网卡抓包对比，response 的RT 没有变化，从这里可以看出瓶颈点在sysbench 和 MySQLD 的网卡之间的链路上，似乎有限流、管控</p>
<p><img src="/images/951413iMgBlog/image-20230512084446715.png" alt="image-20230512084446715" style="zoom:35%;"></p>
<h3 id="快速验证"><a href="#快速验证" class="headerlink" title="快速验证"></a>快速验证</h3><p>到这里我们已经找到了有力的证据，RT是在离开MySQLD网卡后增加上去的，先验证下走走本机127.0.0.1快速压一把，让sysbench 跑在0-7 core上，这时可以看到MySQL跑满了CPU，下图左边1-8核是压力进程，右边65-88是业务进程，TPS：239969.91 1000并发 RT 4.16</p>
<p>htop状态：</p>
<p><img src="/images/951413iMgBlog/image-20230511125346066.png" alt="image-20230511125346066"></p>
<p>各CPU 详细分析：</p>
<ul>
<li>us MySQL解析SQL、处理查询</li>
<li>si  网络软中断</li>
<li>sy OS 的sys API 消耗，一般用户进程会调用系统 API, 比如读写文件、分配内存、网络访问等</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">//sysbench</div><div class="line">top - 13:44:27 up 160 days, 18:04,  3 users,  load average: 792.17, 619.09, 311.58</div><div class="line">Tasks: 1073 total,   1 running, 500 sleeping,   0 stopped,   0 zombie</div><div class="line">%Cpu0  : 14.0 us, 29.1 sy,  0.0 ni, 33.3 id,  0.0 wa,  0.0 hi, 23.5 si,  0.0 st</div><div class="line">%Cpu1  : 12.5 us, 33.0 sy,  0.0 ni, 33.7 id,  0.0 wa,  0.0 hi, 20.8 si,  0.0 st</div><div class="line">%Cpu2  : 11.2 us, 32.7 sy,  0.0 ni, 34.2 id,  0.0 wa,  0.0 hi, 21.9 si,  0.0 st</div><div class="line">%Cpu3  : 13.4 us, 31.2 sy,  0.0 ni, 34.4 id,  0.0 wa,  0.0 hi, 21.0 si,  0.0 st</div><div class="line">%Cpu4  : 12.1 us, 31.3 sy,  0.0 ni, 34.2 id,  0.0 wa,  0.0 hi, 22.4 si,  0.0 st</div><div class="line">%Cpu5  : 10.5 us, 31.8 sy,  0.0 ni, 33.6 id,  0.0 wa,  0.0 hi, 24.1 si,  0.0 st</div><div class="line">%Cpu6  : 12.9 us, 31.3 sy,  0.0 ni, 34.2 id,  0.0 wa,  0.0 hi, 21.6 si,  0.0 st</div><div class="line">%Cpu7  : 12.3 us, 31.4 sy,  0.0 ni, 34.3 id,  0.0 wa,  0.0 hi, 22.0 si,  0.0 st</div><div class="line">%Cpu8  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line"></div><div class="line">//MySQLD</div><div class="line">Tasks: 1073 total,   1 running, 505 sleeping,   0 stopped,   1 zombie</div><div class="line">%Node1 : 22.6 us, 10.1 sy,  0.0 ni, 62.4 id,  0.0 wa,  0.0 hi,  4.8 si,  0.0 st</div><div class="line">%Cpu64 : 57.9 us, 29.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.9 si,  0.0 st</div><div class="line">%Cpu65 : 60.3 us, 26.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.6 si,  0.0 st</div><div class="line">%Cpu66 : 57.6 us, 28.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.2 si,  0.0 st</div><div class="line">%Cpu67 : 60.9 us, 25.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.6 si,  0.0 st</div><div class="line">%Cpu68 : 59.9 us, 26.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.9 si,  0.0 st</div><div class="line">%Cpu69 : 57.9 us, 27.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.6 si,  0.0 st</div><div class="line">%Cpu70 : 61.3 us, 26.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.6 si,  0.0 st</div><div class="line">%Cpu71 : 64.0 us, 23.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.5 si,  0.0 st</div><div class="line">%Cpu72 : 61.3 us, 26.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.9 si,  0.0 st</div><div class="line">%Cpu73 : 63.0 us, 22.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.2 si,  0.0 st</div><div class="line">%Cpu74 : 61.4 us, 27.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.2 si,  0.0 st</div><div class="line">%Cpu75 : 63.9 us, 26.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  9.6 si,  0.0 st</div><div class="line">%Cpu76 : 61.3 us, 27.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.6 si,  0.0 st</div><div class="line">%Cpu77 : 55.0 us, 30.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.6 si,  0.0 st</div><div class="line">%Cpu78 : 60.9 us, 26.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.3 si,  0.0 st</div><div class="line">%Cpu79 : 58.4 us, 26.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 14.9 si,  0.0 st</div><div class="line">%Cpu80 : 58.7 us, 29.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.2 si,  0.0 st</div><div class="line">%Cpu81 : 62.6 us, 27.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 10.3 si,  0.0 st</div><div class="line">%Cpu82 : 61.9 us, 25.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.6 si,  0.0 st</div><div class="line">%Cpu83 : 58.7 us, 27.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.9 si,  0.0 st</div><div class="line">%Cpu84 : 59.4 us, 27.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.9 si,  0.0 st</div><div class="line">%Cpu85 : 58.9 us, 28.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 12.6 si,  0.0 st</div><div class="line">%Cpu86 : 58.4 us, 28.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 13.2 si,  0.0 st</div><div class="line">%Cpu87 : 61.1 us, 27.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 11.6 si,  0.0 st</div></pre></td></tr></table></figure>
<p>就以上sysbench VS  MySQLD 的CPU 消耗来看，因为sysbench 处理逻辑简单，就是发SQL给MySQLD，所以 sysbench自身US很少，大部分都是调用OS的网络操作，而MySQLD有 60% CPU用于US，也就是自身业务逻辑，MySQLD收到SQL要做SQL解析，要去查找数据，这些都是用户态消耗，找到数据后走网络发给Sysbench，这部分是sy </p>
<p>到这里可以拿着证据去VIP通道(土豪+专业的客户得有VIP通道)找做网络管控的了，不会再有撕逼和甩锅</p>
<h3 id="sysbench-结果不是正态分布"><a href="#sysbench-结果不是正态分布" class="headerlink" title="sysbench 结果不是正态分布"></a>sysbench 结果不是正态分布</h3><p>把所有请求RT 分布进行图形化，此时平均 RT 8.33，理论上是一个正态分布，下图是有限速时：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"> 3.615 |                                         2177</div><div class="line"> 3.681 |**                                       14738</div><div class="line"> 3.748 |*******                                  55690</div><div class="line"> 3.816 |*************                            109713</div><div class="line"> 3.885 |***************                          121830</div><div class="line"> 3.956 |***************                          124851</div><div class="line"> 4.028 |*******************                      154927</div><div class="line"> 4.101 |***********************                  188826</div><div class="line"> 4.176 |***************************              226206</div><div class="line"> 4.252 |************************************     302617</div><div class="line"> 4.329 |**************************************** 333310  //这里以4.329为中心符合正态</div><div class="line"> 4.407 |*******************************          257048</div><div class="line"> 4.487 |********************                     163100</div><div class="line"> 4.569 |************                             101785</div><div class="line"> 4.652 |********                                 63871</div><div class="line"> 4.737 |*****                                    43998</div><div class="line"> 4.823 |*****                                    40854</div><div class="line"> 4.910 |*****                                    42189</div><div class="line"> 4.999 |*****                                    41182</div><div class="line"> 5.090 |****                                     35652</div><div class="line"> 5.183 |****                                     30343</div><div class="line"> 5.277 |***                                      28573</div><div class="line"> 5.373 |***                                      24763</div><div class="line"> 5.470 |***                                      22210</div><div class="line"> 5.570 |***                                      21808</div><div class="line"> 5.671 |***                                      25606</div><div class="line"> 5.774 |***                                      26994</div><div class="line"> 5.879 |***                                      24672</div><div class="line"> 5.986 |***                                      22087</div><div class="line"> 6.095 |**                                       18466</div><div class="line"> 6.205 |**                                       14822</div><div class="line"> 6.318 |**                                       13688</div><div class="line"> 6.433 |**                                       15381</div><div class="line"> 6.550 |**                                       13573</div><div class="line"> 6.669 |*                                        11325</div><div class="line"> 6.790 |*                                        9442</div><div class="line"> 6.913 |*                                        7412</div><div class="line"> 省略一大堆</div><div class="line">20.736 |*                                        11407</div><div class="line">21.112 |*                                        9755</div><div class="line">21.496 |*                                        8957</div><div class="line">21.886 |*                                        9434</div><div class="line">22.284 |*                                        9715</div><div class="line">22.689 |**                                       12774</div><div class="line">23.101 |**                                       17000</div><div class="line">23.521 |***                                      22937</div><div class="line">23.948 |*****                                    40401</div><div class="line">24.384 |********                                 65370</div><div class="line">24.827 |**********                               82186</div><div class="line">25.278 |**********                               85505</div><div class="line">25.737 |***********                              94347 //以25.7附近大概又是一个新正态</div><div class="line">26.205 |**********                               82958</div><div class="line">26.681 |****                                     30760</div><div class="line">27.165 |                                         2222</div><div class="line">27.659 |                                         69</div><div class="line">28.162 |                                         16</div><div class="line">28.673 |                                         15</div><div class="line">29.194 |                                         20</div><div class="line">29.725 |                                         17</div></pre></td></tr></table></figure>
<p>去掉限速后平均 RT 3.26(比下图中大概的中位数2.71大了不少)  完美正态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line">1.857 |**                                       19894</div><div class="line">1.891 |***                                      23569</div><div class="line">1.925 |***                                      27912</div><div class="line">1.960 |****                                     33720</div><div class="line">1.996 |****                                     39892</div><div class="line">2.032 |*****                                    48289</div><div class="line">2.069 |******                                   57649</div><div class="line">2.106 |********                                 69437</div><div class="line">2.145 |*********                                83611</div><div class="line">2.184 |***********                              99507</div><div class="line">2.223 |*************                            119275</div><div class="line">2.264 |****************                         141013</div><div class="line">2.305 |*******************                      165450</div><div class="line">2.347 |**********************                   191778</div><div class="line">2.389 |*************************                219706</div><div class="line">2.433 |****************************             250885</div><div class="line">2.477 |*******************************          278379</div><div class="line">2.522 |**********************************       303931</div><div class="line">2.568 |*************************************    325777</div><div class="line">2.615 |***************************************  342948</div><div class="line">2.662 |**************************************** 354029</div><div class="line">2.710 |**************************************** 356295</div><div class="line">2.760 |**************************************** 353068</div><div class="line">2.810 |**************************************   341345</div><div class="line">2.861 |************************************     324600</div><div class="line">2.913 |**********************************       303525</div><div class="line">2.966 |*******************************          280221</div><div class="line">3.020 |*****************************            255042</div><div class="line">3.075 |**************************               230861</div><div class="line">3.130 |***********************                  206909</div><div class="line">3.187 |*********************                    184616</div><div class="line">3.245 |*******************                      164903</div><div class="line">3.304 |****************                         146199</div><div class="line">3.364 |***************                          131427</div><div class="line">3.425 |*************                            117059</div><div class="line">3.488 |************                             104954</div><div class="line">3.551 |***********                              94404</div><div class="line">3.615 |*********                                83739</div><div class="line">3.681 |********                                 75705</div><div class="line">3.748 |********                                 67944</div><div class="line">3.816 |*******                                  60727</div><div class="line">3.885 |******                                   53757</div><div class="line">3.956 |*****                                    47053</div><div class="line">4.028 |*****                                    42130</div><div class="line">4.101 |****                                     38069</div><div class="line">4.176 |****                                     33666</div><div class="line">4.252 |***                                      30048</div><div class="line">4.329 |***                                      26923</div><div class="line">4.407 |***                                      23886</div><div class="line">4.487 |**                                       21615</div><div class="line">4.569 |**                                       19897</div><div class="line">4.652 |**                                       18458</div><div class="line">4.737 |**                                       17729</div><div class="line">4.823 |**                                       17041</div><div class="line">4.910 |**                                       16011</div><div class="line">4.999 |**                                       16099</div><div class="line">5.090 |**                                       16090</div><div class="line">5.183 |**                                       16393</div><div class="line">5.277 |**                                       16729</div><div class="line">5.373 |**                                       17412</div></pre></td></tr></table></figure>
<h2 id="用其他网络业务验证"><a href="#用其他网络业务验证" class="headerlink" title="用其他网络业务验证"></a>用其他网络业务验证</h2><p>先测试一下网络下载时的ping：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">--无流量</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=11 ttl=64 time=0.075 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=12 ttl=64 time=0.080 ms</div><div class="line">--从有网络限速的机器下载，带宽100MB</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=13 ttl=64 time=0.738 ms </div><div class="line">64 bytes from 172.16.0.205: icmp_seq=14 ttl=64 time=0.873 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=15 ttl=64 time=0.993 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=16 ttl=64 time=0.859 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=17 ttl=64 time=0.892 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=18 ttl=64 time=0.972 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=19 ttl=64 time=1.05 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=20 ttl=64 time=0.973 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=21 ttl=64 time=0.997 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=22 ttl=64 time=0.915 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=23 ttl=64 time=0.892 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=24 ttl=64 time=0.960 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=25 ttl=64 time=1.05 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=26 ttl=64 time=0.089 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=27 ttl=64 time=0.097 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=28 ttl=64 time=0.081 ms </div><div class="line">--从没有网络限速的机器下载，带宽1000MB</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=29 ttl=64 time=0.078 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=30 ttl=64 time=0.077 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=31 ttl=64 time=0.073 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=32 ttl=64 time=0.072 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=33 ttl=64 time=0.079 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=34 ttl=64 time=0.074 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=35 ttl=64 time=0.080 ms</div><div class="line">64 bytes from 172.16.0.205: icmp_seq=36 ttl=64 time=0.077 ms</div></pre></td></tr></table></figure>
<p>有限速方向，尝试了BBR和cubic 拥塞算法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#tcpperf -c 172.16.0.205 -t 100</div><div class="line">Connected mysqld217:51254 -&gt; 172.16.0.205:2009, congestion control: cubic</div><div class="line">Time (s)  Throughput   Bitrate    Cwnd    Rwnd  sndbuf  ssthresh  Retr  CA  Pacing  rtt/var</div><div class="line">  0.000s   0.00kB/s   0.00kbps  14.3Ki  41.3Ki  85.0Ki    2048Mi     0   0  65.2Mi  427us/213</div><div class="line">  1.029s    122MB/s    975Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/8</div><div class="line">  2.005s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/10</div><div class="line">  3.010s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/17</div><div class="line">  4.016s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/13</div><div class="line">  5.022s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/14</div><div class="line">  6.028s    105MB/s    842Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/17</div><div class="line">  7.003s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/15</div><div class="line">  8.009s    105MB/s    843Mbps  1595Ki  1595Ki  9512Ki     576Ki     0   0   123Mi  15.2ms/13</div><div class="line"> #tcpperf -c 172.16.0.205 -t 100</div><div class="line">Connected mysqld217:51932 -&gt; 172.16.0.205:2009, congestion control: bbr</div><div class="line">Time (s)  Throughput   Bitrate    Cwnd    Rwnd  sndbuf  ssthresh  Retr  CA  Pacing  rtt/var</div><div class="line">  0.000s   0.00kB/s   0.00kbps  14.3Ki  41.3Ki   128Ki    2048Mi     0   0  98.0Mi  406us/203</div><div class="line">  1.011s    120MB/s    957Mbps   271Ki  2281Ki  10.4Mi     560Ki  2244   0   108Mi  2427us/11</div><div class="line">  2.033s    104MB/s    831Mbps   271Ki  2281Ki  10.4Mi     560Ki  1056   0   109Mi  2417us/18</div><div class="line">  3.021s    104MB/s    830Mbps   274Ki  2281Ki  10.4Mi     560Ki  1056   0   109Mi  2428us/18</div><div class="line">  4.014s    103MB/s    827Mbps   271Ki  2281Ki  10.4Mi     560Ki  1452   0   108Mi  2423us/19</div><div class="line">  5.031s    104MB/s    835Mbps   274Ki  2281Ki  10.4Mi     560Ki   660   0  80.2Mi  2435us/22</div><div class="line">  6.033s    102MB/s    818Mbps   271Ki  2272Ki  10.4Mi     560Ki  2112   0   109Mi  2426us/17</div><div class="line">  7.030s    103MB/s    823Mbps   274Ki  2281Ki  10.4Mi     560Ki  1716   0   117Mi  2430us/18</div><div class="line">  8.023s    103MB/s    826Mbps   274Ki  2281Ki  10.4Mi     560Ki  1452   0   109Mi  2428us/20</div><div class="line">  9.016s    103MB/s    827Mbps   271Ki  2281Ki  10.4Mi     560Ki  1452   0   108Mi  2423us/15</div></pre></td></tr></table></figure>
<p>跑tcpperf触发限速时的监控(上下两个窗口是同一台机器)，红色是丢包率挺高的，绿色丢包就没了，应该是拥塞算法和限速管控达成了平衡</p>
<p><img src="/images/951413iMgBlog/image-20230511215940306.png" alt="image-20230511215940306"></p>
<p>反过来限速被我去掉了(限速可以进出双向单独控制)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#tcpperf -c mysqld217 -t 1000</div><div class="line">Connected 172.16.0.205:32186 -&gt; mysqld217:2009, congestion control: bbr</div><div class="line">Time (s)  Throughput   Bitrate    Cwnd    Rwnd  sndbuf  ssthresh  Retr  CA  Pacing  rtt/var</div><div class="line">  0.000s   0.00kB/s   0.00kbps  14.3Ki  41.3Ki   128Ki    2048Mi     0   0   100Mi  397us/198</div><div class="line">  1.001s   1107MB/s   8859Mbps   471Ki   985Ki  4641Ki     277Ki     0   0  1083Mi  390us/22</div><div class="line">  2.001s   1103MB/s   8823Mbps   465Ki   985Ki  4641Ki     277Ki     0   0  1089Mi  393us/16</div><div class="line">  3.000s   1111MB/s   8892Mbps   465Ki   985Ki  4641Ki     277Ki     0   0  1072Mi  403us/25</div><div class="line">  4.000s   1099MB/s   8789Mbps   459Ki   985Ki  4794Ki     277Ki     0   0   799Mi  399us/18</div><div class="line">  5.001s   1098MB/s   8786Mbps   459Ki   985Ki  4794Ki     277Ki     0   0  1066Mi  387us/12</div><div class="line">  6.000s   1100MB/s   8799Mbps   462Ki   974Ki  4794Ki     277Ki     0   0  1069Mi  399us/16</div><div class="line">  7.001s   1135MB/s   9078Mbps   453Ki   985Ki  4794Ki     277Ki     0   0  1059Mi  377us/19</div></pre></td></tr></table></figure>
<p>查看限速配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&#123;txcmbps:844.000, txckpps:120.000&#125;</div><div class="line"></div><div class="line">//限速解释</div><div class="line">0-31 我猜这是网卡队列(可以修改);</div><div class="line">txcmbps:844.000 105.5MB/s     每秒带宽105.5MB</div><div class="line">txckpps:120.000 120K packet/s 每秒12万网络包</div></pre></td></tr></table></figure>
<p>sysbench(主键查询-小包) 12万QPS 正好命中 txckpps:120，tcpperf (大包)稳定的105MB带宽命中txcmbps:844</p>
<p>去掉后长这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#ovsctl -n set_out_pps -v -1  //把pps限制为-1==不限制</div><div class="line">#ovsctl set_tx -p &#123;&#125; -r -1;   //带宽不限制</div><div class="line"></div><div class="line">&#123;vport:  2 &#123;map:  0, prio:L, weight:   0&#125;meter: &#123;-&#125;queue: [  0- 31L]&#125;</div></pre></td></tr></table></figure>
<p>对这块网络管控感兴趣可以去了解一下 ovs 这个开源项目(open virtual switch)</p>
<h3 id="去掉网卡限速后的结果"><a href="#去掉网卡限速后的结果" class="headerlink" title="去掉网卡限速后的结果"></a>去掉网卡限速后的结果</h3><p>实际结构如下：</p>
<p><img src="/images/951413iMgBlog/image-20230513132101185.png" alt="image-20230513132101185"></p>
<p>放开所有网络控制后，1000并发压力 30万QPS，RT 3.28，此时从sysbench 以及空闲机器ping MySQLD机器的 RTT和没压力基本一致</p>
<p><img src="/images/951413iMgBlog/image-20230512090205685.png" alt="image-20230512090205685"></p>
<p>top状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">%Node1 : 23.4 us, 12.3 sy,  0.0 ni, 61.4 id,  0.0 wa,  0.0 hi,  3.0 si,  0.0 st</div><div class="line">%Cpu64 : 63.2 us, 36.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu65 : 44.4 us, 21.9 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 33.8 si,  0.0 st</div><div class="line">%Cpu66 : 66.6 us, 33.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu67 : 63.4 us, 36.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu68 : 64.2 us, 35.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu69 : 64.9 us, 35.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu70 : 66.6 us, 33.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu71 : 65.3 us, 34.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu72 : 67.7 us, 32.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu73 : 63.6 us, 36.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu74 : 66.7 us, 33.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu75 : 42.4 us, 19.9 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 37.7 si,  0.0 st</div><div class="line">%Cpu76 : 63.9 us, 36.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu77 : 67.0 us, 33.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu78 : 68.3 us, 31.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu79 : 64.9 us, 35.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu80 : 65.2 us, 34.8 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu81 : 44.4 us, 21.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 34.1 si,  0.0 st</div><div class="line">%Cpu82 : 63.9 us, 36.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu83 : 44.2 us, 23.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 32.3 si,  0.0 st</div><div class="line">%Cpu84 : 65.7 us, 34.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu85 : 68.3 us, 31.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu86 : 67.5 us, 32.5 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu87 : 62.4 us, 37.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">%Cpu88 :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/image-20230512092713141.png" alt="image-20230512092713141"></p>
<p>小思考：</p>
<blockquote>
<p>我们中间尝试走本机127.0.0.1 压测时QPS 是24万，比跨机器压的 30万打了8折，想想为什么？网络延时消耗完全没影响？</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>简单可复制的证明办法：抓包，快速撕逼和分析</p>
<p>肯定有很多人想到：内存、磁盘、线程池、队列、网络等等原因，但是这些所有原因有一个共同的爹：RT，所有这些影响因素最后体现出来就是RT 高了，你CPU资源不够、内存慢最后总表现就是在客户端看来你的 RT 太高。</p>
<p>所以我们去掉这些复杂因素先在MySQLD所在EC2 的网卡上抓一个包看看RT，再对比一下1000/2000并发时抓包看到的 RT 有没有升高，如果有升高说明问题在MySQLD这端(含OS、MySQLD的问题)，如果 RT 不变那么问题不在MySQLD这端，并且从EC2网卡出去都是很快的，那么问题只能是在路上或者客户端的sysbench自己慢了。</p>
<p>这是我们星球里说的无招胜有招–抓包大法，扯皮过程中我还没见过几个不认网络抓包的，也有那么一两个扯上是不是网卡驱动有问题，我的代码不会有问题</p>
<p>两个限速条件：pps 120k(每秒最多12万网络包)，带宽 844mbps=105.5MB/s</p>
<p>Sysbench 查询都是小包，触发第一个条件，tcpperf触发第二个条件</p>
<p>ping ping神功失效了吗？也没有，我后来又测试了100、200并发，rtt 0.2ms和0.4ms，也就是说随着并发的增加rtt 增加到0.8ms后就不再增加了。上来1000并发已经到了天花板</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=159 ttl=64 time=0.226 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=160 ttl=64 time=0.334 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=161 ttl=64 time=0.336 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=162 ttl=64 time=0.213 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=163 ttl=64 time=0.104 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=164 ttl=64 time=0.096 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=165 ttl=64 time=0.101 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=166 ttl=64 time=0.116 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=167 ttl=64 time=0.104 ms--以上 100并发，QPS 119K</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=168 ttl=64 time=0.093 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=169 ttl=64 time=0.088 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=170 ttl=64 time=0.405 ms--以下 200并发，QPS 119K</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=171 ttl=64 time=0.419 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=172 ttl=64 time=0.386 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=173 ttl=64 time=0.474 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=174 ttl=64 time=0.462 ms</div><div class="line">64 bytes from polardbxyt27 (mysqld217): icmp_seq=175 ttl=64 time=0.410 ms</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;实战瓶颈定位-我的MySQL为什么压不上去&quot;&gt;&lt;a href=&quot;#实战瓶颈定位-我的MySQL为什么压不上去&quot; class=&quot;headerlink&quot; title=&quot;实战瓶颈定位-我的MySQL为什么压不上去&quot;&gt;&lt;/a&gt;实战瓶颈定位-我的MySQL为什么压不上去&lt;/
    
    </summary>
    
      <category term="performance" scheme="https://plantegg.github.io/categories/performance/"/>
    
    
      <category term="network" scheme="https://plantegg.github.io/tags/network/"/>
    
      <category term="MySQL" scheme="https://plantegg.github.io/tags/MySQL/"/>
    
      <category term="sysbench" scheme="https://plantegg.github.io/tags/sysbench/"/>
    
  </entry>
  
  <entry>
    <title>Nginx reuseport 导致偶发性卡顿</title>
    <link href="https://plantegg.github.io/2023/06/08/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/"/>
    <id>https://plantegg.github.io/2023/06/08/Nginx reuseport 导致偶发性卡顿/</id>
    <published>2023-06-08T09:30:03.000Z</published>
    <updated>2023-06-20T11:48:01.332Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Nginx-reuseport-导致偶发性卡顿"><a href="#Nginx-reuseport-导致偶发性卡顿" class="headerlink" title="Nginx reuseport 导致偶发性卡顿"></a>Nginx reuseport 导致偶发性卡顿</h1><p>by @橘橘球</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>从2018年开始，我们有个业务陆续接到反馈 Nginx 线上集群经常出现不响应或者偶发性的“超慢”请求。这种卡顿每天都有少量出现。而只有多个集群中的一个出现，其他压力更大的集群皆未出现。<br>业务结构比较简单：LVS-&gt;Nginx-&gt;后端，如图<br><img src="/images/951413iMgBlog/image-20230607103449616.png" alt="image-20230607103449616"></p>
<p>一些观察到的现象：</p>
<ul>
<li>出问题前不久升级 Nginx 配置，打开了 reuseport 功能</li>
<li>在压力大的后端（upstream）服务环境不容易出现，后端压力轻对应的Nginx卡顿概率更高</li>
<li>关闭 reuseport 后 问题少了很多</li>
<li>失败的请求响应时间都是 0ms（Nginx日志不靠谱了）</li>
<li>从 Nginx 日志上看，所有失败的健康检查请求都是0ms 的499 错误码（健康检查设置超时是2秒），但实际出问题的时候有5s-2分钟没有任何日志输出（Nginx卡了这么久）要么是Nginx卡住没去accept，要么是accept了没响应</li>
<li>所有超时来自同一个worker(一个Nginx服务一般按照机器核数开启多个worker)  </li>
</ul>
<p>并且已知，卡顿的原因是打开 reuseport 后，新进来的请求可以由内核 hash 派发给一个 Nginx woker ，避免了锁争抢以及惊群。但如果网络条件足够好，压力足够低，Nginx worker 一直来不及读完 receive buffer 中的内容时，就无法切换并处理其他的 request，于是在新请求的客户端会观测不间断的卡顿，而压力大的后端由于网络传输慢，经常卡顿，Nginx worker 反而有时间能处理别的请求。在调小 receive buffer 人为制造卡顿后该问题得以解决。</p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>由于所述场景比较复杂，缺乏直接证据，打算通过构造一个较简单的环境来复现这个问题，并且在这个过程中抓包、观测Nginx worker的具体行为，验证这个假设。</p>
<h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><h3 id="快连接和慢连接"><a href="#快连接和慢连接" class="headerlink" title="快连接和慢连接"></a>快连接和慢连接</h3><ul>
<li>快连接：通常是传输时间短、传输量小的连接，耗时通常是ms级别</li>
<li>慢连接：通常是传输时间长、传输量大的连接，可以维持传输状态一段时间（如30s, 1min）  </li>
</ul>
<p>在本次场景复现过程中，这两种连接都是短连接，每次请求开始前都需要三次握手建立连接，结束后都需要四次挥手销毁连接</p>
<h3 id="Epoll"><a href="#Epoll" class="headerlink" title="Epoll"></a>Epoll</h3><p>Nginx使用了epoll模型，epoll 是多路复用的一种实现。在多路复用的场景下，一个task（process）会批量处理多个socket，哪个来了数据就去读那个。这就意味着要公平对待所有这些socket，不能阻塞在任何socket的”数据读”上，也就是说不能在阻塞模式下针对任何socket调用recv/recvfrom。  </p>
<p>epoll 每次循环为O(1) 操作，循环前会得到一个就绪队列，其中包含所有已经准备好的 socket stream（有数据可读），不需要循环全部 socket stream 读取数据，在循环后会将被读取数据的 stream 重新放回睡眠队列。睡眠队列中的 socket stream 有数据可读时，再唤醒加入到 就绪队列中。</p>
<p>epoll 伪代码 （不包含唤醒、睡眠）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">while(true) &#123;  </div><div class="line">    streamArr = getEpollReadyStream(); // 找到准备好的stream</div><div class="line">    for(Stream i: streamArr) &#123;         // 循环准备好的stream</div><div class="line">        doSomething();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="reuseport与惊群"><a href="#reuseport与惊群" class="headerlink" title="reuseport与惊群"></a>reuseport与惊群</h3><p>Nginx reuseport 选项解决惊群的问题：在 TCP 多进程/线程场景中（B 图），服务端如果所有新连接只保存在一个 listen socket 的全连接队列中，那么多个进程/线程去这个队列里获取（accept）新的连接，势必会出现多个进程/线程对一个公共资源的争抢，争抢过程中，大量资源的损耗，也就会发生惊群现象。<br><img src="/images/951413iMgBlog/reuseport-explained.jpg" alt="img"><br>而开启reuseport后（C 图)，有多个 listener 共同 bind/listen 相同的 IP/PORT，也就是说每个进程/线程有一个独立的 listener，相当于每个进程/线程独享一个 listener 的全连接队列，新的连接请求由内核hash分配，不需要多个进程/线程竞争某个公共资源，能充分利用多核，减少竞争的资源消耗，效率自然提高了。  </p>
<p>但同时也是由于这个分配机制，避免了上下文切换，在服务压力不大，网络情况足够好的情况下，进程/线程更有可能专注于持续读取某个慢连接数据而忽视快连接建立的请求，从而造成快连接方卡顿。  </p>
<h2 id="复现过程"><a href="#复现过程" class="headerlink" title="复现过程"></a>复现过程</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ol>
<li>整体的架构是N个client-&gt;1个Nginx-&gt;N个server。因为卡顿原因和reuseport机制有关，和server数量无关，server数量设为任意数字都能复现，这里为了方便设成1。client数量设为2，为了将快连接和慢连接区分开便于抓包观测</li>
<li>用慢连接制造卡顿环境，用快连接观测卡顿。在快连接客户端进行观测和抓包</li>
<li>进程数量要足够少，使得同一个 worker 有几率分配到多个连接 <code>worker_processes 2</code></li>
<li>连接数目要足够多，慢连接数目&gt;=进程数量，使得快连接在分配时，有一定概率分配到一个正在处理慢连接的worker上</li>
<li>reuseport: 这个配置要开启，卡顿现象才能观测到。<code>listen 8000 reuseport</code></li>
</ol>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">linux kernal version: 6.1  </div><div class="line">linux image: amazon/al2023-ami-2023.0.20230419.0-kernel-6.1-x86_64  </div><div class="line">instance type:  </div><div class="line">1X AWS t2.micro (1 vCPU, 1GiB RAM) – Nginx client(fast request)  </div><div class="line">3X AWS t3.micro (2 vCPU, 1GiB RAM) – Http server, Nginx server, Nginx client(slow request)</div></pre></td></tr></table></figure>
<h3 id="复现操作"><a href="#复现操作" class="headerlink" title="复现操作"></a>复现操作</h3><ol>
<li><p>在server instance上放置一个 2GiB 大文件（0000000000000000.data）和一个 3MiB 小文件（server.pcap），并开启一个http server</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup python -m http.server 8000</div></pre></td></tr></table></figure>
</li>
<li><p>在Nginx instance上安装、配置好Nginx，并启动Nginx (注意要绑核！)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"># install</div><div class="line">sudo yum install nginx</div><div class="line"># config (/etc/nginx/nginx.conf)</div><div class="line">user nginx;</div><div class="line">worker_processes 2;</div><div class="line">error_log /var/log/nginx/error.log notice;</div><div class="line">pid /run/nginx.pid;</div><div class="line"></div><div class="line">include /usr/share/nginx/modules/*.conf;</div><div class="line"></div><div class="line">events &#123;</div><div class="line">    worker_connections 1024;</div><div class="line">&#125;</div><div class="line"></div><div class="line">http &#123;</div><div class="line">    log_format  main  &apos;$remote_addr [$time_local] &quot;$request&quot; &apos;</div><div class="line">                      &apos;status=$status body_bytes_sent=$body_bytes_sent &apos;</div><div class="line">                      &apos;rt=$request_time uct=&quot;$upstream_connect_time&quot; uht=&quot;$upstream_header_time&quot; urt=&quot;$upstream_response_time&quot;&apos;;</div><div class="line"></div><div class="line">    access_log  /var/log/nginx/access.log  main;</div><div class="line"></div><div class="line">    sendfile            on;</div><div class="line">    tcp_nopush          on;</div><div class="line">    keepalive_timeout   60;</div><div class="line">    types_hash_max_size 4096;</div><div class="line"></div><div class="line">    include             /etc/nginx/mime.types;</div><div class="line">    default_type        application/octet-stream;</div><div class="line"></div><div class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</div><div class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</div><div class="line">    # for more information.</div><div class="line">    include /etc/nginx/conf.d/*.conf;</div><div class="line"></div><div class="line">    server &#123;</div><div class="line">        listen       8000 reuseport;</div><div class="line">        server_name  server1;</div><div class="line">        root         /usr/share/nginx/html;</div><div class="line"></div><div class="line">        # Load configuration files for the default server block.</div><div class="line">        include /etc/nginx/default.d/*.conf;</div><div class="line">        </div><div class="line">        location / &#123;</div><div class="line">        proxy_pass http://172.31.86.252:8000; # server ip</div><div class="line">        proxy_set_header Host $host;</div><div class="line">        proxy_set_header X-Real-IP $remote_addr;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        error_page 404 /404.html;</div><div class="line">        location = /404.html &#123;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        error_page 500 502 503 504 /50x.html;</div><div class="line">        location = /50x.html &#123;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"># start nginx</div><div class="line">sudo taskset -c 0 nginx</div></pre></td></tr></table></figure>
</li>
<li><p>启动慢连接client，开启4个下载进程并计时，测试脚本<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/script/get_big_file.sh" target="_blank" rel="external">在此</a> </p>
</li>
<li>启动快连接client，开启1个下载进程并计时，抓包，测试脚本<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/script/get_small_file.sh" target="_blank" rel="external">在此</a><br>需要注意的是此处使用了curl –max-time 1，意味着即使1s内文件没有下载完，也会自动终止。</li>
<li>进入Nginx instance观察access.log</li>
<li>关掉reuseport或者调小recv buffer大小，重试一次</li>
</ol>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>ip maping:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">172.31.86.252: http server</div><div class="line">172.31.89.152: nginx server</div><div class="line">172.31.91.109: 快连接 client</div><div class="line">172.31.92.10:  慢连接 client</div></pre></td></tr></table></figure></p>
<ol>
<li><p>快连接client端：下载同一个小文件的下载时长有快有慢，方差很大，完整日志<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/client-runtime.txt" target="_blank" rel="external">在此</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[2023-05-31 08:27:32,127] runtime=1010</div><div class="line">[2023-05-31 08:27:33,140] runtime=1009</div><div class="line">[2023-05-31 08:27:34,152] runtime=38</div><div class="line">[2023-05-31 08:27:34,192] runtime=1011</div><div class="line">[2023-05-31 08:27:35,205] runtime=37</div><div class="line">[2023-05-31 08:27:35,245] runtime=1008</div><div class="line">[2023-05-31 08:27:36,256] runtime=57</div><div class="line">[2023-05-31 08:27:36,315] runtime=1011</div></pre></td></tr></table></figure>
</li>
<li><p>快连接client：无论耗时长短，抓包结果都显示存在不同程度卡顿，抓包文件<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/nginx-case-client.pcap" target="_blank" rel="external">在此</a>  耗时长的下载过程<br><img src="/images/951413iMgBlog/benchmark-pkg-cature1.png" alt="img"><br>耗时短的下载过程<br><img src="/images/951413iMgBlog/benchmark-pkg-cature2.png" alt="img"></p>
</li>
<li><p>Nginx access.log 存在大量未下载完的200请求，和少量499请求，且499请求的耗时为0，access.log文件<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/access.log.txt" target="_blank" rel="external">在此</a><br>卡顿的日志建立连接时长（utc）在0.3-0.4ms左右，超过1s的就出现499了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">172.31.91.109 [31/May/2023:08:27:49 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=102195 rt=0.790 uct=&quot;0.413&quot; uht=&quot;0.592&quot; urt=&quot;0.791&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:50 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.058 uct=&quot;0.000&quot; uht=&quot;0.002&quot; urt=&quot;0.053&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:51 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=499 body_bytes_sent=0 rt=0.000 uct=&quot;-&quot; uht=&quot;-&quot; urt=&quot;0.000&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:51 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=102195 rt=0.763 uct=&quot;0.400&quot; uht=&quot;0.580&quot; urt=&quot;0.763&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:52 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=102195 rt=0.767 uct=&quot;0.480&quot; uht=&quot;0.768&quot; urt=&quot;0.768&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:53 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=580007 rt=0.773 uct=&quot;0.330&quot; uht=&quot;0.431&quot; urt=&quot;0.773&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:55 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=499 body_bytes_sent=0 rt=0.000 uct=&quot;-&quot; uht=&quot;-&quot; urt=&quot;0.000&quot;</div><div class="line">172.31.91.109 [31/May/2023:08:27:55 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=499 body_bytes_sent=0 rt=0.000 uct=&quot;-&quot; uht=&quot;-&quot; urt=&quot;0.000&quot;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>下载中途被关闭的连接（200），可以观测到Nginx server在客户端已经请求FIN并被ACK之后仍然在发送一些网络数据包，客户端非常迷惑，向Nginx发送RST<br><img src="/images/951413iMgBlog/benchmark-pkg-cature3.png" alt="img"><br>未和Nginx建立连接就被关闭的连接（499），可以观测到连接始终没有被建立，在等待1s后客户端超时，主动请求关连接<br><img src="/images/951413iMgBlog/benchmark-pkg-cature4.png" alt="img"></p>
<ol>
<li>限制Nginx server所在的instance的recv buffer大小，重新进行实验，可以观测到仍然有少量停顿，但整体耗时好了很多，不再有长达1s的卡顿，也不再有RST，完整日志<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-exp1/" target="_blank" rel="external">在此</a>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sysctl -w net.ipv4.tcp_rmem=&quot;40960 40960 40960&quot;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>client runtime log: 耗时稳定在50-100ms，比无慢连接、纯跑快连接时要大一倍（25-50ms）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[2023-06-05 06:13:22,791] runtime=120</div><div class="line">[2023-06-05 06:13:22,913] runtime=82</div><div class="line">[2023-06-05 06:13:22,997] runtime=54</div><div class="line">[2023-06-05 06:13:23,054] runtime=61</div><div class="line">[2023-06-05 06:13:23,118] runtime=109</div><div class="line">[2023-06-05 06:13:23,229] runtime=58</div><div class="line">[2023-06-05 06:13:23,290] runtime=55</div><div class="line">[2023-06-05 06:13:23,347] runtime=79</div><div class="line">[2023-06-05 06:13:23,429] runtime=65</div><div class="line">[2023-06-05 06:13:23,497] runtime=53</div></pre></td></tr></table></figure></p>
<p>client 抓包结果：<br><img src="/images/951413iMgBlog/exp1-pkg-cature1.png" alt="img"><br>Nginx access.log: 都发完了，而且发得很流畅，建立连接时间（utc)非常短</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">172.31.91.109 [05/Jun/2023:06:13:22 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.101 uct=&quot;0.001&quot; uht=&quot;0.004&quot; urt=&quot;0.101&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:22 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.064 uct=&quot;0.001&quot; uht=&quot;0.002&quot; urt=&quot;0.064&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.044 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.044&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.047 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.047&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.100 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.099&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.047 uct=&quot;0.000&quot; uht=&quot;0.001&quot; urt=&quot;0.047&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.045 uct=&quot;0.001&quot; uht=&quot;0.002&quot; urt=&quot;0.045&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:13:23 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=3602590 rt=0.066 uct=&quot;0.000&quot; uht=&quot;0.002&quot; urt=&quot;0.066&quot;</div></pre></td></tr></table></figure>
<p>对于慢连接大文件下载时长略有影响：46s (无限制) vs 53s (有限制)</p>
<ol>
<li>关闭nginx reuseport</li>
</ol>
<p>卡顿依然大量存在，但大多以连接能够建立但是下载不完的形式（200）出现，499较少，并且存在惊群现象，完整日志<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-exp2/" target="_blank" rel="external">在此</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">server &#123;</div><div class="line">    listen 8000;</div></pre></td></tr></table></figure></p>
<p>client runtime log：存在卡顿，和benchmark没有区别<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[2023-06-05 06:38:06,682] runtime=1008</div><div class="line">[2023-06-05 06:38:07,692] runtime=1008</div><div class="line">[2023-06-05 06:38:08,703] runtime=220</div><div class="line">[2023-06-05 06:38:08,926] runtime=112</div><div class="line">[2023-06-05 06:38:09,040] runtime=60</div><div class="line">[2023-06-05 06:38:09,103] runtime=865</div><div class="line">[2023-06-05 06:38:09,970] runtime=1009</div><div class="line">[2023-06-05 06:38:10,982] runtime=1008</div><div class="line">[2023-06-05 06:38:11,992] runtime=1009</div></pre></td></tr></table></figure></p>
<p>client抓包结果：存在卡顿，存在RST，和benchmark没有区别<br><img src="/images/951413iMgBlog/exp2-pkg-cature1.png" alt="img"><br><img src="/images/951413iMgBlog/exp2-pkg-cature2.png" alt="img"><br>access.log：卡顿的日志连接时间比benchmark略短，在0.2-0.3s左右，出现499的情况少了但是依然会有<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">172.31.91.109 [05/Jun/2023:06:38:02 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.844 uct=&quot;0.362&quot; uht=&quot;0.539&quot; urt=&quot;0.845&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:38:03 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.907 uct=&quot;0.334&quot; uht=&quot;0.476&quot; urt=&quot;0.906&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:38:04 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=543900 rt=0.836 uct=&quot;0.319&quot; uht=&quot;0.504&quot; urt=&quot;0.836&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:38:05 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.831 uct=&quot;0.161&quot; uht=&quot;0.480&quot; urt=&quot;0.830&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:38:06 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=552849 rt=0.820 uct=&quot;0.180&quot; uht=&quot;0.329&quot; urt=&quot;0.819&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:38:07 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=204595 rt=0.800 uct=&quot;0.122&quot; uht=&quot;0.462&quot; urt=&quot;0.800&quot;</div><div class="line">172.31.91.109 [05/Jun/2023:06:38:08 +0000] &quot;GET /server.pcap HTTP/1.1&quot; status=200 body_bytes_sent=543900 rt=0.871 uct=&quot;0.251&quot; uht=&quot;0.380&quot; urt=&quot;0.871&quot;</div></pre></td></tr></table></figure></p>
<p>存在惊群现象，以下是Nginx worker进程的cpu使用率和上下文切换频率对比<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 每5s输出一次统计结果</div><div class="line">pidstat -w -u 5</div></pre></td></tr></table></figure></p>
<p>两者的cpu使用率和上下文切换频率差不多，但关闭reuseport后花在wait上的cpu时间明显增加（1.3-1.6% vs 2.8-2.9%），这就是惊群带来的性能损耗。原始文件：<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-bench/pidstat.txt" target="_blank" rel="external">开启reuseport</a>，<a href="https://github.com/plantegg/programmer_case/blob/main/performance/Nginx%20reuseport%20%E5%AF%BC%E8%87%B4%E5%81%B6%E5%8F%91%E6%80%A7%E5%8D%A1%E9%A1%BF/log-exp2/pidstat.txt" target="_blank" rel="external">关闭reuseport</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># 开启reuseport</div><div class="line">Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command</div><div class="line">Average:      992      2590    1.77    9.57    0.00    1.25   11.35     -  nginx</div><div class="line">Average:      992      2591    1.37    5.75    0.00    1.62    7.12     -  nginx</div><div class="line"></div><div class="line">Average:      UID       PID   cswch/s nvcswch/s  Command</div><div class="line">Average:      992      2590    179.18     49.64  nginx</div><div class="line">Average:      992      2591    342.51      9.87  nginx</div><div class="line"></div><div class="line"># 关闭reuseport</div><div class="line">Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command</div><div class="line">Average:      992      2788    1.02    8.02    0.00    2.80    9.04     -  nginx</div><div class="line">Average:      992      2789    0.92    9.07    0.00    2.97    9.99     -  nginx</div><div class="line"></div><div class="line">Average:      UID       PID   cswch/s nvcswch/s  Command</div><div class="line">Average:      992      2788    159.06     28.68  nginx</div><div class="line">Average:      992      2789    250.26     22.93  nginx</div></pre></td></tr></table></figure></p>
<p>惊群对于慢连接大文件下载时长略有影响：46s (开reuseport) vs 53s (关reuseport)</p>
<ol>
<li>其他的观察  </li>
</ol>
<p>最初复现的场景是所有的instance都是t2.micro，但开2个慢连接进程时比较难复现，开4个进程又太容易触发限流，所以开始考虑用大一些又没那么容易限流的instance型号。考虑到aws是通过间歇掉包来限速的，慢连接进程数量并非越大越好，引发限速后反而会造成网络连接不畅，造成慢连接卡顿，使得快连接卡顿反而不容易观测。最后选择将慢连接全链路改成t3.micro，结果好复现多了.  </p>
<p>可以观察到有一些access.log上499的连接，各种计时也是0，这其实是因为计时也是通过worker进行的，只有进行epoll和上下文切换才会在日志上打入时间信息，worker如果一直不进行切换，那么计时就会失真，就会看到日志上计时也是0的现象。  </p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol>
<li>reuseport是Nginx避免惊群的优秀feature，应该开启</li>
<li>开启reuseport后如果网络情况非常好且后端服务压力不大，且存在大量慢连接时，会造成快连接卡顿，这是Nginx的worker-epoll架构带来的，原因是recv buffer一直读不完，NGINX采用的epoll ET 触发模式在这种情况下一直无法触发暂停导致worker无法响应其它请求</li>
<li>减小recv buffer通过人为制造卡顿，提供了epoll ET切换连接的条件，可以很大程度上缓解这个问题，同时带来的负面效果是有一定性能损耗。但卡顿无法根除，只能控制在可接受范围内</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://wenfh2020.com/2021/09/29/nginx-thundering-herd/" target="_blank" rel="external">Nginx 惊群 – wenfh2020</a></li>
<li><a href="https://wenfh2020.com/2021/10/12/thundering-herd-tcp-reuseport/" target="_blank" rel="external">Nginx reuseport – wenfh2020</a></li>
<li><a href="https://wenfh2020.com/2021/11/21/question-nginx-epoll-et/" target="_blank" rel="external">Epoll – wenfh2020</a></li>
<li><a href="https://www.cnblogs.com/my_captain/p/12667016.html" target="_blank" rel="external">上下文切换的案例以及CPU使用率 – cnhkzyy</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Nginx-reuseport-导致偶发性卡顿&quot;&gt;&lt;a href=&quot;#Nginx-reuseport-导致偶发性卡顿&quot; class=&quot;headerlink&quot; title=&quot;Nginx reuseport 导致偶发性卡顿&quot;&gt;&lt;/a&gt;Nginx reuseport 导
    
    </summary>
    
      <category term="performance" scheme="https://plantegg.github.io/categories/performance/"/>
    
    
      <category term="Linux" scheme="https://plantegg.github.io/tags/Linux/"/>
    
      <category term="nginx" scheme="https://plantegg.github.io/tags/nginx/"/>
    
      <category term="buffer" scheme="https://plantegg.github.io/tags/buffer/"/>
    
  </entry>
  
  <entry>
    <title>MySQL线程池卡顿重现</title>
    <link href="https://plantegg.github.io/2023/05/26/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8D%A1%E9%A1%BF%E9%87%8D%E7%8E%B0/"/>
    <id>https://plantegg.github.io/2023/05/26/MySQL线程池卡顿重现/</id>
    <published>2023-05-26T09:30:03.000Z</published>
    <updated>2023-06-20T11:48:06.114Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL线程池卡顿重现"><a href="#MySQL线程池卡顿重现" class="headerlink" title="MySQL线程池卡顿重现"></a>MySQL线程池卡顿重现</h1><p>by @wych42 </p>
<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>为了激励大家多动手少空想，我在推特发起了白嫖我的<a href="http://t.zsxq.com/0cz93XUPj" target="_blank" rel="external">知识星球活动</a>：</p>
<blockquote>
<p>白嫖我星球的机会来了，总有人说贵、没有优惠券，这次直接来一个完全100%免费的机会，要求： 在MySQL的基础上重现某个线程池卡的现象，给出可复制的重现过程。就是因为某个线程池满了导致落到这个池里的查询一定都慢，否则都快。 不愿意出钱就动手吧</p>
</blockquote>
<p>参考现象：<a href="https://plantegg.github.io/2020/11/17/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E6%97%B6%E5%8D%A1%E9%A1%BF%E6%8E%92%E6%9F%A5/">https://plantegg.github.io/2020/11/17/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E6%97%B6%E5%8D%A1%E9%A1%BF%E6%8E%92%E6%9F%A5/</a></p>
<hr>
<p>感谢推友<a href="https://twitter.com/wych42" target="_blank" rel="external">王鱼翅</a>同学，以下是他的教科书级的细致重现，你复制粘贴就能和他一样重现了</p>
<h2 id="这个案例的重要性"><a href="#这个案例的重要性" class="headerlink" title="这个案例的重要性"></a>这个案例的重要性</h2><p>这个现象对应我们年度四大案例之一，如下图左下角</p>
<p><img src="/images/951413iMgBlog/image-20230517082106489.png" alt="image-20230517082106489"></p>
<p>重现后请思考：</p>
<ol>
<li>MySQL为什么要将多个线程分成小池子，小池子肯定容易局部资源不足</li>
<li>Nginx 一个连接固定在一个worker上，那么同样多个Worker也会有不均衡(有的worker很闲，有的很卡)</li>
<li>动手实验一下将多个小池子改成一个大线程池会怎么样</li>
<li>Java ConcurrentHashMap为什么能够高性能</li>
</ol>
<p>由 @wych42 重现 </p>
<h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>根据 <a href="https://www.brendangregg.com/usemethod.html" target="_blank" rel="external">USE</a> 分析套路。看到服务端执行快，但是整体RT慢的现象，大概率是中间哪个位置有排队。根据文章里的描述，原因是在thread pool group中出现了排队。</p>
<p>排队的主要原因是服务端拒绝创建新的thread（worker），导致新进来的SQL需要等待前面的执行完成。那么就需要重点分析thread(worker)的创建过程和约束条件。根据文章和文档的说明，重点在thread_pool_size, thread_pool_oversubscribe, thread_pool_max_threads, thread_pool_stall_limit这几个参数上。</p>
<p>跟据文档分析和实际执行结果，这几个参数在MySQL不同的发型版中的行为逻辑是不尽相同的。核心差异在对创建新worker的限制条件上，后面复现也会根据两个发型版的特点分别执行。</p>
<h2 id="mariadb"><a href="#mariadb" class="headerlink" title="mariadb"></a>mariadb</h2><p><a href="https://mariadb.com/kb/en/thread-groups-in-the-unix-implementation-of-the-thread-pool/" target="_blank" rel="external">文档</a></p>
<ul>
<li>通常情况下，新worker由listener worker创建</li>
<li>当timer worker检测到thread group 有stall时，可能会选择创建一个新的worker</li>
<li>worker的数量上限由thread_pool_max_threads限制</li>
<li>thread_pool_oversubscribe约束的是被额外创建出来的worker，在执行完任务后，最多能保留active状态的数量<blockquote>
<p>To clarify, the thread_pool_oversubscribe system variable does not play any part in the creation of new worker threads. The thread_pool_oversubscribe system variable is only used to determine how many worker threads should remain active in a thread group, once a thread group is already oversubscribed due to stalls.</p>
</blockquote>
</li>
</ul>
<h2 id="percona"><a href="#percona" class="headerlink" title="percona"></a>percona</h2><p><a href="https://docs.percona.com/percona-server/8.0/performance/threadpool.html" target="_blank" rel="external">文档</a></p>
<p>percona的行为更符合原文章里的说明：</p>
<ul>
<li>如果线程执行超过时间 thread_pool_stall_limit 的值，会被任务stalled，会创建一个新的线程执行排队的任务</li>
<li>thread_pool_oversubscribe 约束了每个thread group的线程数上限。</li>
</ul>
<h2 id="尝试复现"><a href="#尝试复现" class="headerlink" title="尝试复现"></a>尝试复现</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>并发向DB发起请求，观察客户端耗时，这些请求应当符合这些条件：</p>
<ul>
<li>可控的并发数量：以对比数据库服务端不同参数值的情况</li>
<li>有稳定的、相同的服务端执行耗时：以对比客户端在不同场景下的耗时</li>
<li>对服务端的硬件压力较小：避免因为并发不同时，因IO、CPU资源占用，影响服务端执行耗时</li>
</ul>
<p>综合考虑使用 <code>select sleep(2);</code>作为测试SQL。并发控制使用下面的golang代码实现。</p>
<p>再控制数据库服务端参数，运行同一个并发程序进行对比，mariadb和percona分析执行运行过程：</p>
<h2 id="复现执行"><a href="#复现执行" class="headerlink" title="复现执行"></a>复现执行</h2><h3 id="mariadb-1"><a href="#mariadb-1" class="headerlink" title="mariadb"></a>mariadb</h3><p>由上面分析可以，mariadb 中造成排队的约束是thread_pool_max_threads。</p>
<h4 id="执行方案"><a href="#执行方案" class="headerlink" title="执行方案"></a>执行方案</h4><ul>
<li><p>DB配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">| thread_pool_max_threads                 | 6               |</div><div class="line">| thread_pool_oversubscribe               | 1               |</div><div class="line">| thread_pool_size                        | 1               |</div><div class="line">| thread_pool_stall_limit                 | 500             |</div></pre></td></tr></table></figure>
</li>
<li><p>执行SQL <code>select sleep(2)</code></p>
</li>
<li>执行并发：8</li>
</ul>
<p>预期结果： 6个SQL执行的客户端观察耗时为2s；2个SQL为4s</p>
<p>若调整 thread_pool_max_threads=8，则8个SQL的执行客户端观察耗时都为2s</p>
<h4 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h4><ol>
<li><p>thread_pool_max_threads=6;concurrency=8</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">go run ./main.go</div><div class="line">2023/05/16 13:34:51 starting taskId:task_3</div><div class="line">2023/05/16 13:34:51 starting taskId:task_1</div><div class="line">2023/05/16 13:34:51 starting taskId:task_6</div><div class="line">2023/05/16 13:34:51 starting taskId:task_4</div><div class="line">2023/05/16 13:34:51 starting taskId:task_0</div><div class="line">2023/05/16 13:34:51 starting taskId:task_7</div><div class="line">2023/05/16 13:34:51 starting taskId:task_2</div><div class="line">2023/05/16 13:34:51 starting taskId:task_5</div><div class="line">2023/05/16 13:34:53 taskId:task_0 exec cost : 2.021305666s</div><div class="line">2023/05/16 13:34:53 taskId:task_6 exec cost : 2.021421041s</div><div class="line">2023/05/16 13:34:53 taskId:task_3 exec cost : 2.021258917s</div><div class="line">2023/05/16 13:34:53 taskId:task_2 exec cost : 2.021275458s</div><div class="line">2023/05/16 13:34:53 taskId:task_4 exec cost : 2.021254083s</div><div class="line">2023/05/16 13:34:53 taskId:task_7 exec cost : 2.02146725s</div><div class="line">2023/05/16 13:34:55 taskId:task_5 exec cost : 4.021478584s</div><div class="line">2023/05/16 13:34:55 taskId:task_1 exec cost : 4.02192s</div></pre></td></tr></table></figure>
</li>
<li><p>thread_pool_max_threads=8;concurrency=8</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">go run ./main.go</div><div class="line">2023/05/16 13:36:17 starting taskId:task_7</div><div class="line">2023/05/16 13:36:17 starting taskId:task_3</div><div class="line">2023/05/16 13:36:17 starting taskId:task_1</div><div class="line">2023/05/16 13:36:17 starting taskId:task_5</div><div class="line">2023/05/16 13:36:17 starting taskId:task_0</div><div class="line">2023/05/16 13:36:17 starting taskId:task_6</div><div class="line">2023/05/16 13:36:17 starting taskId:task_4</div><div class="line">2023/05/16 13:36:17 starting taskId:task_2</div><div class="line">2023/05/16 13:36:19 taskId:task_6 exec cost : 2.045480167s</div><div class="line">2023/05/16 13:36:19 taskId:task_2 exec cost : 2.045405667s</div><div class="line">2023/05/16 13:36:19 taskId:task_7 exec cost : 2.045507334s</div><div class="line">2023/05/16 13:36:19 taskId:task_1 exec cost : 2.04553075s</div><div class="line">2023/05/16 13:36:19 taskId:task_3 exec cost : 2.04554975s</div><div class="line">2023/05/16 13:36:19 taskId:task_0 exec cost : 2.045697375s</div><div class="line">2023/05/16 13:36:19 taskId:task_4 exec cost : 2.046417375s</div><div class="line">2023/05/16 13:36:19 taskId:task_5 exec cost : 2.046453792s</div></pre></td></tr></table></figure>
</li>
</ol>
<p>均符合预期。</p>
<h3 id="percona-1"><a href="#percona-1" class="headerlink" title="percona"></a>percona</h3><p>由上面分析可以，percona中造成排队的约束是thread_pool_oversubscribe。</p>
<h4 id="执行方案-1"><a href="#执行方案-1" class="headerlink" title="执行方案"></a>执行方案</h4><ul>
<li><p>DB配置: thread_pool_max_threads设置一个较大的值，以排除影响。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">| thread_pool_max_threads                 | 1000               |</div><div class="line">| thread_pool_oversubscribe               | 1               |</div><div class="line">| thread_pool_size                        | 1               |</div><div class="line">| thread_pool_stall_limit                 | 500             |</div></pre></td></tr></table></figure>
</li>
<li><p>执行SQL <code>select sleep(2)</code></p>
</li>
<li>执行并发：8</li>
</ul>
<p>预期结果： 客户端观察到的耗时分四个批次输出，每个批次2个SQL，耗时分别为2s,4s,6s,8s.</p>
<p>若调整 thread_pool_oversubscribe=2，则三个批次输出，分别为3条SQL耗时均为2s，3条SQL耗时均为4s，2条SQL耗时均为6s</p>
<h4 id="执行结果-1"><a href="#执行结果-1" class="headerlink" title="执行结果"></a>执行结果</h4><ol>
<li><p>thread_pool_oversubscribe=1,concurrency=8</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">go run ./main.go</div><div class="line">2023/05/16 13:39:35 starting taskId:task_2</div><div class="line">2023/05/16 13:39:35 starting taskId:task_4</div><div class="line">2023/05/16 13:39:35 starting taskId:task_3</div><div class="line">2023/05/16 13:39:35 starting taskId:task_5</div><div class="line">2023/05/16 13:39:35 starting taskId:task_6</div><div class="line">2023/05/16 13:39:35 starting taskId:task_0</div><div class="line">2023/05/16 13:39:35 starting taskId:task_1</div><div class="line">2023/05/16 13:39:35 starting taskId:task_7</div><div class="line">2023/05/16 13:39:37 taskId:task_7 exec cost : 2.063547416s</div><div class="line">2023/05/16 13:39:37 taskId:task_0 exec cost : 2.064091541s</div><div class="line">2023/05/16 13:39:39 taskId:task_5 exec cost : 4.06672125s</div><div class="line">2023/05/16 13:39:39 taskId:task_6 exec cost : 4.066822583s</div><div class="line">2023/05/16 13:39:41 taskId:task_3 exec cost : 6.067720292s</div><div class="line">2023/05/16 13:39:41 taskId:task_2 exec cost : 6.069995s</div><div class="line">2023/05/16 13:39:43 taskId:task_4 exec cost : 8.069296042s</div><div class="line">2023/05/16 13:39:43 taskId:task_1 exec cost : 8.071391709s</div></pre></td></tr></table></figure>
</li>
<li><p>thread_pool_oversubscribe=2,concurrency=8 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">go run ./main.go</div><div class="line">2023/05/16 13:41:02 starting taskId:task_7</div><div class="line">2023/05/16 13:41:02 starting taskId:task_1</div><div class="line">2023/05/16 13:41:02 starting taskId:task_3</div><div class="line">2023/05/16 13:41:02 starting taskId:task_2</div><div class="line">2023/05/16 13:41:02 starting taskId:task_5</div><div class="line">2023/05/16 13:41:02 starting taskId:task_6</div><div class="line">2023/05/16 13:41:02 starting taskId:task_4</div><div class="line">2023/05/16 13:41:02 starting taskId:task_0</div><div class="line">2023/05/16 13:41:04 taskId:task_1 exec cost : 2.057093667s</div><div class="line">2023/05/16 13:41:04 taskId:task_3 exec cost : 2.057156334s</div><div class="line">2023/05/16 13:41:04 taskId:task_5 exec cost : 2.057170667s</div><div class="line">2023/05/16 13:41:06 taskId:task_6 exec cost : 4.066917041s</div><div class="line">2023/05/16 13:41:06 taskId:task_7 exec cost : 4.066944125s</div><div class="line">2023/05/16 13:41:06 taskId:task_2 exec cost : 4.066976875s</div><div class="line">2023/05/16 13:41:08 taskId:task_4 exec cost : 6.070653125s</div><div class="line">2023/05/16 13:41:08 taskId:task_0 exec cost : 6.070612083s</div></pre></td></tr></table></figure>
</li>
</ol>
<p>均符合预期。</p>
<h3 id="real-world-模拟（percona）版本"><a href="#real-world-模拟（percona）版本" class="headerlink" title="real-world 模拟（percona）版本"></a>real-world 模拟（percona）版本</h3><p>现实场景中，很少会有大批量的2s在SQL在生产环境执行（限互联网业务)，上述的分析过程能否在真实场景中验证呢？尝试用一个执行200ms的SQL来模拟下：</p>
<ul>
<li><p>DB配置: thread_pool_max_threads设置一个较大的值，以排除影响。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">| thread_pool_max_threads                 | 1000               |</div><div class="line">| thread_pool_oversubscribe               | 1               |</div><div class="line">| thread_pool_size                        | 1               |</div><div class="line">| thread_pool_stall_limit                 | 500             |</div></pre></td></tr></table></figure>
</li>
<li><p>执行SQL <code>select sleep(0.2)</code></p>
</li>
<li>执行并发：10</li>
</ul>
<p>从执行结果中可以看到，只有第一条SQL按照预期的时间执行完成了。<br>从抓包结果中可以看到，所有SQL几乎是同时发出。观察最慢的一条SQL,但是从客户端发包到服务端响应包发出的耗时，与客户端观察到的耗时也能对应上。</p>
<p>可以验证上述分析过程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">2023/05/16 14:47:47 taskId:task_1 exec cost : 239.34925ms</div><div class="line">2023/05/16 14:47:47 taskId:task_9 exec cost : 239.560833ms</div><div class="line">2023/05/16 14:47:47 taskId:task_5 exec cost : 453.795084ms</div><div class="line">2023/05/16 14:47:47 taskId:task_3 exec cost : 458.0005ms</div><div class="line">2023/05/16 14:47:47 taskId:task_6 exec cost : 659.441541ms</div><div class="line">2023/05/16 14:47:47 taskId:task_8 exec cost : 659.660917ms</div><div class="line">2023/05/16 14:47:47 taskId:task_0 exec cost : 862.526375ms</div><div class="line">2023/05/16 14:47:47 taskId:task_7 exec cost : 864.450042ms</div><div class="line">2023/05/16 14:47:48 taskId:task_2 exec cost : 1.063766875s</div><div class="line">2023/05/16 14:47:48 taskId:task_4 exec cost : 1.066266041s</div></pre></td></tr></table></figure>
<p><img src="/images/951413iMgBlog/238557399-c92e2c4e-436f-4f89-ba87-48c49b5393ac.png" alt="send_sql"></p>
<p><img src="/images/951413iMgBlog/238557635-1209f057-0c3c-4cfd-9072-12bfc112b4c6.png" alt="response_delay"></p>
<h3 id="复现文章中部分线程池卡的现象"><a href="#复现文章中部分线程池卡的现象" class="headerlink" title="复现文章中部分线程池卡的现象"></a>复现文章中部分线程池卡的现象</h3><p>配置两个线程池，在其中一个线程池上,通过<code>select sleep()</code>较长时间模拟线程池被慢SQL或者大量任务堵塞的情况，具体配置方案如下：</p>
<ul>
<li>thread_pool_size=2: 保留两个线程池，验证一个卡顿，一个不卡</li>
<li>thread_pool_oversubscribe=1: 允许多创建一个线程，每个线程池中可以同时运行1+1=2个线程</li>
<li>thread_pool_max_threads=2: 每个线程池的线程数量上限，为thread_pool_oversubscribe的配置约束加一个硬限制，每个线程池中最多允许运行2个线程</li>
</ul>
<p>操作步骤如下:</p>
<ul>
<li>通过mysql client在终端发起链接，通过 <code>show processlist</code>语句获取到链接Id, 该链接会分配到 id%2 的线程池中。</li>
<li>用偶数id的链接验证卡顿线程池，用奇数id的链接验证不卡的线程池，链接情况如下:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">  show processlist;</div><div class="line">+-----+-----------------+----------------+------+---------+-------+------------------------+------------------+----------+-----------+---------------+</div><div class="line">| Id  | User            | Host           | db   | Command | Time  | State                  | Info             | Time_ms  | Rows_sent | Rows_examined |</div><div class="line">+-----+-----------------+----------------+------+---------+-------+------------------------+------------------+----------+-----------+---------------+</div><div class="line">|   5 | event_scheduler | localhost      | NULL | Daemon  | 23664 | Waiting on empty queue | NULL             | 23663650 |         0 |             0 |</div><div class="line">| 404 | root            | _gateway:51310 | NULL | Sleep   |  7256 |                        | NULL             |  7256057 |         1 |             1 |</div><div class="line">| 405 | root            | _gateway:48860 | NULL | Sleep   |  7295 |                        | NULL             |  7295342 |         1 |             1 |</div><div class="line">| 406 | root            | _gateway:41144 | NULL | Sleep   |  7254 |                        | NULL             |  7254236 |         1 |             1 |</div><div class="line">| 410 | root            | _gateway:46794 | NULL | Sleep   |  7196 |                        | NULL             |  7196042 |         1 |             1 |</div><div class="line">+-----+-----------------+----------------+------+---------+-------+------------------------+------------------+----------+-----------+---------------+</div></pre></td></tr></table></figure>
<ul>
<li>在 id=404, id=406的链接上，执行 <code>select sleep(30)</code>，再到 id=410 的链接上执行 <code>select 1</code>，预计 <code>select &#39;slow&#39;</code>会直接卡顿约30s再执行完成。</li>
<li>同时，在id=405的链接上，反复执行 <code>select &#39;fast&#39;</code>,都可以很快执行完成。</li>
</ul>
<p>执行结果:</p>
<ul>
<li>id=410 上的语句执行约25s返回结果（终端操作手速影响导致了5s误差）,语句执行时数据库实例输出报错日志，提示线程不足:<blockquote>
<p>2023-05-16T11:27:09.997916Z 406 [ERROR] [MY-000000] [Server] Threadpool could not create additional thread to handle queries, because the number of allowed threads was reached. Increasing ‘thread_pool_max_threads’ parameter can help in this situation.  If ‘admin_port’ parameter is set, you can still connect to the database with superuser account (it must be TCP connection using admin_port as TCP port) and troubleshoot the situation. A likely cause of pool blocks are clients that lock resources for long time. ‘show processlist’ or ‘show engine innodb status’ can give additional hints.</p>
</blockquote>
</li>
<li>id=405链接上的执行都行快。可参考下面抓包截图。</li>
</ul>
<p>抓包结果:</p>
<p>id=410 上的阻塞SQL,可以看到:</p>
<ol>
<li>三条语句在3s内接连发出,但是由于线程池阻塞， <code>select &#39;slow&#39;</code>原本应该很快返回结果，被卡住</li>
<li>在30s时，第一个<code>select sleep(30)</code>语句执行完成，空出的线程立刻执行了 <code>select &#39;slow&#39;</code>并返回结果<br><img src="/images/951413iMgBlog/238638548-c4161d72-b94c-43ef-b698-3acc1002eb43.png" alt="slow query"></li>
</ol>
<p>id=405链接上的执行结果可以看到，每条语句执行都很快。<br><img src="/images/951413iMgBlog/238637635-323fca3b-edf1-4ae7-8d68-d9db9811c692.png" alt="fast query"></p>
<h1 id="参数合理值-已知参数的容量评估"><a href="#参数合理值-已知参数的容量评估" class="headerlink" title="参数合理值/已知参数的容量评估"></a>参数合理值/已知参数的容量评估</h1><p>percona 的默认配置中，thread_pool_size=核心数，thread_pool_oversubscribe=3.假设在一台 16core 的服务器上运行percona，默认配置下最多可以有 16*(1+3)=64个worker同时接受请求。也就是最大可并行处理的SQL数量为 64 个。</p>
<p>假设同时有65个执行耗时为10ms的SQL到达服务端，理论上，会有一个进入排队。排查网络、解析等阶段，在客户端观察到的64个SQL执行耗时10ms，1个SQL执行耗时约20ms。这也会导致耗时监控中出现毛刺、耗时分布不符合正态分布。</p>
<p>反之，根据硬件配置、查询的量、耗时等特点，也可以推算合理的参数值。</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="过程回顾"><a href="#过程回顾" class="headerlink" title="过程回顾"></a>过程回顾</h2><h3 id="阶段一-确定原因"><a href="#阶段一-确定原因" class="headerlink" title="阶段一 确定原因"></a>阶段一 确定原因</h3><p>看到文章时，基本确认问题根源在执行线程(worker)不够，导致排队，出于以下几点分析:</p>
<ul>
<li>开头提到的 <a href="https://www.brendangregg.com/usemethod.html" target="_blank" rel="external">USE</a> 分析套路，结合排查过类似问题(非SQL)的经验</li>
<li>看到文章作者调大thread_pool_oversubscribe便解决问题, 结合文章中对该参数作用的文档引用，基本可以确定</li>
</ul>
<h3 id="阶段二-走上弯路"><a href="#阶段二-走上弯路" class="headerlink" title="阶段二 走上弯路"></a>阶段二 走上弯路</h3><p>尝试复现时，要先启动一个DB实例，便查询文档该参数如何在配置文件中配置，查了MySQL的文档，似乎只在enterprise版本中才有该配置项，便转头去看mariadb的配置说明(这一步给走弯路埋下了伏笔)。</p>
<p>用docker在本地启动了mariadb实例(thread_pool_size=2 thread_pool_oversubscribe=1)</p>
<p>先尝试用 <code>select sleep(30)</code> 模拟阻塞，用 sysbench 模拟正常流量，结果失败：</p>
<ol>
<li>正常流量中有慢的，但是整体还符合正态分布，没有出现都卡的情况。</li>
<li>加大了  <code>select sleep(30)</code> 查询的并发量，现象同上。</li>
</ol>
<p>又翻阅了一些文档，看到DB在调度时，对不同类型的SQL调度优先级会有所区别，类似sleep这种啥也不干的SQL，会不会被降低调度优先级，才导致了没有复现呢？(走上了弯路)</p>
<p>尝试人工制造慢查询:</p>
<ol>
<li>用 sysbench 制造百万量级的表</li>
<li>执行 offset limit 的排序查询，并且不走索引</li>
</ol>
<p>复现结果仍不满意：</p>
<ol>
<li>整体耗时上升了，出现几笔长尾的耗时特别长的请求</li>
<li>但是整体仍然符合正态分布</li>
</ol>
<p>此时分析了下，整体耗时上升是人工制造的慢查询，占用了过多IO和CPU资源，影响了sysbench SQL执行的效率。</p>
<h3 id="阶段三-柳岸花明"><a href="#阶段三-柳岸花明" class="headerlink" title="阶段三 柳岸花明"></a>阶段三 柳岸花明</h3><p>回头又仔细看了下 mariadb关于线程池的<a href="https://mariadb.com/kb/en/thread-groups-in-the-unix-implementation-of-the-thread-pool/" target="_blank" rel="external">文档</a>，注意到文档中提到 thread_pool_oversubscribe 不决定同时有多少线程池被创建出来并执行任务，这个行为逻辑与文章中作者引用的并不相同。<br>又去查看了另一个MySQL发行版 percona 的文档，对该配置的行为描述与文章中的相符，基本就确定前面复现失败的原因了。</p>
<p>确定了前面提到的复现思路：用有稳定服务端执行耗时、并且不消耗大量硬件资源的SQL,用可控的并发进行模拟流量，到具体执行时：</p>
<ul>
<li>SQL就用 <code>select sleep(N)</code></li>
<li>可控的并发就用 golang写个小脚本(事后看直接在终端手动操作也是可以的,不过写个脚本也不费事就是了)</li>
</ul>
<h2 id="mariadb-启动命令和配置"><a href="#mariadb-启动命令和配置" class="headerlink" title="mariadb 启动命令和配置"></a>mariadb 启动命令和配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">mkdir mariadb</div><div class="line">cat &gt; mariadb/my.cnf &lt;&lt; EOF</div><div class="line">[mariadb]</div><div class="line">#thread pool</div><div class="line">thread_handling=pool-of-threads</div><div class="line">thread_pool_oversubscribe=1</div><div class="line">thread_pool_size=1</div><div class="line">thread_pool_max_threads=6</div><div class="line">EOF</div><div class="line"></div><div class="line">docker run --name mariadb -v ./mariadb:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=password -p3306:3306 mariadb:10.3</div></pre></td></tr></table></figure>
<h2 id="percona-启动命令和配置"><a href="#percona-启动命令和配置" class="headerlink" title="percona 启动命令和配置"></a>percona 启动命令和配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">mkdir percona</div><div class="line">cat &gt; percona/my.cnf &lt;&lt; EOF</div><div class="line">[mysqld]</div><div class="line">#thread pool</div><div class="line">thread_handling=pool-of-threads</div><div class="line">thread_pool_oversubscribe=1</div><div class="line">thread_pool_size=1</div><div class="line">thread_pool_max_threads=1000</div><div class="line">default_authentication_plugin=mysql_native_password</div><div class="line">EOF</div><div class="line">docker run --name percona -v ./percona:/etc/my.cnf.d -e MYSQL_ROOT_PASSWORD=123 -p33060:3306 percona:ps-8</div></pre></td></tr></table></figure>
<p>注：Mac M1启动percona时，需要在 docker run 后面添加 <code>--platform linux/x86_64</code> 参数。(percona 未提供arm架构的image)</p>
<h2 id="其他人的重现和分析"><a href="#其他人的重现和分析" class="headerlink" title="其他人的重现和分析"></a>其他人的重现和分析</h2><p><a href="https://lotabout.me/2023/Verification-of-Percona-Thread-Pool-Behavior/" target="_blank" rel="external">https://lotabout.me/2023/Verification-of-Percona-Thread-Pool-Behavior/</a>  从源代码debug上来分析</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MySQL线程池卡顿重现&quot;&gt;&lt;a href=&quot;#MySQL线程池卡顿重现&quot; class=&quot;headerlink&quot; title=&quot;MySQL线程池卡顿重现&quot;&gt;&lt;/a&gt;MySQL线程池卡顿重现&lt;/h1&gt;&lt;p&gt;by @wych42 &lt;/p&gt;
&lt;h2 id=&quot;起因&quot;&gt;&lt;a
    
    </summary>
    
      <category term="MySQL" scheme="https://plantegg.github.io/categories/MySQL/"/>
    
    
      <category term="thread pool" scheme="https://plantegg.github.io/tags/thread-pool/"/>
    
  </entry>
  
  <entry>
    <title>程序员案例星球介绍</title>
    <link href="https://plantegg.github.io/2023/05/10/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%A1%88%E4%BE%8B%E6%98%9F%E7%90%83%E4%BB%8B%E7%BB%8D/"/>
    <id>https://plantegg.github.io/2023/05/10/程序员案例星球介绍/</id>
    <published>2023-05-10T09:30:03.000Z</published>
    <updated>2023-06-07T01:21:13.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="程序员案例星球介绍"><a href="#程序员案例星球介绍" class="headerlink" title="程序员案例星球介绍"></a>程序员案例星球介绍</h1><h2 id="【星球宗旨】"><a href="#【星球宗旨】" class="headerlink" title="【星球宗旨】"></a>【星球宗旨】</h2><p>平时一学就懂，但是实践总是不会，这是因为学习时<strong>缺少实践案例</strong>、场景导致学起来没有体感。我们总是习惯通过课程、教科书想要一次系统性地掌握很多东西，但最终什么都没掌握好。所以星球想通过案例打透一个或几个知识点，让你通过这几个知识点再去生长发芽形成体系</p>
<p><img src="/images/951413iMgBlog/image-20230510191422496.png" alt="image-20230510191422496"></p>
<p>以上四个案例中的三个都给出了完整的重现环境、配置、重现步骤、抓包分析、日志结果、现场截图等等资料，保证100%重现问题并带你进行分析，让你感受实际工作一样的场景，真正做到学透一个案例顶3年工作经验</p>
<p><img src="/images/951413iMgBlog/image-20230607085652520.png" alt="image-20230607085652520"></p>
<h2 id="【关于案例】"><a href="#【关于案例】" class="headerlink" title="【关于案例】"></a>【关于案例】</h2><p>本星球剖析各种程序员疑难经典案例，搞清楚一个案例基本能横扫一个领域，其次在一个案例后再带3/5个相关小案例可以帮你丰富场景，多角度理解。用做会来解决学不会的问题。 案例典型普适性强，代表基础组件基本原理等知识。分析手段尽量通用，分析过程一定要逻辑合理每个疑问都能回答清晰。 最终实现在新领域用旧知识旧工具解决疑难问题，无招胜有招</p>
<p><img src="/images/951413iMgBlog/image-20230510191512744.png" alt="image-20230510191512744"></p>
<h2 id="【关于星主】"><a href="#【关于星主】" class="headerlink" title="【关于星主】"></a>【关于星主】</h2><p>星主20多年的编程实践经历，疑难问题无数，擅长网络，性能，复杂系统的疑难问题分析，BAT背景，目前还在一线撕逼，作者的故事： <a href="https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/">https://plantegg.github.io/2022/01/01/%E4%B8%89%E4%B8%AA%E6%95%85%E4%BA%8B/</a></p>
<h2 id="【星球成员成果】"><a href="#【星球成员成果】" class="headerlink" title="【星球成员成果】"></a>【星球成员成果】</h2><ul>
<li><p><a href="https://yishenggong.com/2023/05/06/why-does-my-network-speed-drop-cn/" target="_blank" rel="external">强龙难压地头蛇的故事</a> 这位星球成员刚大学毕业几个月，加入星球不到2个月</p>
</li>
<li><p>成员故事 <a href="https://liarlee.site/2023/05/08/Linux/Linux_RDS%20QPS%20%E4%B8%8B%E9%99%8D%E5%BC%95%E5%8F%91%E7%9A%84%E7%BD%91%E7%BB%9C%E6%B5%81%E6%8E%A7%E5%88%86%E6%9E%90%E8%AE%B0%E5%BD%95/" target="_blank" rel="external">tcp协议和 os 网络系统的分析我之前真是一句都说不出来， 这次确实完整的走了一遍网络的部分。</a> 这位星球成员目前是 AWS 中国区员工</p>
</li>
</ul>
<p>强龙难压地头蛇的故事也引起各路技术大佬纷纷下场教年轻人如何学习：<a href="https://t.co/IBLCRzJem2" target="_blank" rel="external">treeverse.app/view/RDzsOXjO</a></p>
<p><img src="/images/951413iMgBlog/image-20230510193840999.png" alt="image-20230510193840999" style="zoom: 33%;"></p>
<h2 id="【加入星球】"><a href="#【加入星球】" class="headerlink" title="【加入星球】"></a>【加入星球】</h2><p>知识星球：<a href="https://t.zsxq.com/0cSFEUh2J" target="_blank" rel="external">https://t.zsxq.com/0cSFEUh2J</a>，在这里有400多成员等着你和你一起分享案例</p>
<p><img src="/images/951413iMgBlog/image-20230607090024270.png" alt="image-20230607090024270"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;程序员案例星球介绍&quot;&gt;&lt;a href=&quot;#程序员案例星球介绍&quot; class=&quot;headerlink&quot; title=&quot;程序员案例星球介绍&quot;&gt;&lt;/a&gt;程序员案例星球介绍&lt;/h1&gt;&lt;h2 id=&quot;【星球宗旨】&quot;&gt;&lt;a href=&quot;#【星球宗旨】&quot; class=&quot;head
    
    </summary>
    
      <category term="others" scheme="https://plantegg.github.io/categories/others/"/>
    
    
      <category term="星球" scheme="https://plantegg.github.io/tags/%E6%98%9F%E7%90%83/"/>
    
      <category term="案例" scheme="https://plantegg.github.io/tags/%E6%A1%88%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>我的网络传输速度为什么突然下降了</title>
    <link href="https://plantegg.github.io/2023/05/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E9%80%9F%E5%BA%A6%E4%B8%BA%E4%BB%80%E4%B9%88%E7%AA%81%E7%84%B6%E4%B8%8B%E9%99%8D%E4%BA%86/"/>
    <id>https://plantegg.github.io/2023/05/06/我的网络传输速度为什么突然下降了/</id>
    <published>2023-05-06T04:30:03.000Z</published>
    <updated>2023-06-07T01:23:38.605Z</updated>
    
    <content type="html"><![CDATA[<h1 id="我的网络传输速度为什么突然下降了"><a href="#我的网络传输速度为什么突然下降了" class="headerlink" title="我的网络传输速度为什么突然下降了"></a>我的网络传输速度为什么突然下降了</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这个问题是我星球成员做星球里面的必做实验时碰到的一个问题</p>
<p>最后的分析用到了我们的抓包大法+ping一ping真牛逼的证明方案，所以特意放出来供大家测试一下自己的分析能力，同时也检验大家对知识的掌握和运用。</p>
<p>这个问题很好，在EC2上稳定重现，假如你们的业务碰到了这个问题你怎么解决？</p>
<p>或者换个场景描述：你有一个SQL单独执行很快，2个SQL并行一起查速度就降到了原来的10%，是DB还是谁的锅？</p>
<p>推特上大佬们的讨论，看看别人都是怎么思考和推理的：<a href="https://treeverse.app/view/RDzsOXjO" target="_blank" rel="external">https://treeverse.app/view/RDzsOXjO</a></p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>一个降速问题，在AWS的 <a href="t2.micro">t2.micro</a>机器上几乎100％复现，操作: </p>
<ol>
<li>开三台aws <a href="t2.micro">t2.micro</a>机器，一台做server两台做client, 已知正常情况rtt是0.5ms，bandwidth 60mbps，文件大小2g</li>
<li>client1 去curl get server 文件</li>
<li>一段时间等client1网速稳定后,client2 去curl get server 文件</li>
<li>可以观察到两个client都降速到3.5mbps，这种情况就是算把server跑坏了。</li>
<li>关掉client2, 观察到client1恢复到7-8mbps，但是远低于60mbps的带宽上限，也就是速度被限制到了标称的10%</li>
<li>server搞坏之后，client重新下载就会出现一开始还行，但过10s就会掉到7-8mbps的情况，需要重启server才能恢复到60mbps</li>
</ol>
<p>星球不能发多图，和pcap文件，重现的详细抓包、截图等都放在google driver上了: <a href="https://drive.google.com/drive/folders/13rsOQ-6VZhXu0JRMLlUypRposRRcRN-a" target="_blank" rel="external">https://drive.google.com/drive/folders/13rsOQ-6VZhXu0JRMLlUypRposRRcRN-a</a> （<strong>建议大家去下载client2.pcap抓包看看</strong>）</p>
<p>抓包发现大量dup ack, 且bytes in flight很大，server send buffer很大。</p>
<p><img src="/images/951413iMgBlog/FryRnESX2vOUCICndaLZ3MuaqSmH.png" alt="img"></p>
<p><strong>==强烈建议你先别往下看，去下载上面链接中的抓包文件分析看看，然后和下面的分析对比一下==</strong></p>
<hr>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>有网络大牛陈硕老师 <a href="https://twitter.com/bnu_chenshuo/status/1654288717673291776" target="_blank" rel="external">在EC2上重现了这个问题</a> 以及他的分析，速度由300Mbps下降到了60Mbps：</p>
<p><img src="/images/951413iMgBlog/Fnl-CGFUBMjLwQWa2i6kPo7MuJFc.png" alt="img"></p>
<p>以及 左耳朵耗子 老师也做了实验以及分析：<a href="https://twitter.com/haoel/status/1654655067365179393" target="_blank" rel="external">https://twitter.com/haoel/status/1654655067365179393</a></p>
<p>我的分析：<a href="https://articles.zsxq.com/id_iq5a872u8sux.html" target="_blank" rel="external">https://articles.zsxq.com/id_iq5a872u8sux.html</a></p>
<p><img src="/images/951413iMgBlog/image-20230506132001274.png" alt="image-20230506132001274"></p>
<h3 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h3><p>证明原理如这个图</p>
<p><img src="/images/951413iMgBlog/image-20230506131422140.png" alt="image-20230506131422140"></p>
<p><img src="/images/951413iMgBlog/image-20230506131709216.png" alt="image-20230506131709216"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>99%的人不会弄脏双手去实验，哪怕是只需要下载一个抓包就能分析出来都不会去下载。但是为什么刚好是两位陈老师会去测试重现一下呢(原谅你没有AWS机器，但是不接受你不去google driver下载抓包文件 :) )，大概率他们的时间、经验、知识都比你要丰富一些，但是他们不忌惮弄脏手而你只想做个过客看看就懂，但最后你真的啥都没看懂！</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;我的网络传输速度为什么突然下降了&quot;&gt;&lt;a href=&quot;#我的网络传输速度为什么突然下降了&quot; class=&quot;headerlink&quot; title=&quot;我的网络传输速度为什么突然下降了&quot;&gt;&lt;/a&gt;我的网络传输速度为什么突然下降了&lt;/h1&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a hr
    
    </summary>
    
      <category term="TCP" scheme="https://plantegg.github.io/categories/TCP/"/>
    
    
      <category term="Linux" scheme="https://plantegg.github.io/tags/Linux/"/>
    
      <category term="TCP" scheme="https://plantegg.github.io/tags/TCP/"/>
    
      <category term="BDP" scheme="https://plantegg.github.io/tags/BDP/"/>
    
      <category term="RTT" scheme="https://plantegg.github.io/tags/RTT/"/>
    
  </entry>
  
  <entry>
    <title>比较不同CPU下的分支预测</title>
    <link href="https://plantegg.github.io/2023/04/16/%E6%AF%94%E8%BE%83%E4%B8%8D%E5%90%8CCPU%E4%B8%8B%E7%9A%84%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/"/>
    <id>https://plantegg.github.io/2023/04/16/比较不同CPU下的分支预测/</id>
    <published>2023-04-16T04:30:03.000Z</published>
    <updated>2023-05-06T13:09:48.218Z</updated>
    
    <content type="html"><![CDATA[<h1 id="比较不同CPU下的分支预测"><a href="#比较不同CPU下的分支预测" class="headerlink" title="比较不同CPU下的分支预测"></a>比较不同CPU下的分支预测</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文通过一段对分支预测是否友好的代码来验证 branch load miss 差异，已经最终带来的 性能差异。同时在x86和aarch64 下各选几款CPU共5款进行差异性对比</p>
<h2 id="CPU-情况"><a href="#CPU-情况" class="headerlink" title="CPU 情况"></a>CPU 情况</h2><h3 id="intel-x86"><a href="#intel-x86" class="headerlink" title="intel x86"></a>intel x86</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          x86_64</div><div class="line">CPU op-mode(s):        32-bit, 64-bit</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                48</div><div class="line">On-line CPU(s) list:   0-47</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    24</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          2</div><div class="line">Vendor ID:             GenuineIntel</div><div class="line">CPU family:            6</div><div class="line">Model:                 85</div><div class="line">Model name:            Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz</div><div class="line">Stepping:              4</div><div class="line">CPU MHz:               2500.195</div><div class="line">CPU max MHz:           3100.0000</div><div class="line">CPU min MHz:           1000.0000</div><div class="line">BogoMIPS:              4998.89</div><div class="line">Virtualization:        VT-x</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              33792K</div><div class="line">NUMA node0 CPU(s):     0-23</div><div class="line">NUMA node1 CPU(s):     24-47</div><div class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt avx512f avx512dq rdseed adx smap clflushopt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local cat_l3 mba</div></pre></td></tr></table></figure>
<h3 id="hygon-7260"><a href="#hygon-7260" class="headerlink" title="hygon 7260"></a>hygon 7260</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:        x86_64</div><div class="line">CPU op-mode(s):      32-bit, 64-bit</div><div class="line">Byte Order:          Little Endian</div><div class="line">Address sizes:       43 bits physical, 48 bits virtual</div><div class="line">CPU(s):              48</div><div class="line">On-line CPU(s) list: 0-47</div><div class="line">Thread(s) per core:  1</div><div class="line">Core(s) per socket:  24</div><div class="line">Socket(s):           2</div><div class="line">NUMA node(s):        8</div><div class="line">Vendor ID:           HygonGenuine</div><div class="line">CPU family:          24</div><div class="line">Model:               1</div><div class="line">Model name:          Hygon C86 7260 24-core Processor</div><div class="line">Stepping:            1</div><div class="line">Frequency boost:     enabled</div><div class="line">CPU MHz:             1069.534</div><div class="line">CPU max MHz:         2200.0000</div><div class="line">CPU min MHz:         1200.0000</div><div class="line">BogoMIPS:            4399.38</div><div class="line">Virtualization:      AMD-V</div><div class="line">L1d cache:           32K</div><div class="line">L1i cache:           64K</div><div class="line">L2 cache:            512K</div><div class="line">L3 cache:            8192K</div><div class="line">NUMA node0 CPU(s):   0-5</div><div class="line">NUMA node1 CPU(s):   6-11</div><div class="line">NUMA node2 CPU(s):   12-17</div><div class="line">NUMA node3 CPU(s):   18-23</div><div class="line">NUMA node4 CPU(s):   24-29</div><div class="line">NUMA node5 CPU(s):   30-35</div><div class="line">NUMA node6 CPU(s):   36-41</div><div class="line">NUMA node7 CPU(s):   42-47</div></pre></td></tr></table></figure>
<h3 id="ARM-鲲鹏920"><a href="#ARM-鲲鹏920" class="headerlink" title="ARM 鲲鹏920"></a>ARM 鲲鹏920</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                96</div><div class="line">On-line CPU(s) list:   0-95</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    48</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          4</div><div class="line">Model:                 0</div><div class="line">CPU max MHz:           2600.0000</div><div class="line">CPU min MHz:           200.0000</div><div class="line">BogoMIPS:              200.00</div><div class="line">L1d cache:             64K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              512K</div><div class="line">L3 cache:              24576K</div><div class="line">NUMA node0 CPU(s):     0-23</div><div class="line">NUMA node1 CPU(s):     24-47</div><div class="line">NUMA node2 CPU(s):     48-71</div><div class="line">NUMA node3 CPU(s):     72-95</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma dcpop asimddp asimdfhm</div></pre></td></tr></table></figure>
<h3 id="ARM-M710"><a href="#ARM-M710" class="headerlink" title="ARM M710"></a>ARM M710</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    128</div><div class="line">Socket(s):             1</div><div class="line">NUMA node(s):          2</div><div class="line">Model:                 0</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             64K</div><div class="line">L1i cache:             64K</div><div class="line">L2 cache:              1024K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-63</div><div class="line">NUMA node1 CPU(s):     64-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma lrcpc dcpop sha3 sm3 sm4 asimddp sha512 sve asimdfhm dit uscat ilrcpc flagm ssbs sb dcpodp sve2 sveaes svepmull svebitperm svesha3 svesm4 flagm2 frint svei8mm svebf16 i8mm bf16 dgh</div></pre></td></tr></table></figure>
<h3 id="ARM-FT-S2500"><a href="#ARM-FT-S2500" class="headerlink" title="ARM FT S2500"></a>ARM FT S2500</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">#lscpu</div><div class="line">Architecture:          aarch64</div><div class="line">Byte Order:            Little Endian</div><div class="line">CPU(s):                128</div><div class="line">On-line CPU(s) list:   0-127</div><div class="line">Thread(s) per core:    1</div><div class="line">Core(s) per socket:    64</div><div class="line">Socket(s):             2</div><div class="line">NUMA node(s):          16</div><div class="line">Model:                 3</div><div class="line">BogoMIPS:              100.00</div><div class="line">L1d cache:             32K</div><div class="line">L1i cache:             32K</div><div class="line">L2 cache:              2048K</div><div class="line">L3 cache:              65536K</div><div class="line">NUMA node0 CPU(s):     0-7</div><div class="line">NUMA node1 CPU(s):     8-15</div><div class="line">NUMA node2 CPU(s):     16-23</div><div class="line">NUMA node3 CPU(s):     24-31</div><div class="line">NUMA node4 CPU(s):     32-39</div><div class="line">NUMA node5 CPU(s):     40-47</div><div class="line">NUMA node6 CPU(s):     48-55</div><div class="line">NUMA node7 CPU(s):     56-63</div><div class="line">NUMA node8 CPU(s):     64-71</div><div class="line">NUMA node9 CPU(s):     72-79</div><div class="line">NUMA node10 CPU(s):    80-87</div><div class="line">NUMA node11 CPU(s):    88-95</div><div class="line">NUMA node12 CPU(s):    96-103</div><div class="line">NUMA node13 CPU(s):    104-111</div><div class="line">NUMA node14 CPU(s):    112-119</div><div class="line">NUMA node15 CPU(s):    120-127</div><div class="line">Flags:                 fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid</div></pre></td></tr></table></figure>
<h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a><a href="https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array" target="_blank" rel="external">测试代码</a></h2><p>对一个数组中较大的一半的值累加：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ctime&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="comment">// 随机产生整数，用分区函数填充，以避免出现分桶不均</span></div><div class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> arraySize = <span class="number">32768</span>;</div><div class="line">    <span class="keyword">int</span> data[arraySize];</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> c = <span class="number">0</span>; c &lt; arraySize; ++c)</div><div class="line">        data[c] = <span class="built_in">std</span>::rand() % <span class="number">256</span>;</div><div class="line"></div><div class="line">    <span class="comment">//排序后数据有序，CPU可以准确预测到if的分支</span></div><div class="line">    <span class="built_in">std</span>::sort(data, data + arraySize); <span class="comment">//预先排序，也可以注释掉，注释掉表示随机乱序几乎无法预测</span></div><div class="line"></div><div class="line">    <span class="comment">// 测试部分</span></div><div class="line">    <span class="keyword">clock_t</span> start = clock();</div><div class="line">    <span class="keyword">long</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; ++i)</div><div class="line">    &#123;</div><div class="line">        <span class="comment">// 主要计算部分，选一半元素参与计算</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">unsigned</span> c = <span class="number">0</span>; c &lt; arraySize; ++c)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span> (data[c] &gt;= <span class="number">128</span>)</div><div class="line">                sum += data[c];</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">double</span> elapsedTime = <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(clock() - start) / CLOCKS_PER_SEC;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; elapsedTime &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"sum = "</span> &lt;&lt; sum &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>以上代码可以注释掉第15行，也就是不对代码排序直接累加，不排序的话 if (data[c] &gt;= 128) 有50% 概率成立，排序后前一半元素if都不成立，后一半元素if都成立，导致CPU流水线很好预测后面的代码，可以提前加载运算打高IPC</p>
<h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><h3 id="aarch64-鲲鹏920"><a href="#aarch64-鲲鹏920" class="headerlink" title="aarch64 鲲鹏920"></a>aarch64 鲲鹏920</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads ./aftersort</div><div class="line">11.44</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">           470,740      branch-misses                                                 (59.99%)</div><div class="line">    29,716,627,485      bus-cycles                # 2595.890 M/sec                    (60.03%)</div><div class="line">        96,469,435      cache-misses              #    0.420 % of all cache refs      (60.03%)</div><div class="line">    22,984,316,728      cache-references          # 2007.791 M/sec                    (60.03%)</div><div class="line">    29,716,018,641      cpu-cycles                #    2.596 GHz                      (65.02%)</div><div class="line">    83,666,813,837      instructions              #    2.82  insn per cycle</div><div class="line">                                                  #    0.10  stalled cycles per insn  (65.02%)</div><div class="line">     8,765,807,804      stalled-cycles-backend    #   29.50% backend cycles idle      (65.02%)</div><div class="line">         8,917,112      stalled-cycles-frontend   #    0.03% frontend cycles idle     (65.02%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">                 5      context-switches          #    0.000 K/sec</div><div class="line">         11,447.57 msec cpu-clock                 #    1.000 CPUs utilized</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               132      minor-faults              #    0.012 K/sec</div><div class="line">               132      page-faults               #    0.012 K/sec</div><div class="line">         11,447.57 msec task-clock                #    1.000 CPUs utilized</div><div class="line">        96,471,779      L1-dcache-load-misses     #    0.42% of all L1-dcache accesses  (65.02%)</div><div class="line">    22,985,408,745      L1-dcache-loads           # 2007.886 M/sec                    (65.02%)</div><div class="line">        96,472,614      L1-dcache-store-misses    #    8.427 M/sec                    (65.02%)</div><div class="line">    22,986,056,706      L1-dcache-stores          # 2007.943 M/sec                    (65.02%)</div><div class="line">           184,402      L1-icache-load-misses     #    0.00% of all L1-icache accesses  (65.02%)</div><div class="line">    14,779,996,797      L1-icache-loads           # 1291.104 M/sec                    (64.99%)</div><div class="line">           330,651      branch-load-misses        #    0.029 M/sec                    (64.96%)</div><div class="line">     6,561,353,921      branch-loads              #  573.166 M/sec                    (64.96%)</div><div class="line">         3,464,612      dTLB-load-misses          #    0.02% of all dTLB cache accesses  (64.96%)</div><div class="line">    23,008,097,187      dTLB-loads                # 2009.868 M/sec                    (59.96%)</div><div class="line">               745      iTLB-load-misses          #    0.00% of all iTLB cache accesses  (59.96%)</div><div class="line">    14,779,577,851      iTLB-loads                # 1291.067 M/sec                    (59.96%)</div><div class="line">    </div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads ./beforesort</div><div class="line">30.92</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     1,639,558,981      branch-misses                                                 (59.96%)</div><div class="line">    80,284,783,419      bus-cycles                # 2595.949 M/sec                    (59.96%)</div><div class="line">       118,459,436      cache-misses              #    0.356 % of all cache refs      (59.96%)</div><div class="line">    33,285,701,200      cache-references          # 1076.269 M/sec                    (59.96%)</div><div class="line">    80,283,427,379      cpu-cycles                #    2.596 GHz                      (64.96%)</div><div class="line">    83,694,841,472      instructions              #    1.04  insn per cycle</div><div class="line">                                                  #    0.11  stalled cycles per insn  (64.98%)</div><div class="line">     8,849,746,372      stalled-cycles-backend    #   11.02% backend cycles idle      (64.99%)</div><div class="line">     8,064,207,583      stalled-cycles-frontend   #   10.04% frontend cycles idle     (65.00%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">                10      context-switches          #    0.000 K/sec</div><div class="line">         30,926.95 msec cpu-clock                 #    1.000 CPUs utilized</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               133      minor-faults              #    0.004 K/sec</div><div class="line">               133      page-faults               #    0.004 K/sec</div><div class="line">         30,926.95 msec task-clock                #    1.000 CPUs utilized</div><div class="line">       118,445,576      L1-dcache-load-misses     #    0.36% of all L1-dcache accesses  (65.02%)</div><div class="line">    33,286,586,418      L1-dcache-loads           # 1076.297 M/sec                    (65.03%)</div><div class="line">       118,441,599      L1-dcache-store-misses    #    3.830 M/sec                    (65.04%)</div><div class="line">    33,286,751,407      L1-dcache-stores          # 1076.302 M/sec                    (65.05%)</div><div class="line">           410,040      L1-icache-load-misses     #    0.00% of all L1-icache accesses  (65.05%)</div><div class="line">    51,611,031,810      L1-icache-loads           # 1668.805 M/sec                    (65.04%)</div><div class="line">     1,639,731,725      branch-load-misses        #   53.020 M/sec                    (65.03%)</div><div class="line">     7,520,634,791      branch-loads              #  243.174 M/sec                    (65.02%)</div><div class="line">         3,536,061      dTLB-load-misses          #    0.01% of all dTLB cache accesses  (65.00%)</div><div class="line">    47,898,134,543      dTLB-loads                # 1548.751 M/sec                    (59.99%)</div><div class="line">             2,529      iTLB-load-misses          #    0.00% of all iTLB cache accesses  (59.97%)</div><div class="line">    51,612,575,118      iTLB-loads                # 1668.854 M/sec                    (59.96%)</div></pre></td></tr></table></figure>
<p>以上在相同CPU下数据对比可以看到核心差异是branch-load-misses和branch-misses，当然最终也体现在 IPC 数值上，排序后IPC更高不是因为数据有序取起来更快，而是因为执行逻辑更容易提前预测，也就是可以提前加载if代码到cache中。符合预期</p>
<h3 id="aarch64-M710"><a href="#aarch64-M710" class="headerlink" title="aarch64 M710"></a>aarch64 M710</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-icache-load-misses,L1-icache-loads,LLC-load-misses,LLC-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads ./aftersort</div><div class="line">8.20237</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">           912,836      branch-misses                                                 (29.86%)</div><div class="line">    22,560,165,604      bus-cycles                # 2748.461 M/sec                    (29.91%)</div><div class="line">       205,068,961      cache-misses              #    0.892 % of all cache refs      (29.96%)</div><div class="line">    22,998,186,284      cache-references          # 2801.824 M/sec                    (30.01%)</div><div class="line">    22,559,518,941      cpu-cycles                #    2.748 GHz                      (35.03%)</div><div class="line">    77,068,271,833      instructions              #    3.42  insn per cycle</div><div class="line">                                                  #    0.06  stalled cycles per insn  (35.08%)</div><div class="line">     4,892,933,264      stalled-cycles-backend    #   21.69% backend cycles idle      (35.13%)</div><div class="line">     1,103,203,963      stalled-cycles-frontend   #    4.89% frontend cycles idle     (35.13%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">                17      context-switches          #    0.002 K/sec</div><div class="line">          8,208.29 msec cpu-clock                 #    1.000 CPUs utilized</div><div class="line">                 3      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               227      minor-faults              #    0.028 K/sec</div><div class="line">               227      page-faults               #    0.028 K/sec</div><div class="line">          8,208.30 msec task-clock                #    1.000 CPUs utilized</div><div class="line">       205,384,990      L1-dcache-load-misses     #    0.89% of all L1-dcache accesses  (35.13%)</div><div class="line">    22,997,494,522      L1-dcache-loads           # 2801.739 M/sec                    (35.13%)</div><div class="line">            66,804      L1-icache-load-misses     #    0.00% of all L1-icache accesses  (35.13%)</div><div class="line">    15,486,704,750      L1-icache-loads           # 1886.715 M/sec                    (30.12%)</div><div class="line">            76,066      LLC-load-misses           #    0.00% of all LL-cache accesses  (30.09%)</div><div class="line">                 0      LLC-loads                 #    0.000 K/sec                    (30.03%)</div><div class="line">           672,231      branch-load-misses        #    0.082 M/sec                    (29.98%)</div><div class="line">     9,844,109,024      branch-loads              # 1199.288 M/sec                    (29.93%)</div><div class="line">           107,198      dTLB-load-misses          #    0.00% of all dTLB cache accesses  (29.89%)</div><div class="line">    22,998,647,232      dTLB-loads                # 2801.880 M/sec                    (29.84%)</div><div class="line">             9,497      iTLB-load-misses          #    0.08% of all iTLB cache accesses  (29.81%)</div><div class="line">        11,755,825      iTLB-loads                #    1.432 M/sec                    (29.82%)</div><div class="line"></div><div class="line">       8.210235171 seconds time elapsed</div><div class="line"></div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-icache-load-misses,L1-icache-loads,LLC-load-misses,LLC-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads ./beforesort</div><div class="line">16.8872</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     1,229,182,485      branch-misses                                                 (29.93%)</div><div class="line">    46,401,675,872      bus-cycles                # 2747.200 M/sec                    (29.95%)</div><div class="line">       206,116,950      cache-misses              #    0.546 % of all cache refs      (29.97%)</div><div class="line">    37,773,036,315      cache-references          # 2236.343 M/sec                    (30.01%)</div><div class="line">    46,410,071,081      cpu-cycles                #    2.748 GHz                      (35.03%)</div><div class="line">    77,083,625,280      instructions              #    1.66  insn per cycle</div><div class="line">                                                  #    0.06  stalled cycles per insn  (35.07%)</div><div class="line">     1,961,071,890      stalled-cycles-backend    #    4.23% backend cycles idle      (35.11%)</div><div class="line">     4,988,241,014      stalled-cycles-frontend   #   10.75% frontend cycles idle     (35.11%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">             1,100      context-switches          #    0.065 K/sec</div><div class="line">         16,890.39 msec cpu-clock                 #    0.997 CPUs utilized</div><div class="line">                 7      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               229      minor-faults              #    0.014 K/sec</div><div class="line">               229      page-faults               #    0.014 K/sec</div><div class="line">         16,890.69 msec task-clock                #    0.997 CPUs utilized</div><div class="line">       205,761,970      L1-dcache-load-misses     #    0.54% of all L1-dcache accesses  (35.09%)</div><div class="line">    37,832,336,945      L1-dcache-loads           # 2239.854 M/sec                    (35.06%)</div><div class="line">           207,158      L1-icache-load-misses     #    0.00% of all L1-icache accesses  (35.04%)</div><div class="line">    41,944,228,741      L1-icache-loads           # 2483.298 M/sec                    (30.00%)</div><div class="line">           135,144      LLC-load-misses           #    0.00% of all LL-cache accesses  (29.97%)</div><div class="line">                 0      LLC-loads                 #    0.000 K/sec                    (29.97%)</div><div class="line">     1,232,325,180      branch-load-misses        #   72.960 M/sec                    (29.96%)</div><div class="line">    14,776,289,690      branch-loads              #  874.827 M/sec                    (29.96%)</div><div class="line">           177,790      dTLB-load-misses          #    0.00% of all dTLB cache accesses  (29.97%)</div><div class="line">    37,839,288,998      dTLB-loads                # 2240.266 M/sec                    (29.95%)</div><div class="line">            46,301      iTLB-load-misses          #    0.00% of all iTLB cache accesses  (29.94%)</div><div class="line">    12,631,307,441      iTLB-loads                #  747.833 M/sec                    (29.92%)</div><div class="line"></div><div class="line">      16.943678377 seconds time elapsed</div></pre></td></tr></table></figure>
<p>M710上排序与否和鲲鹏差不多，但是 M710比 鲲鹏要快一些，差别只要有主频高一点点(6%)，另外M710编译后的指令数量也略少(8%)。</p>
<p>最大的差别是没有排序的话 branch-load-misses(1,232,325,180)/branch-loads(14,776,289,690) 比例只有鲲鹏的50%，导致整体 IPC 比鲲鹏高不少(1.66 VS 1.04)</p>
<p>如果是排序后的数据来看 M710比鲲鹏好40%，IPC 好了20%，iTLB-loads 差异特别大</p>
<h3 id="aarch64-FT-S2500"><a href="#aarch64-FT-S2500" class="headerlink" title="aarch64 FT S2500"></a>aarch64 FT S2500</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,alignment-faults,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses ./aftersort</div><div class="line">16.63</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">         1,298,873      branch-misses             #    0.078 M/sec                    (37.49%)</div><div class="line">    34,893,306,641      bus-cycles                # 2096.049 M/sec                    (37.51%)</div><div class="line">       211,447,452      cache-misses              #    0.913 % of all cache refs      (37.53%)</div><div class="line">    23,154,909,673      cache-references          # 1390.921 M/sec                    (37.54%)</div><div class="line">    34,891,766,353      cpu-cycles                #    2.096 GHz                      (43.79%)</div><div class="line">    83,918,069,835      instructions              #    2.41  insns per cycle          (43.79%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">               102      context-switches          #    0.006 K/sec</div><div class="line">      16647.131540      cpu-clock (msec)</div><div class="line">                35      cpu-migrations            #    0.002 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               384      minor-faults              #    0.023 K/sec</div><div class="line">               384      page-faults               #    0.023 K/sec</div><div class="line">      16647.178560      task-clock (msec)         #    1.000 CPUs utilized</div><div class="line">       211,277,069      L1-dcache-load-misses     #    0.91% of all L1-dcache hits    (43.79%)</div><div class="line">    23,168,806,437      L1-dcache-loads           # 1391.756 M/sec                    (43.77%)</div><div class="line">       211,376,611      L1-dcache-store-misses    #   12.697 M/sec                    (43.75%)</div><div class="line">    23,172,492,978      L1-dcache-stores          # 1391.977 M/sec                    (43.73%)</div><div class="line">         6,060,438      L1-icache-load-misses     #    0.364 M/sec                    (43.72%)</div><div class="line">    23,283,174,318      L1-icache-loads           # 1398.626 M/sec                    (37.48%)</div><div class="line">         1,201,268      branch-load-misses        #    0.072 M/sec                    (37.47%)</div><div class="line">     6,626,003,512      branch-loads              #  398.026 M/sec                    (37.47%)</div><div class="line">         4,417,981      dTLB-load-misses          #    0.265 M/sec                    (37.47%)</div><div class="line">            58,242      iTLB-load-misses          #    0.003 M/sec                    (37.47%)</div><div class="line"></div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,alignment-faults,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-store-misses,L1-dcache-stores,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,iTLB-load-misses ./beforesort</div><div class="line">39.8</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     1,641,714,982      branch-misses             #   41.244 M/sec                    (37.50%)</div><div class="line">    83,450,971,727      bus-cycles                # 2096.514 M/sec                    (37.51%)</div><div class="line">       209,942,920      cache-misses              #    0.625 % of all cache refs      (37.51%)</div><div class="line">    33,584,108,027      cache-references          #  843.724 M/sec                    (37.51%)</div><div class="line">    83,446,991,284      cpu-cycles                #    2.096 GHz                      (43.76%)</div><div class="line">    83,872,213,462      instructions              #    1.01  insns per cycle          (43.75%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">               165      context-switches          #    0.004 K/sec</div><div class="line">      39804.395840      cpu-clock (msec)</div><div class="line">               104      cpu-migrations            #    0.003 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               728      minor-faults              #    0.018 K/sec</div><div class="line">               728      page-faults               #    0.018 K/sec</div><div class="line">      39804.626860      task-clock (msec)         #    1.000 CPUs utilized</div><div class="line">       209,884,485      L1-dcache-load-misses     #    0.62% of all L1-dcache hits    (43.75%)</div><div class="line">    33,591,847,895      L1-dcache-loads           #  843.918 M/sec                    (43.75%)</div><div class="line">       209,796,158      L1-dcache-store-misses    #    5.271 M/sec                    (43.75%)</div><div class="line">    33,595,628,139      L1-dcache-stores          #  844.013 M/sec                    (43.75%)</div><div class="line">         5,575,802      L1-icache-load-misses     #    0.140 M/sec                    (43.75%)</div><div class="line">    68,272,798,305      L1-icache-loads           # 1715.198 M/sec                    (37.50%)</div><div class="line">     1,642,653,627      branch-load-misses        #   41.268 M/sec                    (37.50%)</div><div class="line">     6,846,418,902      branch-loads              #  172.001 M/sec                    (37.50%)</div><div class="line">         4,162,728      dTLB-load-misses          #    0.105 M/sec                    (37.50%)</div><div class="line">            57,375      iTLB-load-misses          #    0.001 M/sec                    (37.50%)</div></pre></td></tr></table></figure>
<h3 id="Intel-x86-8163"><a href="#Intel-x86-8163" class="headerlink" title="Intel x86 8163"></a>Intel x86 8163</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,alignment-faults,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores ./aftersort</div><div class="line">9.77</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     6,541,060,672      branch-instructions       #  669.204 M/sec                    (10.72%)</div><div class="line">           727,847      branch-misses             #    0.01% of all branches          (14.30%)</div><div class="line">       241,730,862      bus-cycles                #   24.731 M/sec                    (17.88%)</div><div class="line">           275,443      cache-misses              #   44.685 % of all cache refs      (21.45%)</div><div class="line">           616,413      cache-references          #    0.063 M/sec                    (25.03%)</div><div class="line">    24,186,369,646      cpu-cycles                #    2.474 GHz                      (28.60%)</div><div class="line">    29,491,804,977      instructions              #    1.22  insns per cycle          (32.18%)</div><div class="line">    24,198,780,299      ref-cycles                # 2475.731 M/sec                    (35.75%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                16      context-switches          #    0.002 K/sec</div><div class="line">       9774.393202      cpu-clock (msec)</div><div class="line">                 8      cpu-migrations            #    0.001 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               490      minor-faults              #    0.050 K/sec</div><div class="line">               490      page-faults               #    0.050 K/sec</div><div class="line">       9774.396556      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">        74,078,676      L1-dcache-load-misses     #    1.64% of all L1-dcache hits    (189256748561.94%)</div><div class="line">     4,515,522,850      L1-dcache-loads           #  461.975 M/sec                    (189237344482.16%)</div><div class="line">         3,798,032      L1-dcache-stores          #    0.389 M/sec                    (189217941721.85%)</div><div class="line">         1,077,146      L1-icache-load-misses     #    0.110 M/sec                    (189198537875.18%)</div><div class="line">            89,144      LLC-load-misses           #   74.54% of all LL-cache hits     (189179139811.86%)</div><div class="line">           119,586      LLC-loads                 #    0.012 M/sec                    (189159737036.24%)</div><div class="line">             3,450      LLC-store-misses          #    0.353 K/sec                    (189140342885.02%)</div><div class="line">           105,021      LLC-stores                #    0.011 M/sec                    (7.15%)</div><div class="line">           458,465      branch-load-misses        #    0.047 M/sec                    (10.73%)</div><div class="line">     6,557,558,579      branch-loads              #  670.891 M/sec                    (14.30%)</div><div class="line">               733      dTLB-load-misses          #    0.00% of all dTLB cache hits   (17.87%)</div><div class="line">    12,039,967,837      dTLB-loads                # 1231.786 M/sec                    (21.44%)</div><div class="line">               104      dTLB-store-misses         #    0.011 K/sec                    (25.01%)</div><div class="line">         7,040,783      dTLB-stores               #    0.720 M/sec                    (28.58%)</div><div class="line">               763      iTLB-load-misses          #   62.80% of all iTLB cache hits   (28.56%)</div><div class="line">             1,215      iTLB-loads                #    0.124 K/sec                    (28.55%)</div><div class="line">           168,588      node-load-misses          #    0.017 M/sec                    (28.55%)</div><div class="line">           131,578      node-loads                #    0.013 M/sec                    (28.55%)</div><div class="line">             4,484      node-store-misses         #    0.459 K/sec                    (7.14%)</div><div class="line">                42      node-stores               #    0.004 K/sec                    (7.14%)</div><div class="line">                </div><div class="line">#perf stat -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,alignment-faults,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores ./beforesort</div><div class="line">29.52</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     6,565,036,614      branch-instructions       #  222.370 M/sec                    (10.72%)</div><div class="line">     1,599,826,737      branch-misses             #   24.37% of all branches          (14.29%)</div><div class="line">       730,977,010      bus-cycles                #   24.760 M/sec                    (17.86%)</div><div class="line">           920,858      cache-misses              #   48.057 % of all cache refs      (21.43%)</div><div class="line">         1,916,178      cache-references          #    0.065 M/sec                    (25.00%)</div><div class="line">    73,123,904,158      cpu-cycles                #    2.477 GHz                      (28.57%)</div><div class="line">    29,618,485,912      instructions              #    0.41  insns per cycle          (32.14%)</div><div class="line">    73,152,861,566      ref-cycles                # 2477.828 M/sec                    (35.72%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                26      context-switches          #    0.001 K/sec</div><div class="line">      29522.972689      cpu-clock (msec)</div><div class="line">                13      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               593      minor-faults              #    0.020 K/sec</div><div class="line">               593      page-faults               #    0.020 K/sec</div><div class="line">      29522.976661      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">        76,164,025      L1-dcache-load-misses     #    1.68% of all L1-dcache hits    (62596004730.92%)</div><div class="line">     4,521,935,099      L1-dcache-loads           #  153.167 M/sec                    (62593882213.79%)</div><div class="line">         1,170,288      L1-dcache-stores          #    0.040 M/sec                    (62591759384.11%)</div><div class="line">         2,975,318      L1-icache-load-misses     #    0.101 M/sec                    (62591281765.29%)</div><div class="line">           178,510      LLC-load-misses           #   66.98% of all LL-cache hits     (62591281765.30%)</div><div class="line">           266,514      LLC-loads                 #    0.009 M/sec                    (62591281765.18%)</div><div class="line">             6,841      LLC-store-misses          #    0.232 K/sec                    (62591578887.87%)</div><div class="line">           335,369      LLC-stores                #    0.011 M/sec                    (7.15%)</div><div class="line">     1,600,893,693      branch-load-misses        #   54.225 M/sec                    (10.72%)</div><div class="line">     6,565,516,562      branch-loads              #  222.387 M/sec                    (14.29%)</div><div class="line">            33,070      dTLB-load-misses          #    0.00% of all dTLB cache hits   (17.87%)</div><div class="line">    12,043,088,689      dTLB-loads                #  407.923 M/sec                    (21.44%)</div><div class="line">               180      dTLB-store-misses         #    0.006 K/sec                    (25.01%)</div><div class="line">         2,359,365      dTLB-stores               #    0.080 M/sec                    (28.58%)</div><div class="line">             9,399      iTLB-load-misses          #  849.82% of all iTLB cache hits   (28.58%)</div><div class="line">             1,106      iTLB-loads                #    0.037 K/sec                    (28.58%)</div><div class="line">           439,052      node-load-misses          #    0.015 M/sec                    (28.58%)</div><div class="line">           367,546      node-loads                #    0.012 M/sec                    (28.58%)</div><div class="line">             7,539      node-store-misses         #    0.255 K/sec                    (7.15%)</div><div class="line">             1,736      node-stores               #    0.059 K/sec                    (7.14%)</div></pre></td></tr></table></figure>
<p>从 x86 和 aarch 对比来看，x86 编译后的指令数是 aarch 的35%，ARM 是精简指令，数量多比较好理解。主频2.5 GHz 较 M710低了11%。</p>
<p>IPC 差异比较大，有一部分是因为 ARM 精简指令本来有较高的 IPC。</p>
<p>从排序前的差异来看除了指令集外导致 IPC 较高的原因主要也是 branch-load-misses(1,232,325,180)/branch-loads(14,776,289,690)  比 intel的 1,602,020,038/6,568,921,480, 也就是 M710的 branch miss 率比 intel 低了一倍。</p>
<p>排序后去掉了 branch miss 差异，M710 比 intel 快了 10%，只要是因为主频的差异</p>
<p>on 8269 3.2GHz</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-instructions,branch-misses,cpu-cycles,instructions,branch-load-misses,branch-loads,task-clock,cpu-clock ./beforesort</div><div class="line">22.96</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line"> Performance counter stats for &apos;./beforesort&apos;:</div><div class="line"></div><div class="line">     6,573,626,859      branch-instructions       #  286.177 M/sec                    (83.33%)</div><div class="line">     1,602,898,541      branch-misses             #   24.38% of all branches          (83.33%)</div><div class="line">    73,189,204,878      cpu-cycles                #    3.186 GHz                      (66.67%)</div><div class="line">    29,627,520,323      instructions              #    0.40  insns per cycle          (83.33%)</div><div class="line">     1,602,848,454      branch-load-misses        #   69.779 M/sec                    (83.33%)</div><div class="line">     6,572,915,651      branch-loads              #  286.146 M/sec                    (83.33%)</div><div class="line">      22970.482491      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">      22970.482557      cpu-clock (msec)</div></pre></td></tr></table></figure>
<h3 id="hygon-7260-1"><a href="#hygon-7260-1" class="headerlink" title="hygon 7260"></a>hygon 7260</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-instructions,branch-misses,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-prefetches,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads ./aftersort</div><div class="line">10.9479</div><div class="line">sum = 314931600000</div><div class="line">     9,848,123,830      branch-instructions       #  898.161 M/sec                    (26.26%)</div><div class="line">           496,734      branch-misses             #    0.01% of all branches          (26.30%)</div><div class="line">           713,235      cache-misses              #    0.336 % of all cache refs      (26.34%)</div><div class="line">       212,455,257      cache-references          #   19.376 M/sec                    (26.37%)</div><div class="line">    27,277,461,559      cpu-cycles                #    2.488 GHz                      (26.41%)</div><div class="line">    32,785,270,866      instructions              #    1.20  insn per cycle</div><div class="line">                                                  #    0.58  stalled cycles per insn  (26.43%)</div><div class="line">    19,069,766,918      stalled-cycles-backend    #   69.91% backend cycles idle      (26.43%)</div><div class="line">         6,560,109      stalled-cycles-frontend   #    0.02% frontend cycles idle     (26.42%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">             1,086      context-switches          #    0.099 K/sec</div><div class="line">         10,964.61 msec cpu-clock                 #    0.999 CPUs utilized</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               154      minor-faults              #    0.014 K/sec</div><div class="line">               154      page-faults               #    0.014 K/sec</div><div class="line">         10,964.91 msec task-clock                #    0.999 CPUs utilized</div><div class="line">       206,294,123      L1-dcache-load-misses     #    1.14% of all L1-dcache hits    (26.38%)</div><div class="line">    18,083,269,173      L1-dcache-loads           # 1649.217 M/sec                    (26.35%)</div><div class="line">       205,499,292      L1-dcache-prefetches      #   18.742 M/sec                    (26.31%)</div><div class="line">           749,548      L1-icache-load-misses     #    8.67% of all L1-icache hits    (26.27%)</div><div class="line">         8,643,478      L1-icache-loads           #    0.788 M/sec                    (26.25%)</div><div class="line">           305,577      branch-load-misses        #    0.028 M/sec                    (26.25%)</div><div class="line">     9,850,674,490      branch-loads              #  898.394 M/sec                    (26.25%)</div><div class="line">             6,736      dTLB-load-misses          #    6.85% of all dTLB cache hits   (26.25%)</div><div class="line">            98,327      dTLB-loads                #    0.009 M/sec                    (26.25%)</div><div class="line">               114      iTLB-load-misses          #   78.62% of all iTLB cache hits   (26.25%)</div><div class="line">               145      iTLB-loads                #    0.013 K/sec                    (26.25%)</div><div class="line">               </div><div class="line">#perf stat -e branch-instructions,branch-misses,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-prefetches,L1-icache-load-misses,L1-icache-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads ./beforesort</div><div class="line">23.3648</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     9,843,358,378      branch-instructions       #  421.186 M/sec                    (26.26%)</div><div class="line">     1,156,804,801      branch-misses             #   11.75% of all branches          (26.28%)</div><div class="line">           754,542      cache-misses              #    0.351 % of all cache refs      (26.29%)</div><div class="line">       215,234,724      cache-references          #    9.210 M/sec                    (26.31%)</div><div class="line">    58,274,116,562      cpu-cycles                #    2.493 GHz                      (26.33%)</div><div class="line">    32,850,416,330      instructions              #    0.56  insn per cycle</div><div class="line">                                                  #    0.06  stalled cycles per insn  (26.34%)</div><div class="line">     1,838,222,200      stalled-cycles-backend    #    3.15% backend cycles idle      (26.34%)</div><div class="line">     1,187,291,146      stalled-cycles-frontend   #    2.04% frontend cycles idle     (26.34%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">             2,326      context-switches          #    0.100 K/sec</div><div class="line">         23,370.23 msec cpu-clock                 #    0.999 CPUs utilized</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               150      minor-faults              #    0.006 K/sec</div><div class="line">               150      page-faults               #    0.006 K/sec</div><div class="line">         23,370.97 msec task-clock                #    0.999 CPUs utilized</div><div class="line">       207,451,839      L1-dcache-load-misses     #    0.82% of all L1-dcache hits    (26.34%)</div><div class="line">    25,180,673,249      L1-dcache-loads           # 1077.451 M/sec                    (26.34%)</div><div class="line">       205,669,557      L1-dcache-prefetches      #    8.800 M/sec                    (26.34%)</div><div class="line">         1,725,971      L1-icache-load-misses     #    8.12% of all L1-icache hits    (26.34%)</div><div class="line">        21,265,604      L1-icache-loads           #    0.910 M/sec                    (26.34%)</div><div class="line">     1,157,454,249      branch-load-misses        #   49.526 M/sec                    (26.34%)</div><div class="line">     9,843,015,406      branch-loads              #  421.171 M/sec                    (26.33%)</div><div class="line">            22,287      dTLB-load-misses          #    7.08% of all dTLB cache hits   (26.31%)</div><div class="line">           314,618      dTLB-loads                #    0.013 M/sec                    (26.29%)</div><div class="line">               445      iTLB-load-misses          #   44.95% of all iTLB cache hits   (26.28%)</div><div class="line">               990      iTLB-loads                #    0.042 K/sec                    (26.26%)</div></pre></td></tr></table></figure>
<p>hygon 在这两个场景中排序前比 intel 好了 20%，IPC 好30%，但是指令数多了10%，最关键的也是因为hygon的 branch-load-misses 率较低。</p>
<p>排序后 hygon 略慢10%，主要是指令数多了将近10%。</p>
<p>如果直接将 intel 下 编译好的二进制放到 hygon 下运行，完全可以跑通，指令数也显示和 intel 一样了，但是总时间较在hygon下编译的二进制没有变化</p>
<p><img src="/images/951413iMgBlog/image-20230308145915585.png" alt="image-20230308145915585"></p>
<h2 id="开启-gcc-O3-优化"><a href="#开启-gcc-O3-优化" class="headerlink" title="开启 gcc O3 优化"></a>开启 gcc O3 优化</h2><h3 id="intel-8163"><a href="#intel-8163" class="headerlink" title="intel 8163"></a>intel 8163</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,alignment-faults,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores ./beforesort</div><div class="line">2.94</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     3,268,501,946      branch-instructions       # 1109.263 M/sec                    (10.74%)</div><div class="line">           226,833      branch-misses             #    0.01% of all branches          (14.33%)</div><div class="line">        72,998,727      bus-cycles                #   24.774 M/sec                    (17.90%)</div><div class="line">            89,636      cache-misses              #   34.026 % of all cache refs      (21.47%)</div><div class="line">           263,434      cache-references          #    0.089 M/sec                    (25.03%)</div><div class="line">     7,301,839,495      cpu-cycles                #    2.478 GHz                      (28.59%)</div><div class="line">    26,180,809,574      instructions              #    3.59  insns per cycle          (32.16%)</div><div class="line">     7,304,150,283      ref-cycles                # 2478.880 M/sec                    (35.73%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                10      context-switches          #    0.003 K/sec</div><div class="line">       2946.550492      cpu-clock (msec)</div><div class="line">                 7      cpu-migrations            #    0.002 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               370      minor-faults              #    0.126 K/sec</div><div class="line">               370      page-faults               #    0.126 K/sec</div><div class="line">       2946.552985      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">        73,550,829      L1-dcache-load-misses     #    8.97% of all L1-dcache hits    (627063379426.55%)</div><div class="line">       820,264,255      L1-dcache-loads           #  278.381 M/sec                    (627063379426.55%)</div><div class="line">             6,301      L1-dcache-stores          #    0.002 M/sec                    (627063379426.52%)</div><div class="line">           344,639      L1-icache-load-misses     #    0.117 M/sec                    (627063379426.51%)</div><div class="line">            70,181      LLC-load-misses           #   84.80% of all LL-cache hits     (630745019998.59%)</div><div class="line">            82,757      LLC-loads                 #    0.028 M/sec                    (630529428492.86%)</div><div class="line">               592      LLC-store-misses          #    0.201 K/sec                    (630313967916.99%)</div><div class="line">            33,362      LLC-stores                #    0.011 M/sec                    (7.17%)</div><div class="line">           153,522      branch-load-misses        #    0.052 M/sec                    (10.75%)</div><div class="line">     3,263,884,498      branch-loads              # 1107.696 M/sec                    (14.33%)</div><div class="line">               274      dTLB-load-misses          #    0.00% of all dTLB cache hits   (17.90%)</div><div class="line">     2,179,821,780      dTLB-loads                #  739.787 M/sec                    (21.47%)</div><div class="line">                 8      dTLB-store-misses         #    0.003 K/sec                    (25.04%)</div><div class="line">            12,708      dTLB-stores               #    0.004 M/sec                    (28.61%)</div><div class="line">                59      iTLB-load-misses          #   52.68% of all iTLB cache hits   (28.60%)</div><div class="line">               112      iTLB-loads                #    0.038 K/sec                    (28.59%)</div><div class="line">             5,919      node-load-misses          #    0.002 M/sec                    (28.59%)</div><div class="line">             1,648      node-loads                #    0.559 K/sec                    (28.58%)</div><div class="line">               560      node-store-misses         #    0.190 K/sec                    (7.15%)</div><div class="line">                14      node-stores               #    0.005 K/sec                    (7.14%)</div><div class="line">                </div><div class="line">#perf stat -e branch-instructions,branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,ref-cycles,alignment-faults,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-dcache-stores,L1-icache-load-misses,LLC-load-misses,LLC-loads,LLC-store-misses,LLC-stores,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,dTLB-store-misses,dTLB-stores,iTLB-load-misses,iTLB-loads,node-load-misses,node-loads,node-store-misses,node-stores ./aftersort</div><div class="line">2.95</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">     3,255,184,180      branch-instructions       # 1102.320 M/sec                    (10.74%)</div><div class="line">           791,180      branch-misses             #    0.02% of all branches          (14.35%)</div><div class="line">        73,001,075      bus-cycles                #   24.721 M/sec                    (17.93%)</div><div class="line">           520,140      cache-misses              #   82.262 % of all cache refs      (21.52%)</div><div class="line">           632,298      cache-references          #    0.214 M/sec                    (25.11%)</div><div class="line">     7,309,286,959      cpu-cycles                #    2.475 GHz                      (28.69%)</div><div class="line">    26,120,077,275      instructions              #    3.57  insns per cycle          (32.28%)</div><div class="line">     7,316,568,954      ref-cycles                # 2477.649 M/sec                    (35.86%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                10      context-switches          #    0.003 K/sec</div><div class="line">       2953.027151      cpu-clock (msec)</div><div class="line">                 3      cpu-migrations            #    0.001 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               370      minor-faults              #    0.125 K/sec</div><div class="line">               370      page-faults               #    0.125 K/sec</div><div class="line">       2953.029425      task-clock (msec)         #    1.001 CPUs utilized</div><div class="line">        73,778,174      L1-dcache-load-misses     #    8.94% of all L1-dcache hits    (625801033059.49%)</div><div class="line">       825,038,324      L1-dcache-loads           #  279.387 M/sec                    (625693600466.98%)</div><div class="line">             6,137      L1-dcache-stores          #    0.002 M/sec                    (625693600466.94%)</div><div class="line">           339,275      L1-icache-load-misses     #    0.115 M/sec                    (625693600466.87%)</div><div class="line">             7,611      LLC-load-misses           #   52.34% of all LL-cache hits     (625693600466.22%)</div><div class="line">            14,542      LLC-loads                 #    0.005 M/sec                    (625693600466.18%)</div><div class="line">               975      LLC-store-misses          #    0.330 K/sec                    (625718826721.74%)</div><div class="line">            28,542      LLC-stores                #    0.010 M/sec                    (7.17%)</div><div class="line">           150,256      branch-load-misses        #    0.051 M/sec                    (10.75%)</div><div class="line">     3,260,765,171      branch-loads              # 1104.210 M/sec                    (14.33%)</div><div class="line">                84      dTLB-load-misses          #    0.00% of all dTLB cache hits   (17.91%)</div><div class="line">     2,177,927,665      dTLB-loads                #  737.523 M/sec                    (21.48%)</div><div class="line">                 0      dTLB-store-misses         #    0.000 K/sec                    (25.05%)</div><div class="line">            12,502      dTLB-stores               #    0.004 M/sec                    (28.62%)</div><div class="line">                10      iTLB-load-misses          #    5.62% of all iTLB cache hits   (28.61%)</div><div class="line">               178      iTLB-loads                #    0.060 K/sec                    (28.60%)</div><div class="line">            14,538      node-load-misses          #    0.005 M/sec                    (28.59%)</div><div class="line">             1,527      node-loads                #    0.517 K/sec                    (28.62%)</div><div class="line">             2,339      node-store-misses         #    0.792 K/sec                    (7.18%)</div><div class="line">                 0      node-stores               #    0.000 K/sec                    (7.14%)</div></pre></td></tr></table></figure>
<p>可以看到 O3 优化后是否排序执行时间差不多，并且都比没有 O3 前的快几倍，指令数较优化前基本不变。</p>
<p>最明显的是排序前的 branch-load-misses 几乎都被优化掉了，这也导致 IPC 从0.41 提升到了3.59</p>
<h3 id="aarch64-M710-1"><a href="#aarch64-M710-1" class="headerlink" title="aarch64 M710"></a>aarch64 M710</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-icache-load-misses,L1-icache-loads,LLC-load-misses,LLC-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads  ./beforesort</div><div class="line">1.19468</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">           178,045      branch-misses                                                 (29.84%)</div><div class="line">     3,290,281,574      bus-cycles                # 2748.321 M/sec                    (29.84%)</div><div class="line">       204,017,139      cache-misses              #   24.768 % of all cache refs      (29.84%)</div><div class="line">       823,700,482      cache-references          #  688.024 M/sec                    (29.84%)</div><div class="line">     3,290,247,311      cpu-cycles                #    2.748 GHz                      (34.85%)</div><div class="line">     5,730,855,778      instructions              #    1.74  insn per cycle</div><div class="line">                                                  #    0.26  stalled cycles per insn  (34.85%)</div><div class="line">     1,485,014,712      stalled-cycles-backend    #   45.13% backend cycles idle      (35.03%)</div><div class="line">           980,441      stalled-cycles-frontend   #    0.03% frontend cycles idle     (35.08%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">                 2      context-switches          #    0.002 K/sec</div><div class="line">          1,197.20 msec cpu-clock                 #    1.000 CPUs utilized</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               140      minor-faults              #    0.117 K/sec</div><div class="line">               140      page-faults               #    0.117 K/sec</div><div class="line">          1,197.20 msec task-clock                #    1.000 CPUs utilized</div><div class="line">       205,399,817      L1-dcache-load-misses     #   25.00% of all L1-dcache accesses  (35.08%)</div><div class="line">       821,607,081      L1-dcache-loads           #  686.276 M/sec                    (35.08%)</div><div class="line">            10,361      L1-icache-load-misses     #    0.00% of all L1-icache accesses  (35.08%)</div><div class="line">     1,150,511,080      L1-icache-loads           #  961.004 M/sec                    (30.07%)</div><div class="line">             6,275      LLC-load-misses           #    0.00% of all LL-cache accesses  (30.07%)</div><div class="line">                 0      LLC-loads                 #    0.000 K/sec                    (30.07%)</div><div class="line">           103,368      branch-load-misses        #    0.086 M/sec                    (30.07%)</div><div class="line">       821,524,106      branch-loads              #  686.206 M/sec                    (30.07%)</div><div class="line">            15,315      dTLB-load-misses          #    0.00% of all dTLB cache accesses  (30.07%)</div><div class="line">       821,589,564      dTLB-loads                #  686.261 M/sec                    (30.07%)</div><div class="line">             1,084      iTLB-load-misses          #    0.07% of all iTLB cache accesses  (30.07%)</div><div class="line">         1,613,786      iTLB-loads                #    1.348 M/sec                    (29.89%)</div><div class="line"></div><div class="line"></div><div class="line">#perf stat -e branch-misses,bus-cycles,cache-misses,cache-references,cpu-cycles,instructions,stalled-cycles-backend,stalled-cycles-frontend,alignment-faults,bpf-output,context-switches,cpu-clock,cpu-migrations,dummy,emulation-faults,major-faults,minor-faults,page-faults,task-clock,L1-dcache-load-misses,L1-dcache-loads,L1-icache-load-misses,L1-icache-loads,LLC-load-misses,LLC-loads,branch-load-misses,branch-loads,dTLB-load-misses,dTLB-loads,iTLB-load-misses,iTLB-loads  ./aftersort</div><div class="line">1.1949</div><div class="line">sum = 314931600000</div><div class="line"></div><div class="line">           656,175      branch-misses                                                 (29.91%)</div><div class="line">     3,293,615,450      bus-cycles                # 2748.397 M/sec                    (29.91%)</div><div class="line">       203,683,518      cache-misses              #   24.631 % of all cache refs      (29.91%)</div><div class="line">       826,934,774      cache-references          #  690.046 M/sec                    (29.91%)</div><div class="line">     3,293,560,111      cpu-cycles                #    2.748 GHz                      (34.92%)</div><div class="line">     5,732,241,288      instructions              #    1.74  insn per cycle</div><div class="line">                                                  #    0.29  stalled cycles per insn  (34.91%)</div><div class="line">     1,645,938,192      stalled-cycles-backend    #   49.97% backend cycles idle      (35.00%)</div><div class="line">         1,757,056      stalled-cycles-frontend   #    0.05% frontend cycles idle     (35.05%)</div><div class="line">                 0      alignment-faults          #    0.000 K/sec</div><div class="line">                 0      bpf-output                #    0.000 K/sec</div><div class="line">                 2      context-switches          #    0.002 K/sec</div><div class="line">          1,198.38 msec cpu-clock                 #    1.000 CPUs utilized</div><div class="line">                 0      cpu-migrations            #    0.000 K/sec</div><div class="line">                 0      dummy                     #    0.000 K/sec</div><div class="line">                 0      emulation-faults          #    0.000 K/sec</div><div class="line">                 0      major-faults              #    0.000 K/sec</div><div class="line">               137      minor-faults              #    0.114 K/sec</div><div class="line">               137      page-faults               #    0.114 K/sec</div><div class="line">          1,198.38 msec task-clock                #    1.000 CPUs utilized</div><div class="line">       205,557,180      L1-dcache-load-misses     #   25.00% of all L1-dcache accesses  (35.05%)</div><div class="line">       822,366,213      L1-dcache-loads           #  686.233 M/sec                    (35.04%)</div><div class="line">            12,708      L1-icache-load-misses     #    0.00% of all L1-icache accesses  (35.05%)</div><div class="line">       987,422,733      L1-icache-loads           #  823.967 M/sec                    (30.04%)</div><div class="line">             6,234      LLC-load-misses           #    0.00% of all LL-cache accesses  (30.04%)</div><div class="line">                 0      LLC-loads                 #    0.000 K/sec                    (30.04%)</div><div class="line">           103,635      branch-load-misses        #    0.086 M/sec                    (30.04%)</div><div class="line">       822,357,251      branch-loads              #  686.226 M/sec                    (30.04%)</div><div class="line">            13,961      dTLB-load-misses          #    0.00% of all dTLB cache accesses  (30.04%)</div><div class="line">       822,374,897      dTLB-loads                #  686.241 M/sec                    (30.04%)</div><div class="line">               709      iTLB-load-misses          #    0.05% of all iTLB cache accesses  (30.04%)</div><div class="line">         1,562,083      iTLB-loads                #    1.303 M/sec                    (29.96%)</div></pre></td></tr></table></figure>
<p>可以看到在M710上开启 O3 优化后是否排序执行时间差不多，并且都比没有 O3 前</p>
<p>的快几倍，最明显的是指令数只有之前的7%。另外就是排序前的 branch-load-misses 几乎都被优化掉了，虽然这里 IPC 提升不大但主要在指令数的减少上。</p>
<p>O3意味着代码尽可能展开，更长的代码意味着对 L1i（以及 L2和更高级别）高速缓存的压力更高。这会导致性能降低。更短的代码可以运行得更快。幸运的是，gcc 有一个优化选项可以指定此项。如果使用-Os，则编译器将优化代码大小。使用后，能够增加代码大小的哪些优化将被禁用。使用此选项通常会产生令人惊讶的结果。特别是循环展开和内联没有实质优势时，那么此选项将是一个很好的选择。</p>
<h2 id="分支预测原理介绍"><a href="#分支预测原理介绍" class="headerlink" title="分支预测原理介绍"></a>分支预测原理介绍</h2><p><img src="/images/951413iMgBlog/v2-475f184ea376484878515491a120bf49_1440w.png" alt="img"></p>
<p>如上图的上面部分代表通常情况下的简单代码布局。如果区域 B（这里是内联函数 inlfct 生成的代码）经常由于条件 I 被跳过，而不会执行，处理器的预取将拉入很少使用的包含块 B 的高速缓存行。使用块重新排序可以改变这种局面，改变之后的效果可以在图的下半部分看到。经常执行的代码在内存中是线性的，而很少执行的代码被移动到不会损害预取和 L1i 效率的位置。</p>
<h2 id="Linux内核流水线优化案例"><a href="#Linux内核流水线优化案例" class="headerlink" title="Linux内核流水线优化案例"></a>Linux内核流水线优化案例</h2><p>在Linux Kernel中有大量的 likely/unlikely</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ip 层收到消息后，如果是tcp就调用tcp_v4_rcv作为tcp协议的入口</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_v4_rcv</span><span class="params">(struct sk_buff *skb)</span></span></div><div class="line">&#123;</div><div class="line">  ...</div><div class="line">	<span class="keyword">if</span> (unlikely(th-&gt;doff &lt; <span class="keyword">sizeof</span>(struct tcphdr) / <span class="number">4</span>))</div><div class="line">		<span class="keyword">goto</span> bad_packet; <span class="comment">//概率很小</span></div><div class="line">	<span class="keyword">if</span> (!pskb_may_pull(skb, th-&gt;doff * <span class="number">4</span>))</div><div class="line">		<span class="keyword">goto</span> discard_it;</div><div class="line">  </div><div class="line"><span class="comment">//file: net/ipv4/tcp_input.c</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_rcv_established</span><span class="params">(struct sock *sk, ...)</span></span></div><div class="line">&#123;</div><div class="line"> <span class="keyword">if</span> (unlikely(sk-&gt;sk_rx_dst == <span class="literal">NULL</span>))</div><div class="line">  ......</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//file: include/linux/compiler.h</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> likely(x)   __builtin_expect(!!(x),1)</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> unlikely(x) __builtin_expect(!!(x),0)</span></div></pre></td></tr></table></figure>
<p>__builtin_expect 这个指令是 gcc 引入的。该函数作用是允许程序员将最有可能执行的分支告诉编译器，来辅助系统进行分支预测。(参见 <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html" target="_blank" rel="external">https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html</a>)</p>
<p>它的用法为：__builtin_expect(EXP, N)。意思是：EXP == N的概率很大。那么上面 likely 和 unlikely 这两句的具体含义就是：</p>
<ul>
<li><strong>builtin_expect(!!(x),1) x 为真的可能性更大  //0两次取反还是0，非0两次取反都是1，这样可以适配</strong>builtin_expect(EXP, N)的N，要不N的参数没法传</li>
<li>__builtin_expect(!!(x),0) x 为假的可能性更大</li>
</ul>
<p>当正确地使用了__builtin_expect后，编译器在编译过程中会根据程序员的指令，将可能性更大的代码紧跟着前面的代码，从而减少指令跳转带来的性能上的下降。让L1i中加载的代码尽量有效紧凑</p>
<p>这样可以让 CPU流水线分支预测的时候默认走可能性更大的分支。如果分支预测错误所有流水线都要取消重新计算。</p>
<p>如果程序员利用这些宏，然后使用 <code>-freorder-blocks</code> 优化选项，则 gcc 将对块进行重新排序，如原理解图所示。该选项在 -O 2中启用，但在-Os 中禁用。还有另一种对块进行重新排序的选项（<code>-freorder-blocks-and-partition</code> ），但是它的用处有限，因为它不适用于异常处理。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>不排序的代码(分支极难预测正确)运行数据对比：</p>
<table>
<thead>
<tr>
<th></th>
<th>branch-load-misses/branch-loads</th>
<th>instructions</th>
<th>IPC</th>
<th>耗时(秒)</th>
<th>排序后耗时(秒)</th>
</tr>
</thead>
<tbody>
<tr>
<td>鲲鹏920</td>
<td>21.7%</td>
<td>83,694,841,472</td>
<td>1.04</td>
<td>30.92</td>
<td>11.44</td>
</tr>
<tr>
<td>M710</td>
<td>8.3%</td>
<td>77,083,625,280</td>
<td>1.66</td>
<td>16.89</td>
<td>8.20</td>
</tr>
<tr>
<td>Intel 8163</td>
<td>24.4%</td>
<td>29,618,485,912</td>
<td>0.41</td>
<td>29.52</td>
<td>9.77</td>
</tr>
<tr>
<td>hygon 7260</td>
<td>11.8%</td>
<td>32,850,416,330</td>
<td>0.56</td>
<td>23.36</td>
<td>10.95</td>
</tr>
<tr>
<td>FT S2500</td>
<td>24%</td>
<td>83,872,213,462</td>
<td>1.01</td>
<td>39.8</td>
<td>16.63</td>
</tr>
</tbody>
</table>
<p>排序后的代码(分支预测容易)运行数据对比：</p>
<table>
<thead>
<tr>
<th></th>
<th>instructions</th>
<th>instructions(排序前)</th>
<th>IPC</th>
<th>耗时(秒)</th>
</tr>
</thead>
<tbody>
<tr>
<td>鲲鹏920</td>
<td>83,666,813,837</td>
<td>83,694,841,472</td>
<td>2.82</td>
<td>11.44</td>
</tr>
<tr>
<td>M710</td>
<td>77,068,271,833</td>
<td>77,083,625,280</td>
<td>3.42</td>
<td>8.20</td>
</tr>
<tr>
<td>Intel 8163</td>
<td>29,491,804,977</td>
<td>29,618,485,912</td>
<td>1.22</td>
<td>9.77</td>
</tr>
<tr>
<td>hygon 7260</td>
<td>32,785,270,866</td>
<td>32,850,416,330</td>
<td>1.20</td>
<td>10.95</td>
</tr>
<tr>
<td>FT S2500</td>
<td>83,918,069,835</td>
<td>83,872,213,462</td>
<td>2.41</td>
<td>16.63</td>
</tr>
</tbody>
</table>
<ul>
<li>所有 CPU 都期望对分支预测友好的代码</li>
<li>分支预测重点关注 perf branch-load-misses/branch-loads</li>
<li>aarch64 较 x86_64 指令数是2.6倍，同时对流水线更友好，也就是 IPC 更高(2.6倍)，测试代码单线程、无锁</li>
<li>M710的分支预测正确率是鲲鹏920、intel的3倍，hygon 是鲲鹏 、intel的分支预测率的2倍</li>
<li>10% 的分支load miss 会带来一倍的性能差异</li>
<li>gcc O3 优化效果很明显，代价就是代码展开后很大，容易造成icache不够，对小段测试代码效果最好，实践不一定</li>
<li>测试代码只是极简场景，实际生产环境更复杂，也就是预测效果不会这么明显</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;比较不同CPU下的分支预测&quot;&gt;&lt;a href=&quot;#比较不同CPU下的分支预测&quot; class=&quot;headerlink&quot; title=&quot;比较不同CPU下的分支预测&quot;&gt;&lt;/a&gt;比较不同CPU下的分支预测&lt;/h1&gt;&lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; cla
    
    </summary>
    
      <category term="CPU" scheme="https://plantegg.github.io/categories/CPU/"/>
    
    
      <category term="CPU" scheme="https://plantegg.github.io/tags/CPU/"/>
    
      <category term="perf" scheme="https://plantegg.github.io/tags/perf/"/>
    
      <category term="IPC" scheme="https://plantegg.github.io/tags/IPC/"/>
    
      <category term="branch_miss" scheme="https://plantegg.github.io/tags/branch-miss/"/>
    
  </entry>
  
</feed>
