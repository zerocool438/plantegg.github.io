<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Linux,LVS,network," />





  <link rel="alternate" href="/atom.xml" title="plantegg" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="长连接黑洞重现和分析这是一个存在多年，遍及各个不同的业务又反反复复地在集团内部出现的一个问题，本文先通过重现展示这个问题，然后从业务、数据库、OS等不同的角度来分析如何解决它，这个问题值得每一位研发同学重视起来，避免再次踩到 背景为了高效率应对故障，本文尝试回答如下一些问题：  为什么数据库crash 重启恢复后，业务还长时间不能恢复？ 我依赖的业务做了高可用切换，但是我的业务长时间报错 我依赖的">
<meta name="keywords" content="Linux,LVS,network">
<meta property="og:type" content="article">
<meta property="og:title" content="长连接黑洞重现和分析">
<meta property="og:url" content="https://plantegg.github.io/2024/05/05/长连接黑洞重现和分析/index.html">
<meta property="og:site_name" content="plantegg">
<meta property="og:description" content="长连接黑洞重现和分析这是一个存在多年，遍及各个不同的业务又反反复复地在集团内部出现的一个问题，本文先通过重现展示这个问题，然后从业务、数据库、OS等不同的角度来分析如何解决它，这个问题值得每一位研发同学重视起来，避免再次踩到 背景为了高效率应对故障，本文尝试回答如下一些问题：  为什么数据库crash 重启恢复后，业务还长时间不能恢复？ 我依赖的业务做了高可用切换，但是我的业务长时间报错 我依赖的">
<meta property="og:image" content="https://plantegg.github.io/images/951413iMgBlog/1713838496899-274cdfbd-aa6e-4f1f-9fcc-16725593c25e.png">
<meta property="og:updated_time" content="2024-05-05T01:24:42.901Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="长连接黑洞重现和分析">
<meta name="twitter:description" content="长连接黑洞重现和分析这是一个存在多年，遍及各个不同的业务又反反复复地在集团内部出现的一个问题，本文先通过重现展示这个问题，然后从业务、数据库、OS等不同的角度来分析如何解决它，这个问题值得每一位研发同学重视起来，避免再次踩到 背景为了高效率应对故障，本文尝试回答如下一些问题：  为什么数据库crash 重启恢复后，业务还长时间不能恢复？ 我依赖的业务做了高可用切换，但是我的业务长时间报错 我依赖的">
<meta name="twitter:image" content="https://plantegg.github.io/images/951413iMgBlog/1713838496899-274cdfbd-aa6e-4f1f-9fcc-16725593c25e.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://plantegg.github.io/2024/05/05/长连接黑洞重现和分析/"/>





  <title>长连接黑洞重现和分析 | plantegg</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">plantegg</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">java tcp mysql performance network docker Linux</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://plantegg.github.io/2024/05/05/长连接黑洞重现和分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="twitter @plantegg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="plantegg">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">长连接黑洞重现和分析</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-05-05T08:30:03+08:00">
                2024-05-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/network/" itemprop="url" rel="index">
                    <span itemprop="name">network</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="长连接黑洞重现和分析"><a href="#长连接黑洞重现和分析" class="headerlink" title="长连接黑洞重现和分析"></a>长连接黑洞重现和分析</h1><p>这是一个存在多年，遍及各个不同的业务又反反复复地在集团内部出现的一个问题，本文先通过重现展示这个问题，然后从业务、数据库、OS等不同的角度来分析如何解决它，这个问题值得每一位研发同学重视起来，避免再次踩到</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了高效率应对故障，本文尝试回答如下一些问题：</p>
<ul>
<li>为什么数据库crash 重启恢复后，业务还长时间不能恢复？</li>
<li>我依赖的业务做了高可用切换，但是我的业务长时间报错</li>
<li>我依赖的服务下掉了一个节点，为什么我的业务长时间报错 </li>
<li>客户做变配，升级云服务节点规格，为什么会导致客户业务长时间报错</li>
</ul>
<p>目的：希望通过这篇文章尽可能地减少故障时长、让业务快速从故障中恢复</p>
<h2 id="重现"><a href="#重现" class="headerlink" title="重现"></a>重现</h2><p>空说无凭，先也通过一次真实的重现来展示这个问题</p>
<h3 id="LVS-MySQL-高可用切换"><a href="#LVS-MySQL-高可用切换" class="headerlink" title="LVS+MySQL 高可用切换"></a>LVS+MySQL 高可用切换</h3><p>OS 默认配置参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#sysctl -a |grep -E &quot;tcp_retries|keepalive&quot;</div><div class="line">net.ipv4.tcp_keepalive_intvl = 30</div><div class="line">net.ipv4.tcp_keepalive_probes = 5</div><div class="line">net.ipv4.tcp_keepalive_time = 10</div><div class="line">net.ipv4.tcp_retries1 = 3</div><div class="line">net.ipv4.tcp_retries2 = 15  //主要是这个参数，默认以及alios 几乎都是15</div></pre></td></tr></table></figure>
<p>LVS 对外服务端口是3001， 后面挂的是 3307，假设3307是当前的Master，Slave是 3306，当检测到3307异常后会从LVS 上摘掉 3307挂上 3306做高可用切换</p>
<p><img src="/images/951413iMgBlog/1713838496899-274cdfbd-aa6e-4f1f-9fcc-16725593c25e.png" alt="undefined">  </p>
<p>切换前的 LVS 状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">#ipvsadm -L --timeout</div><div class="line">Timeout (tcp tcpfin udp): 900 120 300</div><div class="line">#ipvsadm -L -n</div><div class="line">IP Virtual Server version 1.2.1 (size=4096)</div><div class="line">Prot LocalAddress:Port Scheduler Flags</div><div class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</div><div class="line">TCP  127.0.0.1:3001 rr</div><div class="line">  -&gt; 127.0.0.1:3307               Masq    1      0          0</div></pre></td></tr></table></figure>
<p>Sysbench启动压力模拟用户访问，在 31秒的时候模拟管控检测到 3307的Master无法访问，所以管控执行切主把 3306的Slave 提升为新的 Master，同时到 LVS 摘掉 3307，挂上3306，此时管控端着冰可乐、翘着二郎腿，得意地说，你就看吧我们管控牛逼不、我们的高可用牛逼不，这一套行云流水3秒钟不到全搞定</p>
<p>切换命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#cat del3307.sh</div><div class="line">ipvsadm -d -t  127.0.0.1:3001 -r 127.0.0.1:3307 ; ipvsadm -a -t  127.0.0.1:3001 -r 127.0.0.1:3306 -m</div></pre></td></tr></table></figure>
<p>此时Sysbench运行状态，在第 32秒如期跌0：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">#/usr/local/bin/sysbench --debug=on --mysql-user=&apos;root&apos; --mysql-password=&apos;123&apos; --mysql-db=&apos;test&apos; --mysql-host=&apos;127.0.0.1&apos; --mysql-port=&apos;3001&apos; --tables=&apos;16&apos;  --table-size=&apos;10000&apos; --range-size=&apos;5&apos; --db-ps-mode=&apos;disable&apos; --skip-trx=&apos;on&apos; --mysql-ignore-errors=&apos;all&apos; --time=&apos;11080&apos; --report-interval=&apos;1&apos; --histogram=&apos;on&apos; --threads=1 oltp_read_write run</div><div class="line">sysbench 1.1.0 (using bundled LuaJIT 2.1.0-beta3)</div><div class="line"></div><div class="line">Running the test with following options:</div><div class="line">Number of threads: 1</div><div class="line">Report intermediate results every 1 second(s)</div><div class="line">Debug mode enabled.</div><div class="line"></div><div class="line">Initializing random number generator from current time</div><div class="line"></div><div class="line"></div><div class="line">Initializing worker threads...</div><div class="line"></div><div class="line">DEBUG: Worker thread (#0) started</div><div class="line">DEBUG: Reporting thread started</div><div class="line">DEBUG: Worker thread (#0) initialized</div><div class="line">Threads started!</div><div class="line"></div><div class="line">[ 1s ] thds: 1 tps: 51.89 qps: 947.00 (r/w/o: 739.44/207.56/0.00) lat (ms,95%): 35.59 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 2s ] thds: 1 tps: 60.03 qps: 1084.54 (r/w/o: 841.42/243.12/0.00) lat (ms,95%): 22.28 err/s 0.00 reconn/s: 0.00</div><div class="line">…………</div><div class="line">[ 29s ] thds: 1 tps: 68.00 qps: 1223.01 (r/w/o: 952.00/271.00/0.00) lat (ms,95%): 16.12 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 30s ] thds: 1 tps: 66.00 qps: 1188.00 (r/w/o: 924.00/264.00/0.00) lat (ms,95%): 16.71 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 31s ] thds: 1 tps: 67.00 qps: 1203.96 (r/w/o: 937.97/265.99/0.00) lat (ms,95%): 17.95 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 32s ] thds: 1 tps: 22.99 qps: 416.85 (r/w/o: 321.88/94.96/0.00) lat (ms,95%): 15.55 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 33s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 34s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 35s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div></pre></td></tr></table></figure>
<p>5分钟后故障报告大批量涌进来，客户：怎么回事，我们的业务挂掉10分钟了，报错都是访问MySQL 超时，赶紧给我看看，从监控确实看到10分钟后客户业务还没恢复：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[ 601s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 602s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 603s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 604s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div></pre></td></tr></table></figure>
<p>这时 oncall 都被从被窝里拎了起来，不知谁说了一句赶紧恢复吧，先试试把应用重启，5秒钟后应用重启完毕，业务恢复，大家开心地笑了，又成功防御住一次故障升级，还是重启大法好！</p>
<p>在业务/Sysbench QPS跌0 期间可以看到 3307被摘掉，3306 成功挂上去了，但是没有新连接建向 3306，业务/Sysbench 使劲薅着 3307</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">#ipvsadm -L -n --stats -t 127.0.0.1:3001</div><div class="line">Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes</div><div class="line">  -&gt; RemoteAddress:Port</div><div class="line">TCP  127.0.0.1:3001                      2   660294   661999 78202968  184940K</div><div class="line">  -&gt; 127.0.0.1:3306                      0        0        0        0        0</div><div class="line">  </div><div class="line">#ipvsadm -Lcn | head -10</div><div class="line">IPVS connection entries</div><div class="line">pro expire state       source             virtual            destination</div><div class="line">TCP 13:11  ESTABLISHED 127.0.0.1:33864    127.0.0.1:3001     127.0.0.1:3307</div><div class="line"></div><div class="line">#netstat -anto |grep -E &quot;Recv|33864|3001|33077&quot;</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       Timer</div><div class="line">tcp        0    248 127.0.0.1:33864         127.0.0.1:3001          ESTABLISHED probe (33.48/0/8)</div><div class="line">tcp6       0     11 127.0.0.1:3307          127.0.0.1:33864         ESTABLISHED on (49.03/13/0)</div></pre></td></tr></table></figure>
<p>直到 900多秒后 OS 重试了15次发现都失败，于是向业务/Sysbench 返回连接异常，触发业务/Sysbench 释放异常连接重建新连接，新连接指向了新的 Master 3306，业务恢复正常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[ 957s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">DEBUG: Ignoring error 2013 Lost connection to MySQL server during query,</div><div class="line">DEBUG: Reconnecting </div><div class="line">DEBUG: Reconnected</div><div class="line">[ 958s ] thds: 1 tps: 53.00 qps: 950.97 (r/w/o: 741.98/208.99/0.00) lat (ms,95%): 30.26 err/s 0.00 reconn/s: 1.00</div><div class="line">[ 959s ] thds: 1 tps: 64.00 qps: 1154.03 (r/w/o: 896.02/258.01/0.00) lat (ms,95%): 22.69 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 960s ] thds: 1 tps: 66.00 qps: 1184.93 (r/w/o: 923.94/260.98/0.00) lat (ms,95%): 25.28 err/s 0.00 reconn/s: 0.00</div></pre></td></tr></table></figure>
<p>到这里重现了故障中经常碰到的业务需要900多秒才能慢慢恢复，这个问题也就是 <strong>TCP 长连接流量黑洞</strong></p>
<p>如果我们<strong>把 net.ipv4.tcp_retries2 改成5</strong> 再来做这个实验，就会发现业务/Sysbench 只需要20秒就能恢复了，也就是这个流量黑洞从900多秒变成了20秒，这回 oncall 不用再被从被窝里拎出来了吧：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">[ 62s ] thds: 1 tps: 66.00 qps: 1191.00 (r/w/o: 924.00/267.00/0.00) lat (ms,95%): 17.63 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 63s ] thds: 1 tps: 63.00 qps: 1123.01 (r/w/o: 874.00/249.00/0.00) lat (ms,95%): 17.63 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 64s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 65s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 66s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 67s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 68s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 69s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 70s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 71s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 72s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 73s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 74s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 75s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 76s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 77s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 78s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 79s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 80s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 81s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 82s ] thds: 1 tps: 0.00 qps: 0.00 (r/w/o: 0.00/0.00/0.00) lat (ms,95%): 0.00 err/s 0.00 reconn/s: 0.00</div><div class="line">DEBUG: Ignoring error 2013 Lost connection to MySQL server during query,</div><div class="line">DEBUG: Reconnecting </div><div class="line">DEBUG: Reconnected</div><div class="line">[ 83s ] thds: 1 tps: 26.00 qps: 457.01 (r/w/o: 357.01/100.00/0.00) lat (ms,95%): 16.41 err/s 0.00 reconn/s: 1.00</div><div class="line">[ 84s ] thds: 1 tps: 60.00 qps: 1086.94 (r/w/o: 846.96/239.99/0.00) lat (ms,95%): 26.68 err/s 0.00 reconn/s: 0.00</div><div class="line">[ 85s ] thds: 1 tps: 63.00 qps: 1134.02 (r/w/o: 882.01/252.00/0.00) lat (ms,95%): 23.10 err/s 0.00 reconn/s: 0.00</div></pre></td></tr></table></figure>
<h3 id="LVS-Nginx-上重现"><a href="#LVS-Nginx-上重现" class="headerlink" title="LVS + Nginx 上重现"></a>LVS + Nginx 上重现</h3><p>NGINX上重现这个问题：<a href="https://asciinema.org/a/649890" target="_blank" rel="external">https://asciinema.org/a/649890</a> 3分钟的录屏，这个视频构造了一个LVS 的HA切换过程，LVS后有两个Nginx，模拟一个Nginx(Master) 断网后，将第二个Nginx(Slave) 加入到LVS 并将第一个Nginx(Master) 从LVS 摘除，期望业务能立即恢复，但实际上可以看到之前的所有长连接都没有办法恢复，进入一个流量黑洞</p>
<h2 id="TCP-长连接流量黑洞原理总结"><a href="#TCP-长连接流量黑洞原理总结" class="headerlink" title="TCP 长连接流量黑洞原理总结"></a>TCP 长连接流量黑洞原理总结</h2><p>TCP 长连接在发送包的时候，如果没收到ack 默认会进行15次重传(net.ipv4.tcp_retries2=15, 这个不要较真，会根据RTO 时间大致是15次)，累加起来大概是924秒，所以我们经常看到业务需要15分钟左右才恢复。这个问题存在所有TCP长连接中(几乎没有业务还在用短连接吧？)，问题的本质和 LVS/k8s Service 都没关系</p>
<p>我这里重现带上 LVS 只是为了场景演示方便 </p>
<p>这个问题的本质就是如果Server突然消失(宕机、断网，来不及发 RST )客户端如果正在发东西给Server就会遵循TCP 重传逻辑不断地TCP retran , 如果一直收不到Server 的ack，大约重传15次，900秒左右。所以不是因为有 LVS 导致了这个问题，而是在某些场景下 LVS 有能力处理得更优雅，比如删除 RealServer的时候 LVS 完全可以感知这个动作并 reset 掉其上所有长连接</p>
<p>为什么在<a href="https://ata.atatech.org/articles/11000232868" target="_blank" rel="external">K8S 上这个问题更明显</a>呢，K8S 讲究的就是服务不可靠，随时干掉POD(切断网络），如果干POD 之前能kill -9(触发reset)、或者close 业务触发断开连接那还好，但是大多时候啥都没干，有强摘POD、有直接隔离等等，这些操作都会导致对端只能TCP retran</p>
<h2 id="怎么解决"><a href="#怎么解决" class="headerlink" title="怎么解决"></a>怎么解决</h2><h3 id="业务方"><a href="#业务方" class="headerlink" title="业务方"></a>业务方</h3><p>业务方要对自己的请求超时时间有控制和兜底，不能任由一个请求长时间 Hang 在那里</p>
<p>比如JDBC URL 支持设置 SocketTimeout、ConnectTimeout，我相信其他产品也有类似的参数，业务方要设置这些值，不设置就是如上重现里演示的900多秒后才恢复</p>
<h4 id="SocketTimeout"><a href="#SocketTimeout" class="headerlink" title="SocketTimeout"></a>SocketTimeout</h4><p>只要是连接有机会设置 SocketTimeout 就一定要设置，具体值可以根据你们能接受的慢查询来设置；分析、AP类的请求可以设置大一点</p>
<p><strong>最重要的：任何业务只要你用到了TCP 长连接一定要配置一个恰当的SocketTimeout</strong>，比如 Jedis 是连接池模式，底层超时之后，会销毁当前连接，下一次重新建连，就会连接到新的切换节点上去并恢复</p>
<h4 id="RFC-5482-TCP-USER-TIMEOUT"><a href="#RFC-5482-TCP-USER-TIMEOUT" class="headerlink" title="RFC 5482 TCP_USER_TIMEOUT"></a><a href="https://datatracker.ietf.org/doc/html/rfc5482" target="_blank" rel="external">RFC 5482</a> <code>TCP_USER_TIMEOUT</code></h4><p><a href="https://datatracker.ietf.org/doc/html/rfc5482" target="_blank" rel="external">RFC 5482</a> 中增加了<code>TCP_USER_TIMEOUT</code>这个配置，通常用于定制当 TCP 网络连接中出现数据传输问题时，可以等待多长时间前释放网络资源，对应Linux 这个 <a href="https://github.com/torvalds/linux/commit/dca43c75e7e545694a9dd6288553f55c53e2a3a3" target="_blank" rel="external">commit </a></p>
<p><code>TCP_USER_TIMEOUT</code> 是一个整数值，它指定了当 TCP 连接的数据包在发送后多长时间内未被确认（即没有收到 ACK），TCP 连接会考虑释放这个连接。</p>
<p>打个比方，设置 <code>TCP_USER_TIMEOUT</code> 后，应用程序就可以指定说：“如果在 30 秒内我发送的数据没有得到确认，那我就认定网络连接出了问题，不再尝试继续发送，而是直接断开连接。”这对于确保连接质量和维护用户体验是非常有帮助的。</p>
<p>在 Linux 中，可以使用 <code>setsockopt</code> 函数来设置某个特定 socket 的 <code>TCP_USER_TIMEOUT</code> 值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">int timeout = 30000; // 30 seconds</div><div class="line">setsockopt(sock, IPPROTO_TCP, TCP_USER_TIMEOUT, (char *)&amp;timeout, sizeof(timeout));</div></pre></td></tr></table></figure>
<p>在这行代码中，<code>sock</code> 是已经 established 的 TCP socket，我们将该 socket 的 <code>TCP_USER_TIMEOUT</code> 设置为 30000 毫秒，也就是 30 秒。如果设置成功，这个 TCP 连接在发送数据包后 30 秒内如果没有收到 ACK 确认，将开始进行 TCP 连接的释放流程。</p>
<p>TCP_USER_TIMEOUT 相较 SocketTimeout 可以做到更精确(不影响慢查询)，SocketTimeout 超时是不区分ACK 还是请求响应时间的，但是 TCP_USER_TIMEOUT 要求下层的API、OS 都支持。比如 JDK 不支持 TCP_USER_TIMEOUT，但是 <a href="https://github.com/tomasol/netty/commit/3010366d957d7b8106e353f99e15ccdb7d391d8f#diff-a998f73b7303461ca171432d10832884c6e7b0955d9f5634b9a8302b42a4706c" target="_blank" rel="external">Netty 框架自己搞了Native</a> 来实现对 TCP_USER_TIMEOUT 以及其它OS 参数的设置，在这些基础上<a href="https://github.com/redis/lettuce/pull/2499" target="_blank" rel="external">Redis 的Java 客户端 lettuce 依赖了 Netty ，所以也可以设置 TCP_USER_TIMEOUT</a></p>
<p>原本我是想在Druid 上提个feature 来支持 TCP_USER_TIMEOUT，这样集团绝大部分业务都可以无感知解决掉这个问题，但查下来发现 JDK 不支持设置这个值，想要在Druid 里面实现设置 TCP_USER_TIMEOUT 的话，得像 Netty 一样走Native 绕过JDK 来设置，这对 Druid 而言有点重了</p>
<h4 id="ConnectTimeout"><a href="#ConnectTimeout" class="headerlink" title="ConnectTimeout"></a>ConnectTimeout</h4><p>这个值是针对新连接创建超时时间设置，一般设置3-5秒就够长了</p>
<h4 id="连接池"><a href="#连接池" class="headerlink" title="连接池"></a>连接池</h4><p>建议参考这篇 <a href="https://ata.atatech.org/articles/11020180004" target="_blank" rel="external">《数据库连接池配置推荐》</a>  这篇里的很多建议也适合业务、应用等，你把数据库看成一个普通服务就好理解了</p>
<p>补充下如果用的是Druid 数据库连接池不要用它来设置你的  SocketTimeout 参数，因为他有bug 导致你觉得设置了但实际没设置上，<a href="https://github.com/alibaba/druid/releases/tag/1.2.22" target="_blank" rel="external">2024-03-16号的1.2.22</a>这个Release 才fix，所以强烈建议你讲 SocketTimeout 写死在JDBC URL 中简单明了</p>
<h3 id="OS-兜底"><a href="#OS-兜底" class="headerlink" title="OS 兜底"></a>OS 兜底</h3><p>假如业务是一个AP查询/一次慢请求，一次查询/请求就是需要半个小时，将 SocketTimeout 设置太小影响正常的查询，那么可以将如下 OS参数改小，从 OS 层面进行兜底</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">net.ipv4.tcp_retries2 = 8</div><div class="line">net.ipv4.tcp_syn_retries = 4</div></pre></td></tr></table></figure>
<h4 id="keepalive"><a href="#keepalive" class="headerlink" title="keepalive"></a>keepalive</h4><p>keepalive 默认 7200秒太长了，建议改成20秒，可以在OS 镜像层面固化，然后各个业务可以 patch 自己的值；</p>
<p>如果一条连接限制超过 900 秒 LVS就会Reset 这条连接，但是我们将keepalive 设置小于900秒的话，即使业务上一直闲置，因为有 keepalive 触发心跳包，让 LVS 不至于 Reset，这也就避免了当业务取连接使用的时候才发现连接已经不可用被断开了，往往这个时候业务抛错误的时间很和真正 Reset 时间还差了很多，不好排查</p>
<p>在触发 TCP retransmission 后会停止 keepalive 探测</p>
<h3 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a>LVS</h3><p>作为一个负责任的云厂商，肯定要有担当，不能把所有问题都推给客户/业务，所以 LVS 也做了升级，当摘除节点的时候支持你设置一个时间，过了这个时间 LVS 就会向这些连接的客户端发 Reset 干掉这些流量，让客户端触发新建连接，从故障中快速恢复，这是一个实例维度的参数，建议云上所有产品都支持起来，管控可以在购买 LVS 的时候设置一个默认值：</p>
<p><a href="https://alidocs.dingtalk.com/i/nodes/Qnp9zOoBVBDEydnQUXgQGAXP81DK0g6l?utm_scene=team_space" target="_blank" rel="external">https://alidocs.dingtalk.com/i/nodes/Qnp9zOoBVBDEydnQUXgQGAXP81DK0g6l?utm_scene=team_space</a></p>
<h3 id="管控"><a href="#管控" class="headerlink" title="管控"></a>管控</h3><p>如果做高可用切换、删除节点等，最好是先强制断掉节点上所有的连接，比如 RDS 管控会遍历所有的 processlist 然后挨个 kill，怕杀不干净会循环多次杀</p>
<p>比如 PolarDB-X 会先kill -9 掉节点进程(会触发 OS 向原来的连接发 reset)，再从 LVS 摘除</p>
<p>当然最好的做法如果用了LVS 就设置 Reset时间，如果没用LVS 就主动触发 Reset </p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><h3 id="神奇的900秒"><a href="#神奇的900秒" class="headerlink" title="神奇的900秒"></a>神奇的900秒</h3><p>上面阐述的长连接流量黑洞一般是900+秒就恢复了，有时候我们经常在日志中看到 CommunicationsException: Communications link failure 900秒之类的错误，恰好 LVS 也是设置的 900秒闲置 Reset</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#ipvsadm -L --timeout</div><div class="line">Timeout (tcp tcpfin udp): 900 120 300</div></pre></td></tr></table></figure>
<h3 id="为什么这个问题这几年才明显暴露"><a href="#为什么这个问题这几年才明显暴露" class="headerlink" title="为什么这个问题这几年才明显暴露"></a>为什么这个问题这几年才明显暴露</h3><ul>
<li>工程师们混沌了几十年</li>
<li>之前因为出现频率低重启业务就糊弄过去了</li>
<li>对新连接不存在这个问题</li>
<li>有些连接池配置了Check 机制(Check机制一般几秒钟超时 fail)</li>
<li>微服务多了</li>
<li>云上 LVS 普及了</li>
<li>k8s service 大行其道</li>
</ul>
<h3 id="我用的-7层是不是就没有这个问题了？"><a href="#我用的-7层是不是就没有这个问题了？" class="headerlink" title="我用的 7层是不是就没有这个问题了？"></a>我用的 7层是不是就没有这个问题了？</h3><p>幼稚，你4层都挂了7层还能蹦跶，再说一遍只要是 TCP 长连接就有这个问题</p>
<h3 id="极端情况"><a href="#极端情况" class="headerlink" title="极端情况"></a>极端情况</h3><p>A 长连接 访问B 服务，B服务到A网络不通，假如B发生HA，一般会先Reset/断开B上所有连接(比如 MySQL 会去kill 所有processlist；比如重启MySQL——假如这里的B是MySQL)，但是因为网络不通这里的reset、fin网络包都无法到达A，所以B是无法兜底这个异常场景， A无法感知B不可用了，会使用旧连接大约15分钟</p>
<p>最可怕的是 B 服务不响应，B所在的OS 还在响应，那么在A的视角 网络是正常的，这时只能A自己来通过超时兜底</p>
<h3 id="FIN-WAIT状态下，重传一直失败，连接会怎么样？"><a href="#FIN-WAIT状态下，重传一直失败，连接会怎么样？" class="headerlink" title="FIN_WAIT状态下，重传一直失败，连接会怎么样？"></a>FIN_WAIT状态下，重传一直失败，连接会怎么样？</h3><p>为了隔离此问题，我们做了以下实验：</p>
<ul>
<li>在服务器A起了一个监听</li>
<li>在服务器B去连接监听</li>
<li>在服务器A上drop掉流量</li>
<li>在服务器B上调用socket.close()</li>
<li>观察服务器B上的socket的状态变化情况</li>
</ul>
<p>其结果是，服务器B上的socket会在FIN_WAIT1卡100s。这个100s又是怎么来的？继续Google，发现FIN_WAIT1状态下，超时时间由另外一个参数指定：tcp_orphan_retries，其值默认为0，当其值为0时，内核会将它当作8处理，重传8次累积时间为100s。</p>
<p>然而，在CentOS 6.8下，socket会在FIN_WAIT1卡14分钟，加上ESTABLISH状态的1分钟，正好15分钟，显然，它是由tcp_retries2控制的。为了验证此猜想，我们在CentOS 6.8上将tcp_retries2改成了8，然后重复了实验，发现客户端卡100s后就开始发SYN。符合预期。</p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>对于数据库团队来说要从这几个方面来控制这个问题的影响：</p>
<ul>
<li>我们自己的管控代码要设置SocketTimeout 等来做到对超时时间可控、可预期</li>
<li>高可用切换、升降配涉及到节点变换，要先断开/RST 所有老连接</li>
<li>如果从 OS 镜像层面将 tcp_retries2 值设置小一点，对超时进行兜底也是不错的方案，毕竟总有人没注意到这个问题</li>
<li>用户业务访问我们的数据库产品，可以对客户做提醒，对一些<a href="https://help.aliyun.com/zh/redis/product-overview/notice-on-lettuce-update" target="_blank" rel="external">有问题的第三方客户端SDK 要做说明</a></li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这种问题在 LVS 场景下暴露更明显了，但是又和LVS 没啥关系，任何业务长连接都会导致这个 900秒左右的流量黑洞，首先要在业务层面重视这个问题，要不以后数据库一挂掉还得重启业务才能从故障中将恢复，所以业务层面处理好了可以避免900秒黑洞和重启业务，达到快速从故障中恢复</p>
<p>再强调下这个问题如果去掉LVS/k8s Service/软负载等让两个服务直连，然后拔网线也会同样出现</p>
<p>最佳实践总结：</p>
<ul>
<li>如果你的业务支持设置 SocketTimeout 那么请一定要设置，但不一定适合分析类就是需要长时间返回的请求</li>
<li>最好的方式是设置 OS 层面的 TCP_USER_TIMEOUT 参数，只要长时间没有 ack 就报错返回，但 JDK 不支持直接设置</li>
<li>如果用了 ALB/SLB 就一定要配置 connection_drain_timeout 这个参数</li>
<li>OS 镜像层面也可以将 tcp_retries2 设置为5-10次做一个兜底</li>
<li>对你的超时时间做到可控、可预期</li>
</ul>
<h2 id="相关故障和资料"><a href="#相关故障和资料" class="headerlink" title="相关故障和资料"></a>相关故障和资料</h2><p><a href="https://aliyuque.antfin.com/apsaradb-doc/clzmlb/ke1rrdsmgu0vhl88?singleDoc#" target="_blank" rel="external">https://aliyuque.antfin.com/apsaradb-doc/clzmlb/ke1rrdsmgu0vhl88?singleDoc#</a> 《PolarDB-X 2.0变配只是秒级闪断吗？》</p>
<p><a href="https://ata.atatech.org/articles/11000244966" target="_blank" rel="external">ALB 黑洞问题详述</a> 公网版本：<a href="https://mp.weixin.qq.com/s/BJWD2V_RM2rnU1y7LPB9aw" target="_blank" rel="external">https://mp.weixin.qq.com/s/BJWD2V_RM2rnU1y7LPB9aw</a></p>
<p><a href="https://ata.atatech.org/articles/11000127589" target="_blank" rel="external">NAS前端机故障时，nfs客户端有极大的概率卡住，且恢复时间不定，最坏情况下需要重启用户ECS或者宕机的前端机恢复后客户端才能恢复</a></p>
<p>数据库故障引发的“血案” ：<a href="https://www.cnblogs.com/nullllun/p/15073022.html" target="_blank" rel="external">https://www.cnblogs.com/nullllun/p/15073022.html</a> 这篇描述较细致，推荐看看</p>
<p><a href="https://mp.weixin.qq.com/s/fBHl2XShpBpvHofYK2i6JQ" target="_blank" rel="external">线程池相关故障梳理&amp;总结</a></p>
<p><a href="https://alidocs.dingtalk.com/i/nodes/vy20BglGWOxjGpq0C92EnnRvVA7depqY?corpId=dingd8e1123006514592&amp;utm_medium=im_card&amp;cid=57137769275&amp;iframeQuery=utm_medium%3Dim_card%26utm_source%3Dim&amp;utm_scene=person_space&amp;utm_source=im" target="_blank" rel="external">20240307[S4,P4][内]Redis德国Region管控API可用率下跌</a> 管控数据库高可用切换，管控业务没设置 SocketTimeout 导致业务长时间不能恢复</p>
<p>Druid 连接池指南 <a href="https://aliyuque.antfin.com/coronadb/ydgmzl/fl154gfvw4au00ga" target="_blank" rel="external">https://aliyuque.antfin.com/coronadb/ydgmzl/fl154gfvw4au00ga</a></p>
<p>tcp_retries2 的解释：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">tcp_retries1 - INTEGER</div><div class="line">    This value influences the time, after which TCP decides, that</div><div class="line">    something is wrong due to unacknowledged RTO retransmissions,</div><div class="line">    and reports this suspicion to the network layer.</div><div class="line">    See tcp_retries2 for more details.</div><div class="line"></div><div class="line">    RFC 1122 recommends at least 3 retransmissions, which is the</div><div class="line">    default.</div><div class="line"></div><div class="line">tcp_retries2 - INTEGER</div><div class="line">    This value influences the timeout of an alive TCP connection,</div><div class="line">    when RTO retransmissions remain unacknowledged.</div><div class="line">    Given a value of N, a hypothetical TCP connection following</div><div class="line">    exponential backoff with an initial RTO of TCP_RTO_MIN would</div><div class="line">    retransmit N times before killing the connection at the (N+1)th RTO.</div><div class="line"></div><div class="line">    The default value of 15 yields a hypothetical timeout of 924.6</div><div class="line">    seconds and is a lower bound for the effective timeout.</div><div class="line">    TCP will effectively time out at the first RTO which exceeds the</div><div class="line">    hypothetical timeout.</div><div class="line"></div><div class="line">    RFC 1122 recommends at least 100 seconds for the timeout,</div><div class="line">    which corresponds to a value of at least 8.</div></pre></td></tr></table></figure>
<p>tcp_retries2 默认值为15，根据RTO的值来决定，相当于13-30分钟(RFC1122规定，必须大于100秒)，但是这是很多年前的拍下来古董参数值，现在网络条件好多了，尤其是内网，<a href="https://aone.alibaba-inc.com/v2/project/1109668/req/56150129" target="_blank" rel="external">个人认为改成 5-10 是比较恰当</a> azure 建议：<a href="https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-best-practices-connection" target="_blank" rel="external">https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-best-practices-connection</a> ，Oracle RAC的建议值是3：<a href="https://access.redhat.com/solutions/726753" target="_blank" rel="external">https://access.redhat.com/solutions/726753</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Linux/" rel="tag"># Linux</a>
          
            <a href="/tags/LVS/" rel="tag"># LVS</a>
          
            <a href="/tags/network/" rel="tag"># network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2024/04/26/流量一样但为什么CPU使用率差别很大/" rel="next" title="流量一样但为什么CPU使用率差别很大">
                <i class="fa fa-chevron-left"></i> 流量一样但为什么CPU使用率差别很大
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2024/05/16/十年后数据库还是不敢拥抱NUMA-续篇/" rel="prev" title="十年后数据库还是不敢拥抱NUMA-续篇">
                十年后数据库还是不敢拥抱NUMA-续篇 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="twitter @plantegg" />
          <p class="site-author-name" itemprop="name">twitter @plantegg</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">181</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">271</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#长连接黑洞重现和分析"><span class="nav-number">1.</span> <span class="nav-text">长连接黑洞重现和分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#背景"><span class="nav-number">1.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#重现"><span class="nav-number">1.2.</span> <span class="nav-text">重现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LVS-MySQL-高可用切换"><span class="nav-number">1.2.1.</span> <span class="nav-text">LVS+MySQL 高可用切换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LVS-Nginx-上重现"><span class="nav-number">1.2.2.</span> <span class="nav-text">LVS + Nginx 上重现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TCP-长连接流量黑洞原理总结"><span class="nav-number">1.3.</span> <span class="nav-text">TCP 长连接流量黑洞原理总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#怎么解决"><span class="nav-number">1.4.</span> <span class="nav-text">怎么解决</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#业务方"><span class="nav-number">1.4.1.</span> <span class="nav-text">业务方</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SocketTimeout"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">SocketTimeout</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RFC-5482-TCP-USER-TIMEOUT"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">RFC 5482 TCP_USER_TIMEOUT</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ConnectTimeout"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">ConnectTimeout</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#连接池"><span class="nav-number">1.4.1.4.</span> <span class="nav-text">连接池</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OS-兜底"><span class="nav-number">1.4.2.</span> <span class="nav-text">OS 兜底</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#keepalive"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">keepalive</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LVS"><span class="nav-number">1.4.3.</span> <span class="nav-text">LVS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#管控"><span class="nav-number">1.4.4.</span> <span class="nav-text">管控</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其它"><span class="nav-number">1.5.</span> <span class="nav-text">其它</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#神奇的900秒"><span class="nav-number">1.5.1.</span> <span class="nav-text">神奇的900秒</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么这个问题这几年才明显暴露"><span class="nav-number">1.5.2.</span> <span class="nav-text">为什么这个问题这几年才明显暴露</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#我用的-7层是不是就没有这个问题了？"><span class="nav-number">1.5.3.</span> <span class="nav-text">我用的 7层是不是就没有这个问题了？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#极端情况"><span class="nav-number">1.5.4.</span> <span class="nav-text">极端情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FIN-WAIT状态下，重传一直失败，连接会怎么样？"><span class="nav-number">1.5.5.</span> <span class="nav-text">FIN_WAIT状态下，重传一直失败，连接会怎么样？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据库"><span class="nav-number">1.5.6.</span> <span class="nav-text">数据库</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">1.6.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关故障和资料"><span class="nav-number">1.7.</span> <span class="nav-text">相关故障和资料</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">twitter @plantegg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv_footer"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv_footer"></span>人次
</span>


        
<div class="busuanzi-count">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
